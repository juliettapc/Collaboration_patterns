{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2592500, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_id</th>\n",
       "      <th>num_folder_members</th>\n",
       "      <th>folder_creation_date</th>\n",
       "      <th>date_last_change</th>\n",
       "      <th>user_id</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>num_adds</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_deletes</th>\n",
       "      <th>major_content_type</th>\n",
       "      <th>major_content_ext</th>\n",
       "      <th>group_total_publ</th>\n",
       "      <th>group_num_papers_last</th>\n",
       "      <th>group_num_citations</th>\n",
       "      <th>folder_lifespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592732</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-12</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>77422</td>\n",
       "      <td>cornell.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>office_docs</td>\n",
       "      <td>doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592732</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-12</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>79630</td>\n",
       "      <td>cornell.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>office_docs</td>\n",
       "      <td>doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>592732</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-12</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>77619</td>\n",
       "      <td>cornell.edu</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>office_docs</td>\n",
       "      <td>doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604794</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-27</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>86572</td>\n",
       "      <td>unc.edu</td>\n",
       "      <td>21798.0</td>\n",
       "      <td>40498.0</td>\n",
       "      <td>10660.0</td>\n",
       "      <td>pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680152</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-08-26</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>76579</td>\n",
       "      <td>cs.princeton.edu</td>\n",
       "      <td>644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder_id  num_folder_members folder_creation_date date_last_change  \\\n",
       "0     592732                   4           2008-06-12       2012-12-25   \n",
       "1     592732                   4           2008-06-12       2012-12-25   \n",
       "2     592732                   4           2008-06-12       2012-12-25   \n",
       "3     604794                   2           2008-06-27       2012-12-23   \n",
       "4     680152                   2           2008-08-26       2013-01-04   \n",
       "\n",
       "   user_id      email_domain  num_adds  num_edits  num_deletes  \\\n",
       "0    77422       cornell.edu       NaN        NaN          NaN   \n",
       "1    79630       cornell.edu       NaN        NaN          NaN   \n",
       "2    77619       cornell.edu      80.0       72.0          0.0   \n",
       "3    86572           unc.edu   21798.0    40498.0      10660.0   \n",
       "4    76579  cs.princeton.edu     644.0        0.0        112.0   \n",
       "\n",
       "  major_content_type major_content_ext group_total_publ group_num_papers_last  \\\n",
       "0        office_docs               doc              NaN                   NaN   \n",
       "1        office_docs               doc              NaN                   NaN   \n",
       "2        office_docs               doc              NaN                   NaN   \n",
       "3                pdf               pdf              NaN                   NaN   \n",
       "4                pdf               pdf              NaN                   NaN   \n",
       "\n",
       "  group_num_citations  folder_lifespan  \n",
       "0                 NaN             1658  \n",
       "1                 NaN             1658  \n",
       "2                 NaN             1658  \n",
       "3                 NaN             1641  \n",
       "4                 NaN             1593  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file='Dropbox_datafile_may22_2017_modified.csv'\n",
    "df=pd.read_csv(path+input_file, sep=',',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in df.email_domain.unique():\n",
    "    print item,\"   \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-05-01 00:00:00 2014-10-28 00:00:00\n",
      "2014-10-28 00:00:00 2015-04-26 00:00:00\n",
      "2015-04-26 00:00:00 2015-10-23 00:00:00\n",
      "2015-10-23 00:00:00 2016-04-20 00:00:00\n",
      "2016-04-20 00:00:00 2016-10-17 00:00:00\n",
      "2016-10-17 00:00:00 2017-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#### time window for temporal networks\n",
    "string_start_date='2014-05-01'\n",
    "start_date=pd.Timestamp(string_start_date)\n",
    "\n",
    "#string_end_date='2014-11-01'\n",
    "end_date=start_date + pd.Timedelta('180 days')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_tupla_dates=[]\n",
    "for i in range(6):\n",
    "    print start_date, end_date    \n",
    "    tupla_dates=[start_date,end_date]\n",
    "    list_tupla_dates.append(tupla_dates)\n",
    "\n",
    "    \n",
    "    start_date += pd.Timedelta('180 days')\n",
    "    end_date += pd.Timedelta('180 days')\n",
    "\n",
    "# 2014-05-01_2014-10-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### for plotting time series directly from data\n",
    "#df.plot(x='folder_creation_date',y='folder_lifespan',ls='',marker='.') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Timestamp('2014-05-01 00:00:00'), Timestamp('2014-10-28 00:00:00')],\n",
       " [Timestamp('2014-10-28 00:00:00'), Timestamp('2015-04-26 00:00:00')],\n",
       " [Timestamp('2015-04-26 00:00:00'), Timestamp('2015-10-23 00:00:00')],\n",
       " [Timestamp('2015-10-23 00:00:00'), Timestamp('2016-04-20 00:00:00')],\n",
       " [Timestamp('2016-04-20 00:00:00'), Timestamp('2016-10-17 00:00:00')],\n",
       " [Timestamp('2016-10-17 00:00:00'), Timestamp('2017-04-15 00:00:00')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tupla_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print df.folder_creation_date.min(), df.folder_creation_date.max()   ###  2008-05-01 00:00:00     2017-05-16 00:00:00\n",
    "#print df.date_last_change.min(), df.date_last_change.max()   ###          2012-11-07 00:00:00     2017-05-17 00:00:00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.user_id == 86572]\n",
    "\n",
    "#table[table.column_name == some_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buiding network for time window: 2014-05-01 -- 2014-10-28\n",
      "(2592500, 15)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8aa216c48790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"folder_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0memail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"email_domain\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0medits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_edits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0;31m# use this, e.g. DatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "G_all=nx.Graph()\n",
    "\n",
    "for tupla_dates in tqdm_notebook(list_tupla_dates):\n",
    "    \n",
    "\n",
    "\n",
    "    start_date=tupla_dates[0]\n",
    "    end_date=tupla_dates[1]\n",
    "\n",
    "    print \"buiding network for time window:\",str(start_date).replace(\"00:00:00\",\"\").strip(),\"--\",str( end_date).replace(\"00:00:00\",\"\").strip()\n",
    "\n",
    "    \n",
    "    G=nx.Graph()\n",
    "\n",
    "    dict_folder_list_domains={}\n",
    "    dict_folder_list_users={}\n",
    "    dict_user_id_domain={}\n",
    "    dict_user_id_edit={}\n",
    "    dict_user_id_del={}\n",
    "    dict_user_id_add={}\n",
    "    dict_user_id_folder_lifespan={}\n",
    "\n",
    "\n",
    "\n",
    "    print df.shape\n",
    "    cont=0\n",
    "\n",
    "\n",
    "#     df_selection=df[df['first_name'].notnull() & (df['nationality'] == \"USA\")]\n",
    "#     df_selection=df[  ( (df['folder_creation_date'] >= start_date )   & (df['folder_creation_date'] <= end_date ) ) | ( (df['date_last_change'] >= start_date )   & (df['date_last_change'] <= end_date ) ) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for row in tqdm_notebook(df.iterrows()):\n",
    "\n",
    "        folder=row[1][\"folder_id\"]\n",
    "        user_id=row[1][\"user_id\"]                              \n",
    "        email=row[1][\"email_domain\"]    \n",
    "        edits=row[1][\"num_edits\"]\n",
    "        adds=row[1][\"num_adds\"]\n",
    "        deletes=row[1][\"num_deletes\"]   \n",
    "        folder_lifespan=row[1][\"folder_lifespan\"]\n",
    "        num_members=row[1][\"num_folder_members\"]\n",
    "\n",
    "\n",
    "        folder_creation_date=row[1][\"folder_creation_date\"]\n",
    "        date_last_change=row[1][\"date_last_change\"]\n",
    "\n",
    "\n",
    "        #     for focus_university in list_focus_univ:        ALL UNIVERSITIES            \n",
    "    #         if focus_university in email:\n",
    "    #             flag_useful_line =1\n",
    "    #             break\n",
    "\n",
    "\n",
    "    \n",
    "        flag_useful_line=0    \n",
    "        if (folder_creation_date >= start_date  and folder_creation_date <= end_date)     or     ( date_last_change >= start_date  and  date_last_change <= end_date ):\n",
    "            flag_useful_line =1\n",
    "\n",
    "\n",
    "\n",
    "        if flag_useful_line ==1:\n",
    "                try: \n",
    "                    dict_folder_list_users[folder].append(user_id)\n",
    "                except:\n",
    "                    dict_folder_list_users[folder]=[]\n",
    "                    dict_folder_list_users[folder].append(user_id)\n",
    "\n",
    "                try:    \n",
    "                    dict_folder_list_domains[folder].append(email)\n",
    "                except:            \n",
    "                    dict_folder_list_domains[folder]=[]\n",
    "                    dict_folder_list_domains[folder].append(email)\n",
    "\n",
    "\n",
    "\n",
    "                dict_user_id_domain[user_id]=email   \n",
    "\n",
    "                try:\n",
    "                    dict_user_id_edit[user_id] +=edits   # ojo!! the records are by folder and by user, so i need to accumulate!\n",
    "                    dict_user_id_del[user_id] +=deletes\n",
    "                    dict_user_id_add[user_id] +=adds \n",
    "\n",
    "                    dict_user_id_folder_lifespan[user_id].append(folder_lifespan) \n",
    "\n",
    "                except :\n",
    "                    dict_user_id_edit[user_id] =edits\n",
    "                    dict_user_id_del[user_id] =deletes\n",
    "                    dict_user_id_add[user_id] =adds \n",
    "\n",
    "                    dict_user_id_folder_lifespan[user_id]=[]\n",
    "                    dict_user_id_folder_lifespan[user_id].append(folder_lifespan) \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    print \"done with the dict., size:\",len(dict_folder_list_users)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for user in  dict_user_id_folder_lifespan:\n",
    "        dict_user_id_folder_lifespan[user]=np.median(dict_user_id_folder_lifespan[user])\n",
    "\n",
    "\n",
    "\n",
    "    for folder in dict_folder_list_users:\n",
    "        dict_folder_list_users[folder]=list(set(dict_folder_list_users[folder]))  # remove possible duplicates\n",
    "\n",
    "        dict_folder_list_domains[folder]=list(set(dict_folder_list_domains[folder]))\n",
    "\n",
    "\n",
    "        lista=dict_folder_list_users[folder]\n",
    "\n",
    "        if len(lista)>1:\n",
    "\n",
    "            lista_pares=itertools.combinations(lista, 2)        \n",
    "\n",
    "            for item in lista_pares:\n",
    "                e1=item[0]\n",
    "                e2=item[1]\n",
    "                G.add_edge(e1,e2)\n",
    "               # print \"added edge:\",e1, e2\n",
    "    \n",
    "\n",
    "\n",
    "    print \"  N:\", len(G.nodes()),\"  L:\", len(G.edges())       \n",
    "    GC = max(nx.connected_component_subgraphs(G), key=len)\n",
    "    print \"\\n  GC:     N:\", len(GC.nodes()), \"  L:\", len(GC.edges())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### the master dict is larger than G.nodes(), and the set_node_attribute does not work in that case, so i get a selection of the dict only with the common nodes:\n",
    "    #######################\n",
    "    print len(G.nodes()), len(dict_user_id_domain)\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_domain[k] for k in set(G.nodes()) & set(dict_user_id_domain.keys())}\n",
    "    print len(G.nodes()), len(new_dict_user_id)\n",
    "    # i add the email as node attributes    \n",
    "    nx.set_node_attributes(G, 'email', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_edit[k] for k in set(G.nodes()) & set(dict_user_id_edit.keys())}\n",
    "    # i add the number of edits as node attributes    \n",
    "    nx.set_node_attributes(G, 'edits', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_del[k] for k in set(G.nodes()) & set(dict_user_id_del.keys())}\n",
    "    # i add the number of deletes as node attributes    \n",
    "    nx.set_node_attributes(G, 'deletes', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_add[k] for k in set(G.nodes()) & set(dict_user_id_add.keys())}\n",
    "    # i add the number of additions as node attributes    \n",
    "    nx.set_node_attributes(G, 'adds', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_folder_lifespan[k] for k in set(G.nodes()) & set(dict_user_id_folder_lifespan.keys())}\n",
    "    # i add the median folder_lifespan as node attributes \n",
    "    nx.set_node_attributes(G, 'median_folder_lifespan', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/\"\n",
    "    filename=\"first_network_\"+str(start_date).replace(\"00:00:00\",\"\").strip()+\"_\"+str(end_date).replace(\"00:00:00\",\"\").strip()+\".pickle\"\n",
    "    with open(path+filename,'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    print \"written:\",path+filename\n",
    "\n",
    "\n",
    "    \n",
    "    ###### global network\n",
    "    G_all.add_nodes_from(G.nodes(data=True))\n",
    "    G_all.add_edges_from(G.edges(data=True))\n",
    "\n",
    "    \n",
    "print \"\\n\\n\"    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print \"\\n\\n Global network  N:\", len(G_all.nodes()),\"  L:\", len(G_all.edges())       \n",
    "GC_all = max(nx.connected_component_subgraphs(G_all), key=len)\n",
    "print \"\\n  GC:     N:\", len(GC_all.nodes()), \"  L:\", len(GC_all.edges())\n",
    "\n",
    "\n",
    "\n",
    "print \"\\n\\n\"    \n",
    "    \n",
    "\n",
    "path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/\"\n",
    "filename=\"first_network_all.pickle\"\n",
    "with open(path+filename,'wb') as f:\n",
    "    pickle.dump(G_all, f)\n",
    "print \"written:\",path+filename\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Global network  N: 340563   L: 0\n",
      "\n",
      "  GC:     N: 1   L: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"\\n\\n Global network  N:\", len(G_all.nodes()),\"  L:\", len(G_all.edges())       \n",
    "GC_all = max(nx.connected_component_subgraphs(G_all), key=len)\n",
    "print \"\\n  GC:     N:\", len(GC_all.nodes()), \"  L:\", len(GC_all.edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
