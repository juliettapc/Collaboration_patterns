{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle  ##################################\n",
    "   #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "#import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "import time  \n",
    "\n",
    "\n",
    "\n",
    "# import plotly.plotly as py\n",
    "\n",
    "\n",
    "# # i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "# #import plotly.tools as tls\n",
    "# #tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "# import pygraphviz\n",
    "# from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "# import plotly.offline as offline\n",
    "# from plotly.graph_objs import *\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# init_notebook_mode(connected=True)\n",
    "# ################import plotly.plotly as py\n",
    "\n",
    "\n",
    "# # i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "# #import plotly.tools as tls\n",
    "# #tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "# import pygraphviz\n",
    "# from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "# import plotly.offline as offline\n",
    "# from plotly.graph_objs import *\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# init_notebook_mode(connected=True)\n",
    "# ################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### for getting geolocation data  and to calculate distance between two geolocations\n",
    "# import requests\n",
    "# import json\n",
    "# import geopy.distance   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217015\n",
      "438284\n",
      "519045\n",
      "519045\n",
      "519045\n",
      "\n",
      "/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/new_dict_folder_dict_user_act_in_folder.pickle G: 438284   L: 3795947\n",
      "\n",
      "/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/new_dict_folder_dict_user_act_in_folder.pickle G: 181212   L: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########  dictionary aggregated info by folder\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_new_PARTIAL.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_folder_id_folder_attr = pickle.load(handle) \n",
    "print len(dict_folder_id_folder_attr.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########  dictionary aggregated info by user\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/new_dict_user_id_user_attr_PARTIAL.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_user_id_user_attr = pickle.load(handle)\n",
    "print len(dict_user_id_user_attr.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########  dictionary folder list members\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_list_users_COMPLETE.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_folder_id_list_users = pickle.load(handle) \n",
    "print len(dict_folder_id_list_users.keys())\n",
    "\n",
    "\n",
    "########  dictionary user list folders\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_list_folders_COMPLETE.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_user_id_list_folders = pickle.load(handle) \n",
    "print len(dict_folder_id_list_users.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############  dict folder, dict users' act in each folder\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/new_dict_folder_dict_user_act_in_folder.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_folder_dict_user_act_in_folder = pickle.load(handle) \n",
    "print len(dict_folder_dict_user_act_in_folder.keys())\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "        \n",
    "        \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############  load the aggregated network\n",
    "path_network='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/'\n",
    "pickle_name_all_network='network_all_new.pickle'\n",
    "file = open(path_network+pickle_name_all_network,'r')\n",
    "G_all = pickle.load(file)\n",
    "print \"\\n\",pickle_name, \"G:\",len (G_all.nodes()), \"  L:\",len(G_all.edges())    #   440353 3659098\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############  load the aggregated network   filtering links by activity (if a node's activity =0, then it is not link to any other members of a folder)\n",
    "pickle_name_filtered_network='network_all_weighted_by_act_thresh1.pickle'\n",
    "file = open(path_network+pickle_name_filtered_network,'r')\n",
    "G_weighted_activity = pickle.load(file)\n",
    "print \"\\n\",pickle_name, \"G:\",len (G_weighted_activity.nodes()), \"  L:\",len(G_weighted_activity.edges())    #   440353 3659098\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7f41b8ec9a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "G_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_folder_id_folder_attr\n",
    "# 125829122.0: {'act_period': 1,\n",
    "#   'avg_geo_dist_km': 0.0,\n",
    "#   'dominated_folder': 1,  # if one person does more work than everybody else combined\n",
    "#   'eff_num_members': 1.0,\n",
    "#   'folder_activity_GINI': 0.6666666666666666,\n",
    "#   'folder_dominator': ,   # user id of the person dominating the folder\n",
    "#   'folder_lifespan': 1429,\n",
    "#   'folder_tot_act': 30.0,\n",
    "#   'folder_tot_num_adds': 30.0,\n",
    "#   'folder_tot_num_dels': 0.0,\n",
    "#   'folder_tot_num_edits': 0.0,\n",
    "#   'folder_univ_SD_ranking': 0.0,\n",
    "#   'folder_univ_mean_ranking': 196.0,\n",
    "#   'folder_univ_median_ranking': 196.0,\n",
    "#   'fraction_SR': 1.0,\n",
    "#   'fraction_work_by_SR': 0.0,\n",
    "#   'most_common_career_stage': 'sr',\n",
    "#   'most_common_categ_num_last_auth': 2.0,\n",
    "#   'most_common_categ_num_publ': 3.0,\n",
    "#   'most_common_num_cit': 3.0,\n",
    "#   'most_common_univ_ranking': 196.0,\n",
    "#   'num_above_avg_contributors': nan,\n",
    "#   'num_countries': 1,\n",
    "#   'num_fields': 1,\n",
    "#   'num_universities': 1,\n",
    "#   'number_active_members': 3,\n",
    "#   'std_geo_dist_km': 0.0}, ##### ojo! esto va a fallar pq algunos links no estan presentes en la red pesada! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "210918/|/ 97%|| 210918/217015 [00:25<00:00, 8223.12it/s]\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juliaponcela/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/juliaponcela/anaconda2/lib/python2.7/site-packages/tqdm/_tqdm.py\", line 103, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/juliaponcela/anaconda2/lib/python2.7/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_more_var_PARTIAL.pickle\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/folder_id_folder_attr_more_var_PARTIAL.csv\n"
     ]
    }
   ],
   "source": [
    "###### i add folder attributes about number of common projects of folder members\n",
    "\n",
    "G= G_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for folder_id in tqdm_notebook(dict_folder_id_folder_attr):\n",
    "   # print folder_id,\n",
    "    \n",
    "   # df[df['folder_id'].isin(lista)]['user_id'].unique()\n",
    "    \n",
    "    list_members=dict_folder_id_list_users[folder_id] \n",
    "    \n",
    "    list_num_common_prjts=[]        \n",
    "    dict_folder_id_folder_attr[folder_id]['members']=list_members\n",
    "               \n",
    "    \n",
    "    max_num_common_prjt=0.\n",
    "    lista_pares=itertools.combinations(list_members, 2)   \n",
    "    \n",
    "    \n",
    "    cont_pares=0.\n",
    "    cont_multiple_prjt=0.\n",
    "    list_num_common_prjts=[]        \n",
    "    for item in lista_pares:       \n",
    "        cont_pares +=1.\n",
    "        n1=item[0]\n",
    "        n2=item[1]\n",
    "        \n",
    "        num_common_pr=G.edge[n1][n2]['num_common_projects']\n",
    "        \n",
    "        list_num_common_prjts.append(num_common_pr)\n",
    "        if num_common_pr > max_num_common_prjt:\n",
    "            max_num_common_prjt=num_common_pr\n",
    "                    \n",
    "                \n",
    "        if  num_common_pr > 1:\n",
    "            cont_multiple_prjt +=1.\n",
    "                                                                                                                                \n",
    "                \n",
    "                    \n",
    "    dict_folder_id_folder_attr[folder_id]['max_num_common_prjt']=max_num_common_prjt\n",
    "    dict_folder_id_folder_attr[folder_id]['avg_num_common_prjt']=np.mean(list_num_common_prjts)\n",
    "    \n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id]['flag_common_prjt']=0\n",
    "    if max_num_common_prjt >1:\n",
    "        dict_folder_id_folder_attr[folder_id]['flag_common_prjt']=1\n",
    "           \n",
    "    try:        \n",
    "        dict_folder_id_folder_attr[folder_id]['fract_pairs_multipl_prjts']=cont_multiple_prjt/cont_pares\n",
    "    except ZeroDivisionError:\n",
    "        dict_folder_id_folder_attr[folder_id]['fract_pairs_multipl_prjts']=np.nan\n",
    "             \n",
    "            \n",
    "           \n",
    "        \n",
    "    \n",
    "   \n",
    "print \"done\"\n",
    "\n",
    "\n",
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_more_var_PARTIAL.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_folder_id_folder_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_folder_id_folder_attr,orient='index')\n",
    "df_from_dict.to_csv(pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(G_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network loaded unfiltered\n",
      "CC ...... done\n",
      "k-shell structure ......   done\n",
      "adding variables to dict ...... done for network: unfiltered\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_network=\"unfiltered\"   #\"unfiltered\"  # filtered_act\n",
    "\n",
    "\n",
    "\n",
    "if label_network == \"unfiltered\":    \n",
    "    G=G_all\n",
    "    string_for_var=\"unfiltered\"\n",
    "    \n",
    "elif label_network == \"filtered_act\":\n",
    "    G=G_weighted_activity\n",
    "    string_for_var=\"filtered_by_act\"\n",
    "    \n",
    "print \"network loaded\"  , label_network  \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "######   I add Clustering Coefficient as nodes attributes\n",
    "print \"CC ......\",\n",
    "dict_clustering=nx.clustering(G)\n",
    "nx.set_node_attributes(G, 'CC'+\"_\"+string_for_var, dict_clustering)\n",
    "print \"done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########  k-shell decomposition\n",
    "\n",
    "print \"k-shell structure ......\", \n",
    "\n",
    "# i need to make a copy and remove the self-loops from that before i can proceed\n",
    "G_for_kshell = nx.Graph(G.subgraph(G.nodes()))\n",
    "\n",
    "list_edges_to_remove=[]\n",
    "for edge in G_for_kshell.edges():\n",
    "    if edge[0] == edge[1]:\n",
    "        list_edges_to_remove.append(edge)\n",
    "\n",
    "for edge in  list_edges_to_remove:\n",
    "    G_for_kshell.remove_edge(edge[0], edge[1])        \n",
    "\n",
    "   \n",
    "dict_node_kshell=nx.core_number(G_for_kshell)\n",
    "print \"  done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \"adding variables to dict ......\",\n",
    "for user_id in dict_user_id_user_attr:\n",
    "    dict_user_id_user_attr[user_id][\"CC\"+\"_\"+string_for_var]=dict_clustering[user_id]\n",
    "    dict_user_id_user_attr[user_id][\"k\"+\"_\"+string_for_var]=G.degree(user_id)\n",
    "    dict_user_id_user_attr[user_id][\"kshell\"+\"_\"+string_for_var]=dict_node_kshell[user_id]\n",
    "    #dict_user_id_user_attr[user_id][\"betweenness\"+\"_\"+string_for_var]=dict_betweenness[user_id]\n",
    "   \n",
    "\n",
    "print \"done for network:\", string_for_var\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#########  i add list of folders\n",
    "for user_id in dict_user_id_user_attr:   \n",
    "    list_folders = dict_user_id_list_folders[user_id]\n",
    "    dict_user_id_user_attr[user_id][\"list_folders\"]=list_folders\n",
    "   \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(G.nodes()), len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ######### just for betweenness (way slower to calculate than the other network variables)\n",
    "\n",
    "# label_network=\"filtered_act\"   #\"unfiltered\"  # filtered_act\n",
    "\n",
    "\n",
    "# if label_network == \"unfiltered\":    \n",
    "#     G=G_all\n",
    "#     string_for_var=\"unfiltered\"\n",
    "    \n",
    "# elif label_network == \"filtered_act\":\n",
    "#     G=G_weighted_activity\n",
    "#     string_for_var=\"filtered_by_act\"\n",
    "    \n",
    "# print \"network loaded\"  , label_network  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# #######  I add betweenness centrality:\n",
    "# print \"betweenness .....\", \n",
    "# dict_betweenness=nx.betweenness_centrality(G)#, k=None, normalized=True, weight=None, endpoints=False, seed=None)\n",
    "# nx.set_node_attributes(G, 'betweenness'+\"_\"+string_for_var, dict_betweenness)\n",
    "# print \"done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# print \"adding variables to dict ......\",\n",
    "# for user_id in dict_user_id_user_attr:\n",
    "#     dict_user_id_user_attr[user_id][\"betweenness\"+\"_\"+string_for_var]=dict_betweenness[user_id]\n",
    "   \n",
    "\n",
    "# print \"done for network:\", string_for_var\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var_PARTIAL.pickle\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/user_id_user_attr_more_var_PARTIAL.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var_PARTIAL.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_user_id_user_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "df_from_dict.to_csv(pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_user_id_user_attr\n",
    "# 629145600.0: {'CC_unfiltered': 1.0,\n",
    "#   'Country': 'United States',\n",
    "#   'University_name': 'cornell university',\n",
    "#   'career_stage': nan,\n",
    "#   'category_total_cit': nan,\n",
    "#   'category_total_last_auth': nan,\n",
    "#   'category_total_publ': nan,\n",
    "#   'eff_num_folders': 0,\n",
    "#   'email_domain': 'cornell.edu',\n",
    "#   'field': nan,\n",
    "#   'folders_above_avg': {1369112819.0: 0},\n",
    "#   'geoloc': '(42.4534492, -76.4735027) 14850',\n",
    "#   'gini_act_across_folders': nan,\n",
    "#   'group_num_citations': nan,\n",
    "#   'group_num_papers_last': nan,\n",
    "#   'group_total_publ': nan,\n",
    "#   'k_unfiltered': 30,\n",
    "#   'kshell_unfiltered': 30,\n",
    "#   'national_ranking': 8.0,\n",
    "#   'number_folders': 1,\n",
    "#   'user_id': 629145600.0,\n",
    "#   'user_tot_act': 0.0,\n",
    "#   'user_tot_num_adds': 0.0,\n",
    "#   'user_tot_num_deletes': 0.0,\n",
    "#   'user_tot_num_edits': 0.0,\n",
    "#   'user_univ_ranking': 10.0,\n",
    "#   'world_ranking': 10.0},\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##### i load the dict with some variables already\n",
    "# pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_more_var.pickle'\n",
    "# with open(pickle_name, 'rb') as handle:\n",
    "#     dict_folder_id_folder_attr = pickle.load(handle)\n",
    " \n",
    "# print len(dict_folder_id_folder_attr.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### i load the dict with some variables already\n",
    "# pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var.pickle'\n",
    "# with open(pickle_name, 'rb') as handle:\n",
    "#     dict_user_id_user_attr_more_var = pickle.load(handle)\n",
    " \n",
    "# print len(dict_user_id_user_attr_more_var.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network unfiltered\n",
      "66779/|/ 31%|| 66779/217014 [07:36<17:07, 146.19it/s]\n",
      "done\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_more_var_PARTIAL.pickle\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/folder_id_folder_attr_more_var_PARTIAL.csv\n",
      "written:"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c42566cef98d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_network\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpickle_name_all_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"written:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "##### i get avg of network metrics among members of each folder\n",
    "\n",
    "label_network=\"unfiltered\"   #\"unfiltered\"  # filtered_act\n",
    "\n",
    "\n",
    "if label_network == \"unfiltered\":    \n",
    "    G=G_all\n",
    "    string_for_var=\"unfiltered\"\n",
    "    \n",
    "elif label_network == \"filtered_act\":\n",
    "    G=G_weighted_activity\n",
    "    string_for_var=\"filtered_by_act\"\n",
    "    \n",
    "print \"network\"  , label_network  \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for folder_id in tqdm_notebook(dict_folder_id_folder_attr):\n",
    "         \n",
    "    \n",
    "    list_users_folder=dict_folder_id_list_users[folder_id]    \n",
    "    \n",
    "    \n",
    "    lista1=[ dict_user_id_user_attr[user_id][\"k_unfiltered\"]  for user_id in list_users_folder ]   # similar example to lista=[x*2 for x in lista_de_cosas]\n",
    "    dict_folder_id_folder_attr[folder_id][\"avg_k_unfiltered\"]=np.mean(lista1)\n",
    "         \n",
    "    lista2=[ dict_user_id_user_attr[user_id][\"CC_unfiltered\"]  for user_id in list_users_folder ]\n",
    "    dict_folder_id_folder_attr[folder_id][\"avg_CC_unfiltered\"]=np.mean(lista2)\n",
    "            \n",
    "    lista3=[ dict_user_id_user_attr[user_id][\"kshell_unfiltered\"]  for user_id in list_users_folder ]\n",
    "    dict_folder_id_folder_attr[folder_id][\"avg_kshell_unfiltered\"]=np.mean(lista3)\n",
    "   \n",
    "\n",
    "\n",
    "########## OJJO!!! ESTA RED NO LA TENGO HECHA TODAVIA (running @nicoresearch)\n",
    "      \n",
    "#     lista4=[dict_user_id_user_attr[user_id][\"k_filtered_by_act\"]  for user_id in list_users_folder]\n",
    "#     dict_folder_id_folder_attr[folder_id][\"avg_k_filtered_by_act\"]=np.mean(lista4)\n",
    "         \n",
    "#     lista5=[dict_user_id_user_attr[user_id][\"CC_filtered_by_act\"]  for user_id in list_users_folder]\n",
    "#     dict_folder_id_folder_attr[folder_id][\"avg_CC_filtered_by_act\"]=np.mean(lista5)       \n",
    "     \n",
    "#     lista6=[dict_user_id_user_attr[user_id][\"kshell_filtered_by_act\"]  for user_id in list_users_folder]\n",
    "#     dict_folder_id_folder_attr[folder_id][\"avg_kshell_filtered_by_act\"]=np.mean(lista6)\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    ######## i get the overlap of neighborhoods between each pair in a folder:  Overlapping collaborations for a given pair i-j = intersection neighbours ij / union neighbours ij \n",
    "    lista_pares=itertools.combinations(list_users_folder, 2)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    list_overlaps_all_pairs=[]\n",
    "    for item in lista_pares:       \n",
    "        \n",
    "        n1=item[0]\n",
    "        n2=item[1]\n",
    "        \n",
    "        list_neighbours_n1=G.neighbors(n1)\n",
    "        list_neighbours_n2=G.neighbors(n2)\n",
    "        \n",
    "        intersection= len(set(list_neighbours_n1).intersection(list_neighbours_n2))\n",
    "        union=len(set(list_neighbours_n1).union(list_neighbours_n2))\n",
    "        \n",
    "        overlap_n1_n2= intersection/float(union)\n",
    "\n",
    "        list_overlaps_all_pairs.append(overlap_n1_n2)\n",
    "        \n",
    "       \n",
    "        \n",
    "        G.edge[n1][n2]['neighborhood_overlap'+\"_\"+string_for_var]=overlap_n1_n2\n",
    "    \n",
    "\n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"avg_overlap_neighbourhoods\"+\"_\"+string_for_var]=np.mean(list_overlaps_all_pairs)           \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "print \"done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_more_var_PARTIAL.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_folder_id_folder_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_folder_id_folder_attr,orient='index')\n",
    "df_from_dict.to_csv(pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### i re-write the network, after adding attr to links\n",
    "\n",
    "if label_network ==\"unfiltered\"  :       \n",
    "    with open(path_network+pickle_name_all_network.replace(\".pickle\",\"_.pickle\"),'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    print \"written:\",path_network+pickle_name_all_network\n",
    "\n",
    "    \n",
    "elif  label_network == \"filtered_act\":       \n",
    "    with open(path_network+pickle_name_filtered_network.replace(\".pickle\",\"_.pickle\"),'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    print \"written:\",path_network+pickle_name_filtered_network\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_folder_id_folder_attr\n",
    "\n",
    "# 125829122.0: {'act_period': 1,\n",
    "#   'avg_CC_unfiltered': 0.18790826051100021,\n",
    "#   'avg_geo_dist_km': 0.0,\n",
    "#   'avg_k_unfiltered': 49.0,\n",
    "#   'avg_kshell_unfiltered': 11.0,\n",
    "#   'avg_num_common_prjt': 59.0,\n",
    "#   'avg_overlap_neighbourhoods': 0.51014911014911013,\n",
    "#   'dominated_folder': 1,\n",
    "#   'eff_num_members': 1.0,\n",
    "#   'flag_common_prjt': 1,\n",
    "#   'folder_activity_GINI': 0.6666666666666666,\n",
    "#   'folder_dominator': 30.0,\n",
    "#   'folder_lifespan': 1429,\n",
    "#   'folder_tot_act': 30.0,\n",
    "#   'folder_tot_num_adds': 30.0,\n",
    "#   'folder_tot_num_dels': 0.0,\n",
    "#   'folder_tot_num_edits': 0.0,\n",
    "#   'folder_univ_SD_ranking': 0.0,\n",
    "#   'folder_univ_mean_ranking': 196.0,\n",
    "#   'folder_univ_median_ranking': 196.0,\n",
    "#   'fract_pairs_multipl_prjts': 1.0,\n",
    "#   'fraction_SR': 1.0,\n",
    "#   'fraction_work_by_SR': 0.0,\n",
    "#   'max_num_common_prjt': 82,\n",
    "#   'members': [158333798.0, 39269646.0, 14204631.0],\n",
    "#   'most_common_career_stage': 'sr',\n",
    "#   'most_common_categ_num_last_auth': 2.0,\n",
    "#   'most_common_categ_num_publ': 3.0,3\n",
    "#   'most_common_num_cit': 3.0,\n",
    "#   'most_common_univ_ranking': 196.0,\n",
    "#   'num_above_avg_contributors': nan,\n",
    "#   'num_countries': 1,\n",
    "#   'num_fields': 1,\n",
    "#   'num_universities': 1,\n",
    "#   'number_active_members': 3,\n",
    "#   'std_geo_dist_km': 0.0},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############    i add avg. fraction of work a user does across her different folders\n",
    "\n",
    "\n",
    "def remove_nans_replace_by_zeros(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                aux_lista.append(0.)        #pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(float(lista[i]))\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "def gini(list_of_values):\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    try:\n",
    "        return (fair_area - area) / fair_area\n",
    "    except ZeroDivisionError:\n",
    "#         print \"problems with:\",list_of_values   # if lista=[0,0,0]  or [0]\n",
    "#         raw_input()\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "    \n",
    "########################\n",
    "########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_user_id_user_attr\n",
    "\n",
    "# 629145600.0: {'CC_unfiltered': 1.0,\n",
    "#   'Country': 'United States',\n",
    "#   'University_name': 'cornell university',\n",
    "#   'career_stage': nan,\n",
    "#   'category_total_cit': nan,\n",
    "#   'category_total_last_auth': nan,\n",
    "#   'category_total_publ': nan,\n",
    "#   'eff_num_folders': 0,\n",
    "#   'email_domain': 'cornell.edu',\n",
    "#   'field': nan,\n",
    "#   'folders_above_avg': {1369112819.0: 0},\n",
    "#   'geoloc': '(42.4534492, -76.4735027) 14850',\n",
    "#   'gini_act_across_folders': nan,\n",
    "#   'group_num_citations': nan,\n",
    "#   'group_num_papers_last': nan,\n",
    "#   'group_total_publ': nan,\n",
    "#   'k_unfiltered': 30,\n",
    "#   'kshell_unfiltered': 30,\n",
    "#   'national_ranking': 8.0,\n",
    "#   'number_folders': 1,\n",
    "#   'user_id': 629145600.0,\n",
    "#   'user_tot_act': 0.0,\n",
    "#   'user_tot_num_adds': 0.0,\n",
    "#   'user_tot_num_deletes': 0.0,\n",
    "#   'user_tot_num_edits': 0.0,\n",
    "#   'user_univ_ranking': 10.0,\n",
    "#   'world_ranking': 10.0},\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliaponcela/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning:\n",
      "\n",
      "Degrees of freedom <= 0 for slice\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done.\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var_PARTIAL.pickle\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/user_id_user_attr_more_var_PARTIAL.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_per_folder_per_user_work_contribution= []\n",
    "\n",
    "\n",
    "for user_id in tqdm_notebook(dict_user_id_user_attr):\n",
    "        \n",
    "    lista_folders= dict_user_id_list_folders[user_id]  \n",
    "    \n",
    "    list_avg_fract_act_in_each_folder=[]\n",
    "    \n",
    "    for folder_id in  lista_folders:                \n",
    "        \n",
    "                        \n",
    "        try:\n",
    "            user_act_in_folder= dict_folder_dict_user_act_in_folder[folder_id][user_id]\n",
    "            \n",
    "            folder_tot_act=dict_folder_id_folder_attr[folder_id]['folder_tot_act']\n",
    "           \n",
    "\n",
    "            try:\n",
    "                fract=float(user_act_in_folder)/float(folder_tot_act)\n",
    "                list_avg_fract_act_in_each_folder.append(fract)\n",
    "\n",
    "                list_per_folder_per_user_work_contribution.append(fract)\n",
    "\n",
    "            except ZeroDivisionError: pass   # if the user hasnt done any activity, but nobody in the folder has done anything either: i dont consider that for the avg\n",
    "        except KeyError: pass\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dict_user_id_user_attr[user_id][\"avg_fract_work_over_diff_folders\"]=np.mean(list_avg_fract_act_in_each_folder)\n",
    "    except :  #if empty list\n",
    "        dict_user_id_user_attr[user_id][\"avg_fract_work_over_diff_folders\"]=np.nan\n",
    "        \n",
    "        \n",
    "        \n",
    "    try:\n",
    "        dict_user_id_user_attr[user_id][\"SD_fract_work_over_diff_folders\"]=np.std(list_avg_fract_act_in_each_folder)\n",
    "    except :  #if empty list\n",
    "        dict_user_id_user_attr[user_id][\"SD_fract_work_over_diff_folders\"]=np.nan\n",
    "        \n",
    "      \n",
    "        \n",
    "           \n",
    "    try:\n",
    "        dict_user_id_user_attr[user_id][\"GINI_distrib_fract_act_each\"]=gini(list_avg_fract_act_in_each_folder)\n",
    "    except :  #if empty list\n",
    "        dict_user_id_user_attr[user_id][\"GINI_distrib_fract_act_each\"]=np.nan\n",
    "        \n",
    "      \n",
    "print \"done.\"    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var_PARTIAL.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_user_id_user_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "df_from_dict.to_csv(pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
