{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle  ##################################\n",
    "   #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "#import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "import time  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num folders 519045\n",
      "num users 438284\n",
      "num users 519045\n",
      "num folders 519045\n",
      "num. users: 438284 (6527213, 7)\n",
      "after removing rows without dates:\n",
      "  num. users: 175587 (5599544, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########  dictionary aggregated info by folder                                 \n",
    "#pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_new_COMPLETE.pickle'\n",
    "\n",
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_with_time_attr_.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_folder_id_folder_attr = pickle.load(handle) \n",
    "print \"num folders\",len(dict_folder_id_folder_attr.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########  dictionary aggregated info by user\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_new_COMPLETE.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_user_id_user_attr = pickle.load(handle)\n",
    "print \"num users\",len(dict_user_id_user_attr.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########  dictionary folder list members\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_list_users_COMPLETE.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_folder_id_list_users = pickle.load(handle) \n",
    "print \"num users\",len(dict_folder_id_list_users.keys())\n",
    "\n",
    "\n",
    "########  dictionary user list folders\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_list_folders_COMPLETE.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_user_id_list_folders = pickle.load(handle) \n",
    "print \"num folders\",len(dict_folder_id_list_users.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########  csv  all act aggr by date\n",
    "path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file = 'DROPBOX_only_activity_aggr_by_date_COMPLETE.csv'\n",
    "df_all_act = pd.read_csv(path+input_file, sep=',',na_values=[\"NAN\",\"-1\",\"null\"], parse_dates=['folder_creation_date','date'])#, nrows=1000000) # set header=0 if i wanna pass it my own list of header names\n",
    "df_all_act.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print \"num. users:\",len(df_all_act.user_id.unique()),df_all_act.shape    # 200000 (3072489, 8)\n",
    "  \n",
    "df_all_act=df_all_act.replace('nan', np.nan)  ## for some reason, there are diff nomenclatures for NANs, and it is not interpreting them correctly when reading the file \n",
    "df_all_act=df_all_act.replace('NAN', np.nan)\n",
    "df_all_act=df_all_act.replace('NaN', np.nan)\n",
    "df_all_act=df_all_act.replace('-1', np.nan)\n",
    "df_all_act=df_all_act.replace('', np.nan)\n",
    "\n",
    "\n",
    "#convert the date columns from str to datetime    (for some reason, parsing when i read it does nothing)\n",
    "df_all_act['date'] = pd.to_datetime(df_all_act['date'], errors='coerce')\n",
    "df_all_act['folder_creation_date'] = pd.to_datetime(df_all_act['folder_creation_date'], errors='coerce')\n",
    "\n",
    "df_all_act_no_NANs= df_all_act[df_all_act.date.notnull()]    \n",
    "print \"after removing rows without dates:\\n  num. users:\",len(df_all_act_no_NANs.user_id.unique()),df_all_act_no_NANs.shape    # 400000  (5141758, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all_act.shape\n",
    "print \"after removing rows without dates:\\n  num. users:\",len(df_all_act_no_NANs.user_id.unique()),df_all_act_no_NANs.shape    # 400000  (5141758, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_nans(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass            \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "\n",
    "def remove_nans_for_strings(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "             aux_lista.append(lista[i])#pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    " #pd.NaT(lista[i],dtype='datetime64[D]' ) == True:                                                             \n",
    "               # numpy.datetime64('NaT')\n",
    "                \n",
    "#                np.isnat(np.array(['nat', 1, 2, 3, 4, 'nat', 5], dtype='datetime64[D]'))\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "\n",
    "def remove_nans_for_dates(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            #if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "            if np.NaT(lista[i]) == True: \n",
    "               \n",
    "                \n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "             aux_lista.append(lista[i])#pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "\n",
    "def remove_nans_replace_by_zeros(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                aux_lista.append(0.)        #pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(float(lista[i]))\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### get dict with  folder_id lifespan:\n",
    "def remove_nans_replace_intervals_with_starting_value(lista):\n",
    "    #print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when/ nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "        except TypeError: # (when not-nan):\n",
    "            #print lista[i]   \n",
    "            try:  \n",
    "                aux_lista.append(float(lista[i]))\n",
    "                #print \"no problem\"\n",
    "            except ValueError:  # sometimes, the ranking is 75-82\n",
    "                #print \"issue found\"\n",
    "                value=lista[i]\n",
    "#                 v1=float(value.split(\"-\")[0])\n",
    "#                 v2=float(value.split(\"-\")[1])\n",
    "                \n",
    "                new_value=float(value.split(\"-\")[0])#np.median([v1,v2])  \n",
    "                aux_lista.append(new_value)\n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "\n",
    "\n",
    "def gini(old_list_of_values):\n",
    "    \n",
    "    list_of_values=[]\n",
    "    for item in old_list_of_values:\n",
    "        try:\n",
    "            int(item) # if it is a NAN, it with fail\n",
    "            list_of_values.append(item)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "   # print list_of_values\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    try:\n",
    "        return (fair_area - area) / fair_area\n",
    "    except ZeroDivisionError:\n",
    "#         print \"problems with:\",list_of_values   # if lista=[0,0,0]  or [0]\n",
    "#         raw_input()\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "##############\n",
    "\n",
    "\n",
    "def  effective_num(lista_values):  # i can use it for the effective number of members in a folder, by activity, or the effective number of folders for a user, also by activity\n",
    "    \n",
    "     # first, i need to remove the zeros, because i cant do the log(0), but i can remove them, they dont count as effective members\n",
    "    \n",
    "    \n",
    "    cont_num_nonzero_items=0\n",
    "    H=0.\n",
    "    tot_sum=float(sum(lista_values))\n",
    "    for item in lista_values:\n",
    "        if item >0:\n",
    "            aux= item/tot_sum * np.log2( item/tot_sum)\n",
    "            H += aux\n",
    "            cont_num_nonzero_items +=1\n",
    "            \n",
    "    H = -1.0 * H\n",
    "    \n",
    "    eff_number = np.power(2.0, H)\n",
    "    \n",
    "    if cont_num_nonzero_items ==0:   # if the list of act is [0] then i want the eff. number to be 0, not 1\n",
    "        eff_number =0\n",
    "    \n",
    "    return eff_number\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_with_time_attr_.pickle\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/folder_id_folder_attr_with_time_attr_.csv\n"
     ]
    }
   ],
   "source": [
    "########### i get dict for the folder_id time-related attr.\n",
    "\n",
    "#df_all_act_no_NANs\n",
    "\n",
    "def  temporary_grouping_folder(folder_id, dict_folder_id_folder_attr, df_select_folder_act, list_users) :  # df_select_folder_act is sorted by user_id and then date                 \n",
    "        \n",
    "    \n",
    "    \n",
    "    list_days_present_members=[]\n",
    "    for user_id in list_users:\n",
    "        \n",
    "        df_act_user= df_select_folder_act[df_select_folder_act['user_id'] == user_id]                                   \n",
    "        num_days= len(df_act_user.date.unique())                       \n",
    "        list_days_present_members.append(num_days)\n",
    "                            \n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"eff_num_members_by_days_present\"]=effective_num(remove_nans_replace_by_zeros(list_days_present_members))\n",
    "    \n",
    "    \n",
    "           \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "############################################\n",
    "#############################################\n",
    "     \n",
    "cont=1\n",
    "\n",
    "for folder_id in tqdm_notebook(dict_folder_id_list_users):  \n",
    "  \n",
    "    list_users=dict_folder_id_list_users[folder_id]\n",
    "\n",
    "    \n",
    "    \n",
    "    df_select_folder_act=df_all_act_no_NANs[df_all_act_no_NANs['folder_id']== folder_id].sort_values(by='date')   \n",
    "    \n",
    "    #df_select_folder_act=df_all_act[df_all_act['folder_id']== folder_id].sort_values(by='date')        \n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "    cont +=1\n",
    "   # if len(df_select_folder_act)>0:\n",
    "    temporary_grouping_folder(folder_id, dict_folder_id_folder_attr, df_select_folder_act, list_users)\n",
    "\n",
    "\n",
    "#     if cont >= 10000:\n",
    "#         break          \n",
    "  \n",
    "    \n",
    "print \"done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dict_folder_id_folder_attr['folder_id'][\"gini_num_days_present_over_members\"]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_with_time_attr_.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_folder_id_folder_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_folder_id_folder_attr,orient='index')\n",
    "## add foler_id from index\n",
    "df_from_dict.to_csv(pickle_name.replace(\"dict_\",'').strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### i get dict for the folder_id time-related attr.\n",
    "\n",
    "#df_all_act_no_NANs\n",
    "\n",
    "def  grouping_folder(folder_id, dict_folder_id_folder_attr, df_select_folder_act, list_users) :  # df_select_folder_act is sorted by user_id and then date                 \n",
    "    \n",
    "#     print \n",
    "#     print df_select_folder_act\n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"act_per_day\"] = float(dict_folder_id_folder_attr[folder_id][\"folder_tot_act\"]) / dict_folder_id_folder_attr[folder_id][\"act_period\"]\n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"act_per_day_per_active_user\"] = float(dict_folder_id_folder_attr[folder_id][\"folder_tot_act\"]) / \\\n",
    "    (dict_folder_id_folder_attr[folder_id][\"act_period\"]*dict_folder_id_folder_attr[folder_id][\"number_active_members\"])\n",
    "    \n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"overall_num_active_days\"]=len(df_select_folder_act.date.dropna().unique())   #  there shouldnt be any nans anyway len(remove_nans_for_dates(df_select_folder_act.date.unique()))\n",
    "    \n",
    "                                        \n",
    "           \n",
    "    tot_num_days=dict_folder_id_folder_attr[folder_id][\"act_period\"]\n",
    "    \n",
    "    #rolling_window=int(tot_num_days/10.)\n",
    "    \n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"num_time_stamps\"]=len(df_select_folder_act)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    list_days_present_members=[]\n",
    "    for user_id in list_users:\n",
    "        \n",
    "        df_act_user= df_select_folder_act[df_select_folder_act['user_id'] == user_id]                                   \n",
    "        num_days= len(df_act_user.date.unique())                       \n",
    "        list_days_present_members.append(num_days)\n",
    "        \n",
    "        \n",
    "        \n",
    "    dict_folder_id_folder_attr[folder_id][\"gini_num_days_present_over_members\"]=gini(list_days_present_members)\n",
    "\n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"eff_num_members_by_days_present\"]=effective_num(list_days_present_members)\n",
    "    \n",
    "    \n",
    "    ########### calculate burstiness for the folder's activity:\n",
    "    \n",
    "    if len(df_select_folder_act)>2:        \n",
    "        \n",
    "        #print \n",
    "        #print df_select_folder_act\n",
    "        list_deltas= ( df_select_folder_act.date - df_select_folder_act.date.shift() ).fillna(0)\n",
    "        lista_interevent_times=[x.days for x in list_deltas][1:]      # the first delta time is always zero because it comes from comparing to nan when shifting the column\n",
    "\n",
    "\n",
    "       # print lista_interevent_times\n",
    "        m1=np.mean(lista_interevent_times)\n",
    "        s1=np.std(lista_interevent_times)\n",
    "\n",
    "        burstiness= (s1-m1)/(s1+m1)\n",
    "        dict_folder_id_folder_attr[folder_id][\"burstiness\"]= burstiness\n",
    "        dict_folder_id_folder_attr[folder_id][\"avg_interevent_time\"]= np.mean(lista_interevent_times)\n",
    "       \n",
    "      \n",
    " \n",
    "    else:\n",
    "        dict_folder_id_folder_attr[folder_id][\"burstiness\"]=np.nan\n",
    "        dict_folder_id_folder_attr[folder_id][\"avg_interevent_time\"]= np.nan\n",
    "           \n",
    "        \n",
    "        \n",
    "   \n",
    "    \n",
    "    \n",
    "    #### fract of days when multiple users are working simultaneously\n",
    "    cont_simult=0.\n",
    "#     if cont >= 10000:\n",
    "#         break       \n",
    "    for date in df_select_folder_act.date.unique():\n",
    "        \n",
    "        df_select_date = df_select_folder_act[df_select_folder_act['date'] == date]\n",
    "        num_users=len(df_select_date.user_id.unique())\n",
    "        if num_users >1:\n",
    "             cont_simult +=1.\n",
    "    \n",
    "    try:\n",
    "        dict_folder_id_folder_attr[folder_id][\"frac_simult_days_overall\"] = cont_simult /  dict_folder_id_folder_attr[folder_id][\"act_period\"]\n",
    "    except ZeroDivisionError:\n",
    "        dict_folder_id_folder_attr[folder_id][\"frac_simult_days_overall\"] = np.nan\n",
    "        \n",
    "        \n",
    "    try:    \n",
    "        dict_folder_id_folder_attr[folder_id][\"frac_simult_days_over_active_days\"] = cont_simult /  dict_folder_id_folder_attr[folder_id][\"overall_num_active_days\"]\n",
    "    except ZeroDivisionError:\n",
    "        dict_folder_id_folder_attr[folder_id][\"frac_simult_days_over_active_days\"] = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print \"fract simult days:\", dict_folder_id_folder_attr[folder_id][\"frac_simult_days\"], \"  cont_sim:\",cont_simult, \" act_period:\",dict_folder_id_folder_attr[folder_id][\"act_period\"]\n",
    "   \n",
    "#     print \"overall num. active days in folder:\", dict_folder_id_folder_attr[folder_id][\"overall_num_active_days\"]\n",
    "#     raw_input()    \n",
    "\n",
    "    \n",
    "#         #### i identify who is the most active user using a rolling window              \n",
    "#         df_rolling_avg=df_act_user.set_index('date').rolling(rolling_window, center=True).mean()       \n",
    "#         df_rolling_avg['date'] = df_rolling_avg.index\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "############################################\n",
    "#############################################\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "cont=1\n",
    "\n",
    "for folder_id in tqdm_notebook( dict_folder_id_list_users):  \n",
    "  \n",
    "    list_users=dict_folder_id_list_users[folder_id]\n",
    "\n",
    "    \n",
    "    \n",
    "    df_select_folder_act=df_all_act_no_NANs[df_all_act_no_NANs['folder_id']== folder_id].sort_values(by='date')        \n",
    "    #df_select_folder_act=df_all_act[df_all_act['folder_id']== folder_id].sort_values(by='date')        \n",
    "\n",
    "    \n",
    "    \n",
    "    #df_select_users_attr= df_user_basic_attr[df_user_basic_attr.user_id.isin(list_users)]        \n",
    "\n",
    "   \n",
    "\n",
    "    cont +=1\n",
    "   # if len(df_select_folder_act)>0:\n",
    "    grouping_folder(folder_id, dict_folder_id_folder_attr, df_select_folder_act, list_users)\n",
    "\n",
    "\n",
    "#     if cont >= 10000:\n",
    "#         break          \n",
    "  \n",
    "    \n",
    "print \"done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dict_folder_id_folder_attr['folder_id'][\"gini_num_days_present_over_members\"]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_with_time_attr.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_folder_id_folder_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_folder_id_folder_attr,orient='index')\n",
    "## add foler_id from index\n",
    "df_from_dict.to_csv(pickle_name.replace(\"dict_\",'').strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\".csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# data = [go.Histogram(x=lista_burstiness_values,\n",
    "#                      histnorm='probability')]\n",
    "\n",
    "# py.iplot(data, filename='normalized histogram')\n",
    "                                                       # REAL DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_b_low=[]\n",
    "lista_b_high=[]\n",
    "lista_neutral_b=[]\n",
    "\n",
    "for folder_id in dict_folder_id_folder_attr:\n",
    "    if dict_folder_id_folder_attr[folder_id]['overall_num_active_days']>50:\n",
    "        #print folder\n",
    "        if dict_folder_id_folder_attr[folder_id]['burstiness']>0.5:   # examples folders: 278921388.0  1022361891.0  640680533.0  500171667.0 94594249.0 1174406155.0 876612829.0\n",
    "            lista_b_high.append(folder_id)  \n",
    "        elif dict_folder_id_folder_attr[folder_id]['burstiness'] < -0.5:   # examples folders (rare!): 1288795403.0   1303489998.0   1396197512.0   156510508.0   1175798456.0  184263678.0  23781582.0\n",
    "            lista_b_low.append(folder_id)\n",
    "        elif( dict_folder_id_folder_attr[folder_id]['burstiness'] < 0.1)  and   (dict_folder_id_folder_attr[folder_id]['burstiness'] > -0.1) :   # examples folders : 810549883.0  1304953142.0 430966151.0 914359852.0 1220543920.0 \n",
    "            lista_neutral_b.append(folder_id)\n",
    "           \n",
    "#             for key in sorted(dict_folder_id_folder_attr[folder]):\n",
    "#                 print key, dict_folder_id_folder_attr[folder][key]\n",
    "#             raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(lista_b_high)+ len(lista_b_low)+ len(lista_neutral_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder_id=1027611958.0\n",
    "\n",
    "for key in sorted(dict_folder_id_folder_attr[folder_id]):\n",
    "    print key, dict_folder_id_folder_attr[folder_id][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_all_act[ df_all_act[\"folder_id\"] == 125829122.0]   #sort_values(by=[\"user_id\",\"date\"]).head(300)\n",
    "df_all_act[ df_all_act[\"user_id\"] == 125829122.0]   #sort_values(by=[\"user_id\",\"date\"]).head(300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3488229\t2015-11-23\t2015-03-23\t864026646.0\t0.0\t0.0\t3.0\t44588732.0   x\n",
    "# 3488230\t2015-11-24\t2015-03-23\t864026646.0\t1.0\t1.0\t0.0\t44588732.0   x\n",
    "# 3488231\t2015-11-25\t2015-03-23\t864026646.0\t0.0\t1.0\t1.0\t44588732.0  x\n",
    "# 3488232\t2015-12-04\t2015-03-23\t864026646.0\t6.0\t3.0\t0.0\t44588732.0 x\n",
    "# 3488233\t2015-12-05\t2015-03-23\t864026646.0\t1.0\t0.0\t0.0\t44588732.0 x\n",
    "# 3488234\t2015-12-09\t2015-03-23\t864026646.0\t1.0\t0.0\t0.0\t44588732.0 x\n",
    "# 3488235\t2015-12-10\t2015-03-23\t864026646.0\t0.0\t1.0\t0.0\t44588732.0 x\n",
    "# 3488236\t2016-02-08\t2015-03-23\t864026646.0\t2.0\t1.0\t0.0\t44588732.0 x\n",
    "# 3488237\t2016-02-09\t2015-03-23\t864026646.0\t0.0\t0.0\t2.0\t44588732.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
