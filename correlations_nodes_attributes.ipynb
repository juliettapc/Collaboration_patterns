{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle  ##################################\n",
    "   #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "import time  \n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "##### for getting geolocation data  and to calculate distance between two geolocations\n",
    "import requests\n",
    "import json\n",
    "import geopy.distance   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/network_all_weighted_by_act_thresh1.pickle 440353 450589\n",
      "/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var_.pickle 440353\n"
     ]
    }
   ],
   "source": [
    "# path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "# input_file = 'Dropbox_datafile_complete_new_ranking.csv'\n",
    "# #input_file = 'Dropbox_datafile_may22_2017_modified_added_univ_country_geolocation_RUCC_population_density_when_available_career_stage_GINI_folder_act_categories.csv'\n",
    "# df = pd.read_csv(path+input_file, sep=';',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "# df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# print df.shape   #  1403349, 38 \n",
    "\n",
    "\n",
    "\n",
    "# ############  load the aggregated network\n",
    "# pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/network_all_new.pickle'\n",
    "# file = open(pickle_name,'r')\n",
    "# G_no_filter = pickle.load(file)\n",
    "# print \"\\n\",pickle_name, len (G_no_filter.nodes()), len(G_no_filter.edges())    #   440353 3659098\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############  load the aggregated network   filtering links by activity (if a node's activity =0, then it is not link to any other members of a folder)\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/network_all_weighted_by_act_thresh1.pickle'\n",
    "file = open(pickle_name,'r')\n",
    "G_activity = pickle.load(file)\n",
    "print \"\\n\",pickle_name, len (G_activity.nodes()), len(G_activity.edges())    #   440353 3659098\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ######## load dictionary aggregated info by user\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var_.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "     dict_user_id_user_attr = pickle.load(handle)\n",
    "print pickle_name, len(dict_user_id_user_attr.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_user_id_user_attr\n",
    "# 378535942: {'CC_filtered_by_act': 0.0,\n",
    "#   'CC_unfiltered': 1.0,\n",
    "#   'SD_fract_work_over_diff_folders': 0.0,\n",
    "#   'avg_fract_work_over_diff_folders': 0.0,\n",
    "#   'career_stage': nan,\n",
    "#   'category_total_cit': nan,\n",
    "#   'category_total_last_auth': nan,\n",
    "#   'category_total_publ': nan,\n",
    "#   'k_filtered_by_act': 0,\n",
    "#   'k_unfiltered': 11,\n",
    "#   'kshell_filtered_by_act': 0,\n",
    "#   'kshell_unfiltered': 11,did you make yours too\n",
    "#   'list_folders': [803186458],\n",
    "#   'mean_folder_lifespan': 1.0,\n",
    "#   'number_folders': 1,\n",
    "#   'user_tot_act': 0.0,\n",
    "#   'user_tot_num_adds': 0.0,\n",
    "#   'user_tot_num_deletes': 0.0,\n",
    "#   'user_tot_num_edits': 0.0,\n",
    "#   'user_univ_ranking': 281.0},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# #### if the dict is larger than G.nodes(), and the set_node_attribute does not work in that case, so i get a selection of the dict only with the common nodes:\n",
    "# new_dict_user_id = {k: dict_user_id_domain[k] for k in set(G.nodes()) & set(dict_user_id_domain.keys())}\n",
    "    \n",
    "# # i add the email as node attributes    \n",
    "# nx.set_node_attributes(G, 'email', new_dict_user_id)\n",
    "# ############\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "G= G_activity  ## or G_activity\n",
    "\n",
    "dict_node_degree={}\n",
    "dict_node_number_folders={}\n",
    "dict_node_user_tot_act={}\n",
    "dict_node_user_univ_ranking={}\n",
    "dict_node_user_career_stage={}\n",
    "dict_node_user_avg_fract_work_over_diff_folders={}\n",
    "dict_node_category_total_cit={}\n",
    "dict_node_category_total_publ={}\n",
    "dict_node_kshell_filtered_by_act={}\n",
    "dict_node_mean_folder_lifespan={}\n",
    "\n",
    "for user_id in dict_user_id_user_attr:\n",
    "    \n",
    "    dict_node_degree[user_id]=G.degree(user_id)\n",
    "    dict_node_number_folders[user_id]=dict_user_id_user_attr[user_id]['number_folders']\n",
    "    dict_node_user_tot_act[user_id]=dict_user_id_user_attr[user_id]['user_tot_act']\n",
    "    dict_node_user_univ_ranking[user_id]=dict_user_id_user_attr[user_id]['user_univ_ranking']\n",
    "    dict_node_user_career_stage[user_id]=dict_user_id_user_attr[user_id]['career_stage']\n",
    "    dict_node_user_avg_fract_work_over_diff_folders[user_id]=dict_user_id_user_attr[user_id]['avg_fract_work_over_diff_folders']\n",
    "    dict_node_category_total_cit[user_id]=dict_user_id_user_attr[user_id]['category_total_cit']\n",
    "    dict_node_category_total_publ[user_id]=dict_user_id_user_attr[user_id]['category_total_publ']\n",
    "    dict_node_kshell_filtered_by_act[user_id]=dict_user_id_user_attr[user_id]['kshell_filtered_by_act']\n",
    "    dict_node_mean_folder_lifespan[user_id]=dict_user_id_user_attr[user_id]['mean_folder_lifespan']\n",
    "    \n",
    " \n",
    "\n",
    "nx.set_node_attributes(G, 'k', dict_node_degree)\n",
    "nx.set_node_attributes(G, 'number_folders', dict_node_number_folders)\n",
    "nx.set_node_attributes(G, 'user_tot_act', dict_node_user_tot_act)\n",
    "nx.set_node_attributes(G, 'user_univ_ranking', dict_node_user_univ_ranking)\n",
    "nx.set_node_attributes(G, 'career_stage', dict_node_user_career_stage)\n",
    "nx.set_node_attributes(G, 'user_avg_fract_work_over_diff_folders', dict_node_user_avg_fract_work_over_diff_folders)\n",
    "nx.set_node_attributes(G, 'category_total_cit', dict_node_category_total_cit)\n",
    "nx.set_node_attributes(G, 'category_total_publ', dict_node_category_total_publ)\n",
    "nx.set_node_attributes(G, 'kshell_filtered_by_act', dict_node_kshell_filtered_by_act)\n",
    "nx.set_node_attributes(G, 'mean_folder_lifespan', dict_node_mean_folder_lifespan)\n",
    "\n",
    "\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\n",
      " len of list: 440353\n",
      " Size of subgraph: 440353 nodes    450589 edges   \n",
      " assortativity 0.373837539772\n",
      "\n",
      "number_folders\n",
      " len of list: 440353\n",
      " Size of subgraph: 440353 nodes    450589 edges   \n",
      " assortativity 0.103194172983\n",
      "\n",
      "user_tot_act\n",
      " len of list: 440353\n",
      " Size of subgraph: 440353 nodes    450589 edges   \n",
      " assortativity"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "list_var=['k', 'number_folders', 'user_tot_act', 'user_univ_ranking',  'career_stage',  'user_avg_fract_work_over_diff_folders',  'category_total_cit',  'category_total_publ',  'kshell_filtered_by_act', 'mean_folder_lifespan']\n",
    "for var in list_var:\n",
    "    print var\n",
    "\n",
    "    list_nodes=[]\n",
    "    for node in G.nodes(): ### i need to create lists of nodes for each variable, so i only include the nodes that have a non-nan value for that variable\n",
    "        value=G.node[node][var]\n",
    "        #print node, value\n",
    "        \n",
    "        try:\n",
    "            int(value)  # BECAUSE NAN IS A FLOAT, BUT IT CAN NOT BE CONVERTED TO INT\n",
    "            list_nodes.append(node)\n",
    "        except: pass\n",
    "            #print \"no cant do\"\n",
    "    print \" len of list:\", len(list_nodes)\n",
    "    H = G.subgraph(list_nodes)\n",
    "    print \" Size of subgraph:\",len(H.nodes()),\"nodes   \",len(H.edges()),\"edges   \"\n",
    "    print \" assortativity\", nx.attribute_assortativity_coefficient(H,var)\n",
    "    print \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df['user_id'] == 51380975]\n",
    "# df[df['folder_id'] == 216959429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# G= nx.Graph()\n",
    "# G.add_nodes_from([0,1,2,3,4],color='red')\n",
    "# G.add_nodes_from([5,6,7,8,9],color='blue')\n",
    "# G.add_edges_from([(0,9),(2,3),(3,4),(5,6),(7,8),(8,9)])\n",
    "# print(nx.attribute_assortativity_coefficient(G,'color'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
