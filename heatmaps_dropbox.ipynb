{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle  ##################################\n",
    "   #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "import time  \n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "##### for getting geolocation data  and to calculate distance between two geolocations\n",
    "import requests\n",
    "import json\n",
    "import geopy.distance   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_with_time_attr.pickle'\n",
    "#pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr_more_var.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_folder_id_folder_attr_ORIGINAL = pickle.load(handle)\n",
    "# df_folders = pd.DataFrame.from_dict(dict_folder_id_folder_attr_ORIGINAL,orient='index')\n",
    "# df_folders['folder_id'] = df_folders.index\n",
    "# print df_folders.shape   # 521274, 13\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/new_dict_user_id_user_attr.pickle'\n",
    "# with open(pickle_name, 'rb') as handle:\n",
    "#     dict_user_id_user_attr = pickle.load(handle)\n",
    "# df_users = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "# print df_users.shape   # 440353, 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act_per_day': 30.0,\n",
       " 'act_per_day_per_active_user': 10.0,\n",
       " 'act_period': 1,\n",
       " 'avg_geo_dist_km': 0.0,\n",
       " 'avg_interevent_time': nan,\n",
       " 'burstiness': nan,\n",
       " 'dominated_folder': 1,\n",
       " 'eff_num_members': 1.0,\n",
       " 'eff_num_members_by_days_present': 1.0,\n",
       " 'folder_activity_GINI': 0.6666666666666666,\n",
       " 'folder_dominator': 30.0,\n",
       " 'folder_lifespan': 1429,\n",
       " 'folder_tot_act': 30.0,\n",
       " 'folder_tot_num_adds': 30.0,\n",
       " 'folder_tot_num_dels': 0.0,\n",
       " 'folder_tot_num_edits': 0.0,\n",
       " 'folder_univ_SD_ranking': 0.0,\n",
       " 'folder_univ_mean_ranking': 196.0,\n",
       " 'folder_univ_median_ranking': 196.0,\n",
       " 'frac_simult_days_over_active_days': 0.0,\n",
       " 'frac_simult_days_overall': 0.0,\n",
       " 'fract_above_avg_contributors': nan,\n",
       " 'fraction_SR': 1.0,\n",
       " 'fraction_work_by_SR': 0.0,\n",
       " 'gini_num_days_present_over_members': 0.6666666666666666,\n",
       " 'most_common_career_stage': 'sr',\n",
       " 'most_common_categ_num_last_auth': 2.0,\n",
       " 'most_common_categ_num_publ': 3.0,\n",
       " 'most_common_num_cit': 3.0,\n",
       " 'most_common_univ_ranking': 196.0,\n",
       " 'num_above_avg_contributors': nan,\n",
       " 'num_countries': 1,\n",
       " 'num_fields': 1,\n",
       " 'num_time_stamps': 1,\n",
       " 'num_unique_projects_members_work_on': 179,\n",
       " 'num_universities': 1,\n",
       " 'number_active_members': 3,\n",
       " 'overall_num_active_days': 1,\n",
       " 'ratio_cit_publ': 1.0,\n",
       " 'std_geo_dist_km': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_folder_id_folder_attr_ORIGINAL[125829122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for folder_id in dict_folder_id_folder_attr_ORIGINAL:\n",
    "    \n",
    "    try:\n",
    "        dict_folder_id_folder_attr_ORIGINAL[folder_id]['ratio_cit_publ']=dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_num_cit'] / dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_categ_num_publ']\n",
    "        #print dict_folder_id_folder_attr_ORIGINAL[folder_id]['ratio_cit_publ'], dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_num_cit'] , dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_categ_num_publ']\n",
    "    \n",
    "    except:\n",
    "        dict_folder_id_folder_attr_ORIGINAL[folder_id]['ratio_cit_publ']=np.nan\n",
    "        #print dict_folder_id_folder_attr_ORIGINAL[folder_id]['ratio_cit_publ'], dict_folder_id_folder_attr_ORIGINAL[folder_id]\n",
    "    #raw_input()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "df_folders = pd.DataFrame.from_dict(dict_folder_id_folder_attr_ORIGINAL,orient='index')\n",
    "df_folders['folder_id'] = df_folders.index\n",
    "\n",
    "\n",
    "df_folders.to_csv(pickle_name.replace(\"dict_\",'').strip(\".pickle\")+\"_.csv\", sep=';')\n",
    "print \"written:\", pickle_name.replace(\"dict_\",\"\").strip(\".pickle\")+\"_.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for user_id in dict_user_id_user_attr:\n",
    "#     if (dict_user_id_user_attr[user_id]['burstiness'] >1.0 )  or (dict_user_id_user_attr[user_id]['burstiness'] <-1.0) :\n",
    "#         dict_user_id_user_attr[user_id]['burstiness'] = np.nan\n",
    "        \n",
    "#     if (dict_user_id_user_attr[user_id]['frac_multitasking_days_overall'] >1.0 )  or (dict_user_id_user_attr[user_id]['frac_multitasking_days_overall'] <.0) :\n",
    "#         dict_user_id_user_attr[user_id]['frac_multitasking_days_overall'] = np.nan\n",
    "        \n",
    "        \n",
    "#     if dict_user_id_user_attr[user_id]['act_period'] < 0.:\n",
    "#         dict_user_id_user_attr[user_id]['act_period'] = -1.*dict_user_id_user_attr[user_id]['act_period']\n",
    "        \n",
    "        \n",
    "#     if dict_user_id_user_attr[user_id]['avg_interevent_time'] < 0.:\n",
    "#         dict_user_id_user_attr[user_id]['avg_interevent_time'] = -1.*dict_user_id_user_attr[user_id]['avg_interevent_time']\n",
    "        \n",
    "# df_users = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "# print df_users.shape \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open(pickle_name, 'wb') as handle:\n",
    "#     pickle.dump(dict_user_id_user_attr, handle)\n",
    "# print \"written:\", pickle_name\n",
    "\n",
    "\n",
    "\n",
    "# df_users.to_csv(pickle_name.strip(\"dict_\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "# print \"written:\", pickle_name.strip(\"dict_\").strip(\".pickle\")+\".csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000    187504\n",
       "2.000000     18865\n",
       "1.333333     11988\n",
       "1.250000     11854\n",
       "1.500000     11781\n",
       "0.750000     10577\n",
       "0.800000      9636\n",
       "0.500000      9103\n",
       "0.666667      6821\n",
       "3.000000      2140\n",
       "0.333333       772\n",
       "0.600000       468\n",
       "4.000000       227\n",
       "1.666667       199\n",
       "5.000000       176\n",
       "0.250000       134\n",
       "0.400000       116\n",
       "0.200000        99\n",
       "2.500000        34\n",
       "Name: ratio_cit_publ, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_folders['ratio_cit_publ'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ratio_cit_publ (row):\n",
    "    \n",
    "    ratio=np.nan\n",
    "    \n",
    "    try:\n",
    "        ratio=row['most_common_num_cit'] / row['most_common_categ_num_publ']\n",
    "        print ratio\n",
    "        raw_input()\n",
    "    except: pass\n",
    "    \n",
    "    return ratio\n",
    "    \n",
    "    \n",
    "#############################\n",
    "df_folders['ratio_cit_publ'] = df_folders.apply (lambda row: get_ratio_cit_publ(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(df_users.burstiness.unique())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font=40\n",
    "font_ticks=20\n",
    "font_axes=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.columns\n",
    "# [u'national_ranking', u'group_num_citations', u'user_tot_act',\n",
    "#        u'email_domain', u'gini_num_days_present_over_folders', u'user_id',\n",
    "#        u'University_name', u'category_total_last_auth', u'number_folders',\n",
    "#        u'field', u'frac_multitasking_days_overall', u'user_tot_num_deletes',\n",
    "#        u'eff_num_folders_by_days_present', u'burstiness', u'group_total_publ',\n",
    "#        u'group_num_papers_last', u'Country', u'act_period',\n",
    "#        u'user_tot_num_edits', u'geoloc', u'user_tot_num_adds',\n",
    "#        u'category_total_cit', u'career_stage', u'avg_interevent_time',\n",
    "#        u'user_univ_ranking', u'gini_act_across_folders', u'eff_num_folders',\n",
    "#        u'category_total_publ', u'frac_multitasking_days_over_active_days',\n",
    "#        u'world_ranking', u'overall_num_active_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.category_total_cit.unique()\n",
    "df_selection=df_users[ (df_users['overall_num_active_days'] > 1) &  (df_users['world_ranking'] <= 100)  & (df_users['user_tot_act'] >1)]   \n",
    "print \"sample size:\",len(df_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######### ONE-VARIABLE HISTOGRAMS  BY GROUPS  user-centered\n",
    "\n",
    "# df_users.columns  \n",
    "# [u'national_ranking', u'group_num_citations', u'user_tot_act',\n",
    "#        u'email_domain', u'gini_num_days_present_over_folders', u'user_id',\n",
    "#        u'University_name', u'category_total_last_auth', u'number_folders',\n",
    "#        u'field', u'frac_multitasking_days_overall', u'user_tot_num_deletes',\n",
    "#        u'eff_num_folders_by_days_present', u'burstiness', u'group_total_publ',\n",
    "#        u'group_num_papers_last', u'Country', u'act_period',\n",
    "#        u'user_tot_num_edits', u'geoloc', u'user_tot_num_adds',\n",
    "#        u'category_total_cit', u'career_stage', u'avg_interevent_time',\n",
    "#        u'user_univ_ranking', u'gini_act_across_folders', u'eff_num_folders',\n",
    "#        u'category_total_publ', u'frac_multitasking_days_over_active_days',\n",
    "#        u'world_ranking', u'overall_num_active_days']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # sr: 18261    jr: 13202\n",
    "#df_selection=df_users[df_users['overall_num_active_days'] > 1]  \n",
    "df_selection=df_users[ (df_users['overall_num_active_days'] > 1) &  (df_users['world_ranking'] <= 100)  & (df_users['user_tot_act'] >1)]   \n",
    "print \"sample size:\",len(df_selection)\n",
    "###if i do selection == srs only, then most of them have higher cit category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_selection_high=df_selection[df_selection['category_total_publ'] >= 4.]    \n",
    "df_selection_low=df_selection[df_selection['category_total_publ'] <= 2.]    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \" num. users in high cat.:\", len(df_selection_high), \" num. users in low cat.:\", len(df_selection_low)\n",
    "print\n",
    "\n",
    "\n",
    "list_variables=['gini_num_days_present_over_folders','avg_interevent_time','gini_act_across_folders',\\\n",
    "                'eff_num_folders','frac_multitasking_days_over_active_days','world_ranking', 'overall_num_active_days','category_total_last_auth']\n",
    "\n",
    "list_var_in_log=['user_tot_act','number_folders','frac_multitasking_days_overall','eff_num_folders_by_days_present', 'burstiness','act_period']\n",
    "\n",
    "\n",
    "for v1_string in list_variables:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print \"avg\", v1_string, \"for high:\",df_selection_high[v1_string].mean(),  \"   low:\",df_selection_low[v1_string].mean()#,  df_select_top3[\"folder_lifespan\"].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    x1 = df_selection_high[v1_string]\n",
    "    x2 = df_selection_low[v1_string]\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "    print \"KS test 2-sample:\",  scipy.stats.ks_2samp(x1,x2)\n",
    "    # a= df_users[v1_string].dropna()\n",
    "    # sample1=np.random.choice(a, size=len(x1), replace=True)\n",
    "    # sample2=np.random.choice(a, size=len(x2), replace=True)\n",
    "    # print \"KS test 2-sample for random samples:\",  scipy.stats.ks_2samp(sample1,sample2)\n",
    "\n",
    "\n",
    "\n",
    "    trace1= Histogram(\n",
    "            x=x1, \n",
    "            name='high cit',\n",
    "           histnorm='probability',\n",
    "        #cumulative=dict(enabled=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    trace2= Histogram(\n",
    "            x=x2, \n",
    "            name='low cit',\n",
    "           histnorm='probability',\n",
    "        #cumulative=dict(enabled=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    # trace3= Histogram(\n",
    "    #         x=x3, \n",
    "    #         name=' top > 50',\n",
    "    #         histnorm='probability'\n",
    "    # )\n",
    "\n",
    "\n",
    "    layout = Layout(    \n",
    "\n",
    "       # bargap=0.2,\n",
    "\n",
    "\n",
    "\n",
    "        xaxis=dict(\n",
    "            title=v1_string.replace(\"_\",\" \"),   #\"User's university national ranking\",\n",
    "            titlefont=dict(\n",
    "                family=font,#family='Arial, sans-serif',\n",
    "                size=font_axes,\n",
    "                color='black'\n",
    "            #    color='lightgrey'\n",
    "            ),  \n",
    "            tickfont=dict(   \n",
    "                family=font,\n",
    "                size=font_ticks,\n",
    "                color='black'\n",
    "            ),\n",
    "            #type='log'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='pdf',\n",
    "            type='log',\n",
    "            titlefont=dict(\n",
    "                family=font,#family='Arial, sans-serif',\n",
    "                size=font_axes,\n",
    "                color='black'\n",
    "            #    color='lightgrey'\n",
    "            ),  \n",
    "            tickfont=dict(   \n",
    "                family=font,\n",
    "                size=font_ticks,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     bargroupgap=0.1\n",
    "    )       \n",
    "\n",
    "    data = [trace1, trace2]#, trace3]\n",
    "\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "\n",
    "    iplot(fig, filename='histogram_'+v1_string+'_by_high_low_cit.html')\n",
    "    #offline.plot(fig, filename='/home/juliaponcela/histogram_'+v1_string+'_by_groups.html')\n",
    "\n",
    "    offline.plot(fig, auto_open=True, image = 'png', image_filename=\"histogram_\"+v1_string+\"_by_groups\" ,\n",
    "                 output_type='file', image_width=1600, image_height=1200, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/histogram_for_users_'+v1_string+'_by_high_low_cit.html', validate=False)\n",
    "\n",
    "\n",
    "\n",
    "    raw_input()\n",
    "    \n",
    "    \n",
    "########### DIFFERENCES FOR CATEGORIES HIGH/LOW FOR NUMBER OF CITATIONS:\n",
    "# sample size: 68973\n",
    "#  num. users in high cat.: 4730  num. users in low cat.: 4016\n",
    "\n",
    "\n",
    "\n",
    "# avg gini_num_days_present_over_folders for high: 0.7168503002    low: 0.71660106302\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.02715922778231683, pvalue=0.07982694523426008)\n",
    "    \n",
    "    \n",
    "# avg avg_interevent_time for high: 13.8782242439    low: 14.6029049486\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.022476689436756125, pvalue=0.21997291239987324)\n",
    "    \n",
    "    \n",
    "# avg gini_act_across_folders for high: 0.780679780661    low: 0.779065931073\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.018171078897938897, pvalue=0.46673713569880609)\n",
    "    \n",
    "\n",
    "##### avg eff_num_folders for high: 3.1107318149    low: 2.8690792351\n",
    "#### KS test 2-sample: Ks_2sampResult(statistic=0.039958980147065004, pvalue=0.0018748193415143448)\n",
    "    \n",
    "    \n",
    "# avg frac_multitasking_days_over_active_days for high: 0.0879148238142    low: 0.0835148298419\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.029321403603345564, pvalue=0.046835732326722557)\n",
    "    \n",
    "    \n",
    "#### avg world_ranking for high: 32.4084566596    low: 34.6964641434\n",
    "#### KS test 2-sample: Ks_2sampResult(statistic=0.054883110265070756, pvalue=3.8786655060788129e-06)  \n",
    "    \n",
    "\n",
    "#### avg overall_num_active_days for high: 74.4308668076    low: 66.2303286853\n",
    "#### KS test 2-sample: Ks_2sampResult(statistic=0.036826478441414068, pvalue=0.0053593143219811332)\n",
    "\n",
    "\n",
    "#### avg user_tot_act for high: 8848.10591966    low: 7560.76743028\n",
    "#### KS test 2-sample: Ks_2sampResult(statistic=0.048087459885616135, pvalue=8.2359590241010448e-05)\n",
    "    \n",
    "    \n",
    "#### avg number_folders for high: 18.6492600423    low: 17.4422310757\n",
    "#### KS test 2-sample: Ks_2sampResult(statistic=0.035218639185330636, pvalue=0.0088876326480917932)\n",
    "    \n",
    "    \n",
    "### avg eff_num_folders_by_days_present for high: 4.7694875164    low: 4.36293294818\n",
    "### KS test 2-sample: Ks_2sampResult(statistic=0.046208401068032368, pvalue=0.00017854105907213685)\n",
    "    \n",
    "    \n",
    "# avg burstiness for high: 0.577776628598    low: 0.565997654232\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.031125603295064974, pvalue=0.029091064726796224)\n",
    "    \n",
    "    \n",
    "# avg act_period for high: 141.637632135    low: 139.534611554\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.011206758589321297, pvalue=0.94677583728353398)    \n",
    "\n",
    "\n",
    "# avg frac_multitasking_days_overall for high: 0.063266200764    low: 0.0577059851689\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.0085575246582380859, pvalue=0.99720631768752099)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " #######################################################   \n",
    "#######################################################    \n",
    "\n",
    "########### DIFFERENCES FOR CATEGORIES HIGH/LOW FOR NUMBER OF PUBLICATIONS:\n",
    "\n",
    "# sample size: 68973\n",
    "#  num. users in high cat.: 4686  num. users in low cat.: 4109\n",
    "\n",
    "# avg user_tot_act for high: 8374.02795561    low: 8717.82428815\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.025195569680537377, pvalue=0.12230605480930659)\n",
    "    \n",
    "    \n",
    "# avg number_folders for high: 18.5401195049    low: 17.9603309808\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.019502903539662442, pvalue=0.37245814791707144)\n",
    "    \n",
    "    \n",
    "# avg frac_multitasking_days_overall for high: 0.060319481759    low: 0.0647849707383\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.0041269765098255751, pvalue=0.99999999999993439)\n",
    "    \n",
    "    \n",
    "\n",
    "# avg eff_num_folders_by_days_present for high: 4.74024690741    low: 4.4725198334\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.030452291987431268, pvalue=0.033757402128963117)\n",
    "    \n",
    "    \n",
    "# avg burstiness for high: 0.575735381811    low: 0.576828923315\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.015641835110606905, pvalue=0.65449031363574328)\n",
    "    \n",
    "    \n",
    "# avg act_period for high: 138.566794708    low: 143.426137746\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.014007954598688088, pvalue=0.78086591659952331)\n",
    "\n",
    "\n",
    "# avg gini_num_days_present_over_folders for high: 0.717663358412    low: 0.719105191799\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.020969812473519589, pvalue=0.28783985574855403)\n",
    "    \n",
    "#  avg avg_interevent_time for high: 13.8486794626    low: 14.3566844475\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.016771425102159121, pvalue=0.56578747198252421)\n",
    "    \n",
    "    \n",
    "# avg gini_act_across_folders for high: 0.782419459893    low: 0.781067109956\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.016806637148792297, pvalue=0.56306735103317307)\n",
    "    \n",
    " \n",
    "# avg eff_num_folders for high: 3.08578884767    low: 2.94446553222\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.022378502079536289, pvalue=0.22036780461617247)\n",
    "\n",
    "\n",
    "    \n",
    "#   avg frac_multitasking_days_over_active_days for high: 0.0866308574264    low: 0.0876436496511\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.012099388961927082, pvalue=0.90405429330926101)  \n",
    "    \n",
    "    \n",
    "    \n",
    "####  avg world_ranking for high: 32.865130175    low: 35.0472134339\n",
    "#### KS test 2-sample: Ks_2sampResult(statistic=0.049518368795188117, pvalue=4.1094410211322548e-05)\n",
    "    \n",
    "    \n",
    "    \n",
    "# avg overall_num_active_days for high: 72.2089201878    low: 71.6957897299\n",
    "# KS test 2-sample: Ks_2sampResult(statistic=0.011959163997458555, pvalue=0.91131283641270711)   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders.columns\n",
    "\n",
    "\n",
    "pd.value_counts(df_folders['ratio_cit_publ'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_selection=df_folders[ (df_folders['num_time_stamps'] > 1) &  (df_folders['most_common_univ_ranking'] <= 100)  & (df_folders['folder_tot_act'] >1)  & (df_folders['number_active_members'] >=2)]   \n",
    "# print \"sample size:\",len(df_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 94481\n",
      " num. folders in high ratio cit/publ: 12822  num. folders in low ratio cit/publ: 7289\n",
      "\n",
      "< act_per_day >   for high: 23.9613342239    low: 16.5892581003      all: 28.3903969201\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.046667393826108183, pvalue=3.0114442850475638e-09)\n",
      "\n",
      "< act_per_day_per_active_user >   for high: 8.12973132414    low: 5.58618162848      all: 9.50484693205\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.054818117158225821, pvalue=1.3425868224513657e-12)\n",
      "\n",
      "< act_period >   for high: 270.629075027    low: 257.328577308      all: 262.121135466\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.027444886910336086, pvalue=0.0017774473155275109)\n",
      "\n",
      "< avg_geo_dist_km >   for high: 956.839889482    low: 1125.17746169      all: 1006.2242261\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.040350383424668013, pvalue=5.0760756847063421e-07)\n",
      "\n",
      "< avg_interevent_time >   for high: 28.9728364539    low: 30.6868137497      all: 28.9501210557\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.041561463408590071, pvalue=2.0121974907178156e-07)\n",
      "\n",
      "< burstiness >   for high: 0.124021921138    low: 0.105764222973      all: 0.11790134612\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.025492566528080518, pvalue=0.0046608135347775709)\n",
      "\n",
      "< dominated_folder >   for high: 0.937217282795    low: 0.934010152284      all: 0.935161566876\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.0032071305109317993, pvalue=0.99999999992248401)\n",
      "\n",
      "< eff_num_members >   for high: 1.54851690071    low: 1.56285622063      all: 1.55705282083\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.026973174857086279, pvalue=0.0022583028526130663)\n",
      "\n",
      "< eff_num_members_by_days_present >   for high: 1.88025985396    low: 1.89008205422      all: 1.86683696019\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.027986308259664583, pvalue=0.0013434525629757279)\n",
      "\n",
      "< folder_activity_GINI >   for high: 0.553835720399    low: 0.5586663666      all: 0.546698317728\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.026294967070141673, pvalue=0.0031632160086158077)\n",
      "\n",
      "< folder_lifespan >   for high: 556.810559975    low: 519.485937714      all: 528.727426678\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.037414546728329223, pvalue=4.2694455958933145e-06)\n",
      "\n",
      "< folder_tot_act >   for high: 5025.12689128    low: 3260.17409796      all: 4323.66106413\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.060117949626939171, pvalue=4.5747124810791586e-15)\n",
      "\n",
      "< folder_univ_SD_ranking >   for high: 22.1069776955    low: 25.1173384187      all: 22.0241662401\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.028575932276504012, pvalue=0.00098428907873283509)\n",
      "\n",
      "< folder_univ_mean_ranking >   for high: 46.5124228394    low: 50.0791879989      all: 49.19352822\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.053028787061030203, pvalue=8.121970008221109e-12)\n",
      "\n",
      "< folder_univ_median_ranking >   for high: 39.2101856185    low: 41.8269995884      all: 42.269927287\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.046458726029926289, pvalue=3.6098887027399037e-09)\n",
      "\n",
      "< frac_simult_days_over_active_days >   for high: 0.100725399653    low: 0.0917951535887      all: 0.0983197098738\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.038151828195036042, pvalue=2.5391034091626769e-06)\n",
      "\n",
      "< frac_simult_days_overall >   for high: 0.0356763021333    low: 0.0329593392823      all: 0.0346107914261\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.038151828195036042, pvalue=2.5391034091626769e-06)\n",
      "\n",
      "< fraction_SR >   for high: 0.537686172804    low: 0.764810166587      all: 0.610142317007\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.2587994156788116, pvalue=9.609951882308096e-272)\n",
      "\n",
      "< fraction_work_by_SR >   for high: 0.400183527753    low: 0.419869931175      all: 0.385567488045\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.19867471446847629, pvalue=2.5409025979038658e-160)\n",
      "\n",
      "< gini_num_days_present_over_members >   for high: 0.487202760187    low: 0.498201476281      all: 0.484346988163\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.03151256075916814, pvalue=0.00018980559739517066)\n",
      "\n",
      "< most_common_univ_ranking >   for high: 32.5437529247    low: 33.3863355742      all: 34.7302103068\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.037142033134802466, pvalue=5.1603192256038237e-06)\n",
      "\n",
      "< num_countries >   for high: 1.16799251287    low: 1.24873096447      all: 1.176924461\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.044712398490050709, pvalue=1.5938883610084189e-08)\n",
      "\n",
      "< num_fields >   for high: 1.12384963344    low: 1.1417204006      all: 1.10271673601\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.013756410018545107, pvalue=0.34061029143788923)\n",
      "\n",
      "< num_time_stamps >   for high: 33.2002027765    low: 27.9592536699      all: 31.1128269176\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.042088611204431303, pvalue=1.3336500930696605e-07)\n",
      "\n",
      "< num_unique_projects_members_work_on >   for high: 55.0471065356    low: 49.0691452874      all: 50.8107767699\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.076538367536469698, pvalue=3.7180082985981381e-24)\n",
      "\n",
      "< num_universities >   for high: 1.93401965372    low: 2.17107970915      all: 1.88616758925\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.037746711791639354, pvalue=3.3824914583901175e-06)\n",
      "\n",
      "< number_active_members >   for high: 4.27031664327    low: 4.49115104953      all: 4.15914310814\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.019124229113088642, pvalue=0.065985797886473518)\n",
      "\n",
      "< overall_num_active_days >   for high: 27.9337076899    low: 23.7607353546      all: 26.2471819731\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.041333161451501899, pvalue=2.4006789366337777e-07)\n",
      "\n",
      "< std_geo_dist_km >   for high: 444.134030902    low: 541.913489656      all: 457.401092721\n",
      "KS test 2-sample: Ks_2sampResult(statistic=0.030914976079814194, pvalue=0.00026880118735683837)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######### ONE-VARIABLE HISTOGRAMS  BY GROUPS  folder-centered\n",
    "\n",
    "# df_folders.columns  \n",
    "# [u'frac_simult_days_over_active_days', u'most_common_categ_num_publ',\n",
    "#        u'num_unique_projects_members_work_on', u'num_fields',\n",
    "#        u'avg_geo_dist_km', u'most_common_categ_num_last_auth',\n",
    "#        u'folder_univ_median_ranking', u'eff_num_members_by_days_present',\n",
    "#        u'num_above_avg_contributors', u'gini_num_days_present_over_members',\n",
    "#        u'frac_simult_days_ove rall', u'folder_dominator',\n",
    "#        u'avg_interevent_time', u'most_common_career_stage',\n",
    "#        u'folder_activity_GINI', u'act_per_day_per_active_user',\n",
    "#        u'num_universities', u'act_per_day', u'folder_univ_mean_ranking',\n",
    "#        u'num_countries', u'burstiness', u'eff_num_members', u'folder_lifespan',\n",
    "#        u'act_period', u'folder_univ_SD_ranking', u'dominated_folder',\n",
    "#        u'fraction_work_by_SR', u'fract_above_avg_contributors',\n",
    "#        u'most_common_univ_ranking', u'folder_tot_act', u'folder_tot_num_edits',\n",
    "#        u'std_geo_dist_km', u'fraction_SR', u'most_common_num_cit',\n",
    "#        u'number_active_members', u'overall_num_active_days',\n",
    "#        u'folder_tot_num_adds', u'num_time_stamps', u'folder_tot_num_dels',\n",
    "#        u'folder_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flag_var_for_groups='ratio_cit_publ'  ######  'cit' # or  \"publ\"  or \"ratio_cit_publ\"\n",
    "\n",
    "\n",
    " # sr: 18261    jr: 13202\n",
    " \n",
    "df_selection=df_folders[ (df_folders['num_time_stamps'] > 1) &  (df_folders['most_common_univ_ranking'] <= 100)  & (df_folders['folder_tot_act'] >1) \\\n",
    "                        & (df_folders['number_active_members'] >=2) ]#    &  (df_folders['ratio_cit_publ'] < 1.)  ]  \n",
    " \n",
    "\n",
    "\n",
    "print \"sample size:\",len(df_selection)\n",
    "###if i do selection == srs only, then most of them have higher cit category\n",
    "\n",
    "\n",
    "\n",
    "##'most_common_categ_num_publ'   'most_common_categ_num_last_auth',  'most_common_num_cit'\n",
    "\n",
    "\n",
    "if flag_var_for_groups=='cit' :\n",
    "    df_selection_high=df_selection[df_selection['most_common_num_cit'] >= 4.]    \n",
    "    df_selection_low=df_selection[df_selection['most_common_num_cit'] <= 2.]    \n",
    "\n",
    "    print \" num. folders in high cat. cit:\", len(df_selection_high), \" num. folders in low cat. cit:\", len(df_selection_low)\n",
    "    print\n",
    "    \n",
    "    label_high=\"high citations\"\n",
    "    label_low=\"low citations\"\n",
    "    \n",
    "elif flag_var_for_groups=='publ' :\n",
    "    df_selection_high=df_selection[df_selection['most_common_categ_num_publ'] >= 4.]    \n",
    "    df_selection_low=df_selection[df_selection['most_common_categ_num_publ'] <= 2.]    \n",
    "\n",
    "    print \" num. folders in high cat. publ:\", len(df_selection_high), \" num. folders in low cat. publ:\", len(df_selection_low)\n",
    "    print\n",
    "\n",
    "    label_high=\"high publications\"\n",
    "    label_low=\"low publications\"\n",
    "    \n",
    "    \n",
    "    \n",
    "elif flag_var_for_groups=='ratio_cit_publ' :\n",
    "    df_selection_high=df_selection[df_selection['ratio_cit_publ'] > 1.]    \n",
    "    df_selection_low=df_selection[df_selection['ratio_cit_publ'] < 1.]    \n",
    "\n",
    "    print \" num. folders in high ratio cit/publ:\", len(df_selection_high), \" num. folders in low ratio cit/publ:\", len(df_selection_low)\n",
    "    print\n",
    "\n",
    "    label_high=\"high ratio cit/publ\"\n",
    "    label_low=\"low ratio cit/publ\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "list_variables=['frac_simult_days_over_active_days', 'num_unique_projects_members_work_on',   'folder_activity_GINI',\\\n",
    "                'act_per_day_per_active_user','num_fields', 'avg_geo_dist_km', 'folder_univ_median_ranking', \\\n",
    "                 'eff_num_members_by_days_present', 'gini_num_days_present_over_members', 'frac_simult_days_overall', \\\n",
    "                'avg_interevent_time', 'num_universities', 'act_per_day', 'folder_univ_mean_ranking',\\\n",
    "                 'num_countries', 'burstiness',  'eff_num_members', 'folder_lifespan', 'act_period', 'folder_univ_SD_ranking', \\\n",
    "                'dominated_folder', 'fraction_work_by_SR', 'most_common_univ_ranking', 'folder_tot_act', 'std_geo_dist_km', \\\n",
    "                'fraction_SR', 'number_active_members', 'overall_num_active_days', 'num_time_stamps']                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "  \n",
    "               \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "for v1_string in sorted(list_variables):\n",
    "\n",
    "\n",
    "    print \"<\", v1_string, \">   for high:\",df_selection_high[v1_string].mean(),  \"   low:\",df_selection_low[v1_string].mean(), \"     all:\", df_selection[v1_string].mean()  \n",
    "\n",
    "\n",
    "    x1 = df_selection_high[v1_string]\n",
    "    x2 = df_selection_low[v1_string]\n",
    "   \n",
    "   \n",
    "\n",
    "    print \"KS test 2-sample:\",  scipy.stats.ks_2samp(x1,x2)\n",
    "    # a= df_users[v1_string].dropna()\n",
    "    # sample1=np.random.choice(a, size=len(x1), replace=True)\n",
    "    # sample2=np.random.choice(a, size=len(x2), replace=True)\n",
    "    # print \"KS test 2-sample for random samples:\",  scipy.stats.ks_2samp(sample1,sample2)\n",
    "\n",
    "    print\n",
    "\n",
    "    trace1= Histogram(\n",
    "            x=x1, \n",
    "            name=label_high,\n",
    "           histnorm='probability',\n",
    "        #cumulative=dict(enabled=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    trace2= Histogram(\n",
    "            x=x2, \n",
    "            name=label_low,\n",
    "           histnorm='probability',\n",
    "        #cumulative=dict(enabled=True)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    layout = Layout(    \n",
    "         xaxis=dict(\n",
    "            title=v1_string.replace(\"_\",\" \"),   \n",
    "            titlefont=dict(\n",
    "                family=font,#family='Arial, sans-serif',\n",
    "                size=font_axes,\n",
    "                color='black'\n",
    "            #    color='lightgrey'\n",
    "            ),  \n",
    "            tickfont=dict(   \n",
    "                family=font,\n",
    "                size=font_ticks,\n",
    "                color='black'\n",
    "            ),\n",
    "            #type='log'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='pdf',\n",
    "            type='log',\n",
    "            titlefont=dict(\n",
    "                family=font,#family='Arial, sans-serif',\n",
    "                size=font_axes,\n",
    "                color='black'\n",
    "            #    color='lightgrey'\n",
    "            ),  \n",
    "            tickfont=dict(   \n",
    "                family=font,\n",
    "                size=font_ticks,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),                \n",
    "\n",
    "\n",
    "    )       \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     data = [trace1, trace2]\n",
    "#     fig = Figure(data=data, layout=layout)\n",
    "\n",
    "#     iplot(fig, filename=\"histogram_for_folders_\"+v1_string+\"_by_high_low_publ.html\")\n",
    "    \n",
    "#     offline.plot(fig, auto_open=True, image = 'png', image_filename=\"histogram_for_folders_\"+v1_string+\"_by_high_low_publ\" ,\n",
    "#                  output_type='file', image_width=1600, image_height=1200, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/histogram_for_folders_'\\\n",
    "#                  +v1_string+'_by_high_low_publ.html', validate=False)\n",
    "\n",
    "\n",
    "\n",
    "#     raw_input()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(df_folders.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_folders.columns\n",
    "\n",
    "#       [u'folder_id', u'avg_num_common_prjt', u'most_common_categ_num_publ',\n",
    "#        u'most_common_categ_num_last_auth', u'fract_pairs_multipl_prjts',\n",
    "#        u'num_folder_members', u'most_common_career_stage',\n",
    "#        u'folder_activity_GINI', u'folder_univ_median_ranking',\n",
    "#        u'max_num_common_prjt', u'folder_tot_num_deletes', u'num_countries',\n",
    "#        u'flag_common_prjt', u'folder_lifespan', u'multi_univ_collab',\n",
    "#        u'folder_univ_SD_rank[u'folder_id', u'avg_num_common_prjt', u'most_common_categ_num_publ',\n",
    "#        u'most_common_categ_num_last_auth', u'fract_pairs_multipl_prjts',\n",
    "#        u'num_folder_members', u'most_common_career_stage',\n",
    "#        u'folder_activity_GINI', u'folder_univ_median_ranking',\n",
    "#        u'max_num_common_prjt', u'folder_tot_num_deletes', u'num_countries',\n",
    "#        u'flag_common_prjt', u'folder_lifespan', u'multi_univ_collab',\n",
    "#        u'folder_univ_SD_ranking', u'fraction_work_by_SR',\n",
    "#        u'most_common_univ_ranking', u'folder_tot_act', u'folder_tot_num_edits',\n",
    "#        u'fraction_SR', u'most_common_num_cit', u'number_active_members',\n",
    "#        u'list_ranking', u'folder_tot_num_adds']ing', u'fraction_work_by_SR',\n",
    "#        u'most_common_univ_ranking', u'folder_tot_act', u'folder_tot_num_edits',\n",
    "#        u'fraction_SR', u'most_common_num_cit', u'number_active_members',\n",
    "#        u'list_ranking', u'folder_tot_num_adds']\n",
    "\n",
    "\n",
    "#df_users.columns\n",
    "#       [u'mean_folder_lifespan', u'category_total_publ',\n",
    "#        u'category_total_last_auth', u'user_tot_num_edits', u'number_folders',\n",
    "#        u'user_tot_num_adds', u'user_tot_act', u'career_stage',\n",
    "#        u'user_tot_num_deletes', u'category_total_cit', u'user_univ_ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_folders=df_folders.drop('most_common_career_stage', axis=1)\n",
    "# df_folders=df_folders.drop('list_ranking', axis=1)\n",
    "# df_folders['most_common_career_stage'].unique()\n",
    "\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_career_stage_folder(row):\n",
    "    \n",
    "   \n",
    "    career=row['most_common_career_stage']\n",
    "    \n",
    "    if career ==\"sr\":\n",
    "        return 1.\n",
    "    elif career ==\"jr\":\n",
    "        return 0.\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "%time df_folders['most_common_career_stage_'] = df_folders.apply (lambda row: get_career_stage_folder(row),axis=1)\n",
    "\n",
    "###################################\n",
    "\n",
    "\n",
    "def get_career_stage_user(row):\n",
    "    \n",
    "   \n",
    "    career=row['career_stage']\n",
    "    \n",
    "    if career ==\"sr\":\n",
    "        return 1.\n",
    "    elif career ==\"jr\":\n",
    "        return 0.\n",
    "    else:\n",
    "        return np.nan\n",
    "%time df_users['career_stage_'] = df_users.apply (lambda row: get_career_stage_user(row),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "def num_folders_above_avg(row):\n",
    "    \n",
    "   \n",
    "   \n",
    "    dicc=row['folders_above_avg']  # it is a dict    {95727106.0: 0, 938404357.0: 0, 271750151.0: 0...\n",
    "   \n",
    "    \n",
    "    suma=sum(dicc.values())\n",
    "    \n",
    "    \n",
    "    \n",
    "    return suma\n",
    "\n",
    "%time df_users['num_folders_user_works_above_avg'] = df_users.apply (lambda row: num_folders_above_avg(row),axis=1)\n",
    "\n",
    "\n",
    "##############\n",
    "\n",
    "\n",
    "def fract_folders_above_avg(row):       \n",
    "   \n",
    "    dicc=row['folders_above_avg']  # it is a dict    {95727106.0: 0, 938404357.0: 0, 271750151.0: 0...\n",
    "    \n",
    "    \n",
    "    fract=sum(dicc.values())/float(len(dicc))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fract\n",
    "\n",
    "%time df_users['fract_folders_user_works_above_avg'] = df_users.apply (lambda row: fract_folders_above_avg(row),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_folders[[\"most_common_career_stage_\",\"most_common_career_stage\"]].head(200)\n",
    "df_users[[\"folders_above_avg\",\"num_folders_user_works_above_avg\",\"fract_folders_user_works_above_avg\"]].head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for folder_id in dict_folder_id_folder_attr_ORIGINAL:\n",
    "    \n",
    "    career=dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_career_stage']\n",
    "    \n",
    "    if career ==\"sr\":\n",
    "        dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_career_stage_']=1.\n",
    "    elif career ==\"jr\":\n",
    "        dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_career_stage_']=0.\n",
    "    else:\n",
    "        dict_folder_id_folder_attr_ORIGINAL[folder_id]['most_common_career_stage_']= np.nan\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# for c in lista_c:\n",
    "#     print \"avg\", c, df_folders[c].mean()#, \"   SD:\", df_folders[c].std()\n",
    "    \n",
    "#  df_folders['avg_num_common_prjt'].mean()  4.3345286339492795       \n",
    "#     df_folders['most_common_categ_num_publ'].mean()     2.9017439403543723\n",
    " \n",
    "#df_folders['most_common_categ_num_last_auth'].mean()     2.3970652600440703   \n",
    "#    df_folders['fract_pairs_multipl_prjts'].mean()   0.5183679192565429 \n",
    "  \n",
    "    \n",
    "\n",
    "# avg_num_common_prjt 4.33452863395\n",
    "# most_common_categ_num_publ 2.90174394035\n",
    "# most_common_categ_num_last_auth 2.39706526004\n",
    "# fract_pairs_multipl_prjts 0.518367919257\n",
    "# num_folder_members 4.51193997782    \n",
    "    \n",
    "print \"folders:\",df_folders.shape    \n",
    "print \n",
    "for c in sorted(df_folders.columns):  \n",
    "    try:\n",
    "        print c, df_folders[c].mean(), df_folders[c].std()   \n",
    "#     raw_input()\n",
    "    except TypeError:\n",
    "        print \"  -----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sorted(df_users.Country.unique())\n",
    "df_users[df_users[\"Country\"] ==  'United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_columns=[ 'career_stage_', 'category_total_cit', 'category_total_last_auth', 'category_total_publ', 'eff_num_folders',\\\n",
    "              'fract_folders_user_works_above_avg', 'gini_act_across_folders', 'national_ranking', 'number_folders', \\\n",
    "              'user_tot_act', 'user_tot_num_adds', 'user_tot_num_deletes', 'user_tot_num_edits', 'user_univ_ranking', 'world_ranking'] \n",
    "print \"users:\", df_users.shape\n",
    "print \n",
    "# for c in sorted(df_users.columns):  \n",
    "for c in sorted(list_columns):\n",
    "    try:\n",
    "        print c, df_users[c].mean()   \n",
    "#     raw_input()\n",
    "    except TypeError:\n",
    "        print \"  -----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders_select=df_folders[(df_folders['act_period']>=30) & (df_folders['num_time_stamps']>=5) ]\n",
    "\n",
    "print df_folders_select.shape\n",
    "for c in sorted(df_folders_select.columns):  \n",
    "    try:\n",
    "        print c, df_folders_select[c].mean()   \n",
    "#     raw_input()\n",
    "    except TypeError:\n",
    "        print \"  -----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_nans(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass            \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "############################3\n",
    "\n",
    "\n",
    "\n",
    "def remove_nans_for_strings(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "             aux_lista.append(lista[i])#pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "\n",
    "def remove_nans_replace_by_zeros(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                aux_lista.append(0.)        #pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(float(lista[i]))\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### get dict with  folder_id lifespan:\n",
    "def remove_nans_replace_intervals_with_starting_value(lista):\n",
    "    #print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when/ nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "        except TypeError: # (when not-nan):\n",
    "            #print lista[i]   \n",
    "            try:  \n",
    "                aux_lista.append(float(lista[i]))\n",
    "                #print \"no problem\"\n",
    "            except ValueError:  # sometimes, the ranking is 75-82\n",
    "                #print \"issue found\"\n",
    "                value=lista[i]\n",
    "#                 v1=float(value.split(\"-\")[0])\n",
    "#                 v2=float(value.split(\"-\")[1])\n",
    "                \n",
    "                new_value=float(value.split(\"-\")[0])#np.median([v1,v2])  \n",
    "                aux_lista.append(new_value)\n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "\n",
    "\n",
    "def gini(old_list_of_values):\n",
    "    \n",
    "    list_of_values=[]\n",
    "    for item in old_list_of_values:\n",
    "        try:\n",
    "            int(item) # if it is a NAN, it with fail\n",
    "            list_of_values.append(item)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "   # print list_of_values\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    try:\n",
    "        return (fair_area - area) / fair_area\n",
    "    except ZeroDivisionError:\n",
    "#         print \"problems with:\",list_of_values   # if lista=[0,0,0]  or [0]\n",
    "#         raw_input()\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "##############\n",
    "\n",
    "\n",
    "def  effective_num(lista_values):  # i can use it for the effective number of members in a folder, by activity, or the effective number of folders for a user, also by activity\n",
    "    \n",
    "     # first, i need to remove the zeros, because i cant do the log(0), but i can remove them, they dont count as effective members\n",
    "    \n",
    "    \n",
    "    cont_num_nonzero_items=0\n",
    "    H=0.\n",
    "    tot_sum=float(sum(lista_values))\n",
    "    for item in lista_values:\n",
    "        if item >0:\n",
    "            aux= item/tot_sum * np.log2( item/tot_sum)\n",
    "            H += aux\n",
    "            cont_num_nonzero_items +=1\n",
    "            \n",
    "    H = -1.0 * H\n",
    "    \n",
    "    eff_number = np.power(2.0, H)\n",
    "    \n",
    "    if cont_num_nonzero_items ==0:   # if the list of act is [0] then i want the eff. number to be 0, not 1\n",
    "        eff_number =0\n",
    "    \n",
    "    return eff_number\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## getting stats for Rebecca:\n",
    "\n",
    "# i get the ranking quantiles\n",
    "\n",
    "lista_ranking_values = df_folders['folder_univ_median_ranking'].dropna().tolist()   # sorted(df_folders.folder_univ_median_ranking)\n",
    "\n",
    "print np.mean(lista_ranking_values), df_folders.folder_univ_median_ranking.dropna().quantile(q=0.9) #  q=10: 8,   q=25: 19,   q=50: 53,  q=75:  164,   q=90:  271  \n",
    "\n",
    "df_selection_folder2=df_folders[df_folders['folder_univ_median_ranking'] >= 271]\n",
    "print df_selection_folder2.shape\n",
    "\n",
    "    \n",
    "for c in df_selection_folder2.columns:  \n",
    "     print c, df_selection_folder2[c].mean(skipna=True)  , df_selection_folder2[c].std(skipna=True)    \n",
    "     raw_input()\n",
    "\n",
    "\n",
    "# df_selection_folder3=df_folders[ df_folders['folder_lifespan'] >1]\n",
    "# print df_selection_folder3.shape\n",
    "\n",
    "# df_selection_folder4=df_folders[ df_folders['number_active_members'] >1]\n",
    "# print df_selection_folder4.shape\n",
    "\n",
    "# df_selection_folder5=df_folders[ (df_folders['number_active_members'] >1)  &  (df_folders['folder_lifespan'] >1) ]\n",
    "# print df_selection_folder5.shape\n",
    "\n",
    "print \"done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "font=40\n",
    "font_ticks=20\n",
    "font_axes=20\n",
    "\n",
    "#dict_int_ranking_bin_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders['act_period'].quantile([.1,.25, .5, .65, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders['num_time_stamps'].quantile([.1,.25, .5, .65, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(dict_folder_id_folder_attr_ORIGINAL[125829122.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### i pre-select the folders with enough datapoints:\n",
    "\n",
    "\n",
    "\n",
    "threshold_act_period=30\n",
    "threshold_timestamps=5\n",
    "\n",
    "\n",
    "preselect_dict_folder_id_folder_attr_act={}\n",
    "preselect_dict_folder_id_folder_attr_timestamps={}\n",
    "preselect_dict_folder_id_folder_attr_act_timestamps={}\n",
    "\n",
    "for folder_id in dict_folder_id_folder_attr_ORIGINAL:\n",
    "#     print folder_id, \"  num. active days:\",dict_folder_id_folder_attr[folder_id]['overall_num_active_days'], \"  act period:\", dict_folder_id_folder_attr[folder_id]['act_period'],\\\n",
    "#     \" lifespan\", dict_folder_id_folder_attr[folder_id]['folder_lifespan'], \" <interevent>:\", dict_folder_id_folder_attr[folder_id]['avg_interevent_time']\n",
    "#     raw_input()\n",
    "    \n",
    "    if dict_folder_id_folder_attr_ORIGINAL[folder_id]['act_period'] >=threshold_act_period:\n",
    "        \n",
    "        preselect_dict_folder_id_folder_attr_act[folder_id] = dict_folder_id_folder_attr_ORIGINAL[folder_id]\n",
    "        \n",
    "    if dict_folder_id_folder_attr_ORIGINAL[folder_id]['num_time_stamps'] >=threshold_timestamps:\n",
    "        \n",
    "        preselect_dict_folder_id_folder_attr_timestamps[folder_id] = dict_folder_id_folder_attr_ORIGINAL[folder_id]\n",
    "        \n",
    "        \n",
    "    if (dict_folder_id_folder_attr_ORIGINAL[folder_id]['act_period'] >=threshold_act_period )  &  (dict_folder_id_folder_attr_ORIGINAL[folder_id]['num_time_stamps'] >=threshold_timestamps):\n",
    "        \n",
    "        preselect_dict_folder_id_folder_attr_act_timestamps[folder_id] = dict_folder_id_folder_attr_ORIGINAL[folder_id]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print   \"all folders:\",len(dict_folder_id_folder_attr_ORIGINAL) , \"   # pre-selected folders act:\",len(preselect_dict_folder_id_folder_attr_act)  ,\\\n",
    "\"   # pre-selected folders timestamps:\",len(preselect_dict_folder_id_folder_attr_timestamps) , \"   # pre-selected folders act and timestamps:\",len(preselect_dict_folder_id_folder_attr_act_timestamps)       \n",
    "#pre_selected_df_folders = pd.DataFrame.from_dict(preselect_dict_folder_id_folder_attr,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################### getting simple scatter plot variables vs university_ranking:\n",
    "\n",
    "\n",
    "\n",
    "flag_selection = \"selection\"   # if i want to select only folders with enough data points etc  # or \"all\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### i bin the values for avg team univ. ranking:\n",
    "\n",
    "bining_size_ranking=10\n",
    "\n",
    "dict_int_ranking_bin_ranking={}  # dict with with correspondence ranking-binned_ranking\n",
    "\n",
    "new_bin=0\n",
    "for i in range(2000):   \n",
    "    if i % bining_size_ranking == 0 :            \n",
    "        new_bin =  i\n",
    "    #print i, new_bin    \n",
    "    dict_int_ranking_bin_ranking[i]=new_bin\n",
    "    \n",
    "   \n",
    "# max avg ranking for a team: 994\n",
    "    \n",
    "# for the restricted lin. regrss  (i will remove the last points, lower ranked universities, to reduce noise)\n",
    "num_points= int(1000./ (bining_size_ranking*2.) )\n",
    "print num_points\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "list_strings=['frac_simult_days_over_active_days', 'most_common_categ_num_publ', 'num_unique_projects_members_work_on',  'num_fields',  'avg_geo_dist_km',\\\n",
    "              'most_common_categ_num_last_auth',  'folder_univ_median_ranking','gini_num_days_present_over_members', 'frac_simult_days_overall',\\\n",
    "              'folder_activity_GINI', 'act_per_day_per_active_user', 'num_universities', 'act_per_day', 'folder_univ_mean_ranking',\\\n",
    "              'num_countries', 'burstiness', 'eff_num_members', 'folder_lifespan', 'act_period', 'folder_univ_SD_ranking', 'dominated_folder', 'fraction_work_by_SR',\\\n",
    "              'most_common_univ_ranking', 'folder_tot_act', 'folder_tot_num_edits', 'std_geo_dist_km', 'fraction_SR', 'most_common_num_cit',\\\n",
    "              'number_active_members', 'overall_num_active_days', 'folder_tot_num_adds', 'folder_tot_num_dels', 'avg_interevent_time','num_time_stamps','most_common_career_stage_']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_fig='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/'\n",
    "dict_folder_id_folder_attr= dict_folder_id_folder_attr_ORIGINAL\n",
    "\n",
    "if flag_selection == \"selection\":\n",
    "    dict_folder_id_folder_attr= preselect_dict_folder_id_folder_attr_act_timestamps   #preselect_dict_folder_id_folder_attr  # or dict_folder_id_folder_attr_ORIGINAL\n",
    "    path_fig='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/Pre_selected_folders/'\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "dict_int_ranking_num_folders={}\n",
    "for folder_id in dict_folder_id_folder_attr:\n",
    "   # list_avg_rankings_per_team.append(dict_folder_id_folder_attr[folder_id]['folder_univ_mean_ranking'])\n",
    "\n",
    "\n",
    "    try:\n",
    "        int_ranking=int(dict_folder_id_folder_attr[folder_id]['folder_univ_mean_ranking'])\n",
    "        bin_ranking=dict_int_ranking_bin_ranking[int_ranking]\n",
    "\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            dict_int_ranking_num_folders[bin_ranking]\n",
    "        except KeyError:\n",
    "            dict_int_ranking_num_folders[bin_ranking]=0.\n",
    "\n",
    "        dict_int_ranking_num_folders[bin_ranking] +=1.\n",
    "\n",
    "\n",
    "    except ValueError:  # if the avg ranking is NANist_avg_rankings_per_team                                     \n",
    "\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#### VARS THAT DONT WORK:\n",
    "# num_above_avg_contributors\n",
    "#fract_above_avg_contributors\n",
    "# most_common_career_stage\n",
    "  \n",
    "for var_string in sorted(list_strings):\n",
    "    \n",
    "    print var_string\n",
    "\n",
    "    dict_int_ranking_list_avg_values_group={}\n",
    "    for folder_id in dict_folder_id_folder_attr:\n",
    "       # list_avg_rankings_per_team.append(dict_folder_id_folder_attr[folder_id]['folder_univ_mean_ranking'])\n",
    "\n",
    "\n",
    "        try:\n",
    "            int_ranking=int(dict_folder_id_folder_attr[folder_id]['folder_univ_mean_ranking'])\n",
    "            bin_ranking=dict_int_ranking_bin_ranking[int_ranking]\n",
    "            \n",
    "            try:\n",
    "                dict_int_ranking_list_avg_values_group[bin_ranking]\n",
    "            except KeyError:\n",
    "                dict_int_ranking_list_avg_values_group[bin_ranking]=[]\n",
    "\n",
    "            dict_int_ranking_list_avg_values_group[bin_ranking].append(dict_folder_id_folder_attr[folder_id][var_string])\n",
    "\n",
    "\n",
    "        except ValueError:  # if the avg ranking is NANist_avg_rankings_per_team                                     \n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    list_rankings=[]\n",
    "    list_avg_values_per_team=[]\n",
    "    list_std_values_per_team=[]\n",
    "    list_sem_values_per_team=[]\n",
    "    for ranking in sorted(dict_int_ranking_list_avg_values_group):\n",
    "        list_rankings.append(ranking)\n",
    "        list_avg_values_per_team.append(np.mean(remove_nans(dict_int_ranking_list_avg_values_group[ranking])))\n",
    "        list_std_values_per_team.append(np.std(remove_nans(dict_int_ranking_list_avg_values_group[ranking])))\n",
    "        list_sem_values_per_team.append(scipy.stats.sem(remove_nans(dict_int_ranking_list_avg_values_group[ranking])))\n",
    "\n",
    "    #     print  ranking, dict_int_ranking_list_avg_values_group[ranking]\n",
    "    #     raw_input()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############  i get the values for the lin. regr\n",
    "    list_clean_x=[]  # remove nan values\n",
    "    list_clean_y=[]\n",
    "    for i in range(len(list_rankings)):\n",
    "        try:\n",
    "            int(list_avg_values_per_team[i])\n",
    "            list_clean_x.append(list_rankings[i])\n",
    "            list_clean_y.append(list_avg_values_per_team[i])\n",
    "            #print list_rankings[i], list_avg_values_per_team[i]\n",
    "        except:        \n",
    "            pass\n",
    "\n",
    "    \n",
    "    result=scipy.stats.linregress(list_clean_x ,list_clean_y)\n",
    "    slope1=result[0]\n",
    "    intercept1=result[1]\n",
    "    pvalue1=result[3]\n",
    "    print \"Lin. Regrss. with all \",len(list_clean_x),\" datapoints:\", result\n",
    "\n",
    "     \n",
    "    \n",
    "    result=scipy.stats.linregress(list_clean_x[:num_points] ,list_clean_y[:num_points])\n",
    "    slope2=result[0]\n",
    "    intercept2=result[1]\n",
    "    pvalue2=result[3]\n",
    "    \n",
    "    print \"   Lin. Regrss. for first\", num_points, \" points:\", result\n",
    "    print  len(list_clean_x[:num_points])\n",
    "    print \n",
    "  \n",
    "    \n",
    "    \n",
    "    regr_values_x1=[]\n",
    "    regr_values_y1=[]\n",
    "    for i in range(len(list_rankings)):\n",
    "        regr_values_x1.append(list_rankings[i])\n",
    "        regr_values_y1.append(intercept1 + slope1*list_rankings[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    regr_values_x2=[]\n",
    "    regr_values_y2=[]\n",
    "    for i in range(len(list_rankings)):\n",
    "        regr_values_x2.append(list_rankings[i])\n",
    "        regr_values_y2.append(intercept2 + slope2*list_rankings[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### i define the different traces:\n",
    "\n",
    "    trace0 = go.Scatter(\n",
    "        x = list_rankings,\n",
    "        y = list_avg_values_per_team,\n",
    "\n",
    "#         error_y=dict(\n",
    "#                 type='data',\n",
    "#                 #symmetric=False,\n",
    "#                 array=list_std_values_per_team           \n",
    "#             ),        \n",
    "        mode = 'lines+markers',  \n",
    "        name='data'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x = regr_values_x1,\n",
    "        y = regr_values_y1,      \n",
    "        mode = 'line',\n",
    "        name='lin.regr<br>slope: '+str(slope1)+\"<br>intercept: \"+str(intercept1)+\"<br>p-value: \"+str(pvalue1),     \n",
    "    )\n",
    "\n",
    "\n",
    "    trace2 = go.Scatter(\n",
    "        x = regr_values_x2,\n",
    "        y = regr_values_y2,      \n",
    "        mode = 'line',\n",
    "        name='lin.regr('+str(num_points)+'points)'+'<br>slope: '+str(slope2)+\"<br>intercept: \"+str(intercept2)+\"<br>p-value: \"+str(pvalue2),     \n",
    "    )\n",
    "\n",
    "    # trace2 = go.Scatter(\n",
    "    #     x = [0,1000],\n",
    "    #     y = [list_avg_values_per_team[0],list_avg_values_per_team[0]],      \n",
    "    #     mode = 'line',\n",
    "    #     name='',      \n",
    "    # )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    layout = Layout(    \n",
    "        xaxis=dict(\n",
    "            title=\"average university ranking in the team\",#\"User's university national ranking\"\n",
    "           # range=[1,50]   # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "           # type='log',\n",
    "            titlefont=dict(\n",
    "                family=font,\n",
    "                size=font_axes,\n",
    "                color='black'\n",
    "            #    color='lightgrey'\n",
    "            ), \n",
    "            tickfont=dict(      \n",
    "                family=font,\n",
    "                size=font_ticks,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=var_string,  #'folder_lifespan',\n",
    "            #range=[2,300]      # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "           # type='log',\n",
    "            titlefont=dict(\n",
    "                family=font,\n",
    "                size=font_axes,\n",
    "                color='black'\n",
    "            #    color='lightgrey'\n",
    "            ), \n",
    "            tickfont=dict(      \n",
    "                family=font,\n",
    "                size=font_ticks,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1\n",
    "    )       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data = [trace0, trace1, trace2]#, trace2]\n",
    "\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "\n",
    "    iplot(fig, filename='scatterplot')\n",
    "\n",
    "    name='scatterplot_binned_ranking_by_'+str(bining_size_ranking)+'_vs_avg_'+var_string+\"_\"+flag_selection\n",
    "    offline.plot(fig, auto_open=True, image = 'png', image_filename=name,\n",
    "                 output_type='file', image_width=1600, image_height=1000, filename=path_fig+name+'.html', validate=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bining_size_ranking=10\n",
    "\n",
    "dict_int_ranking_bin_ranking={}  # dict with with correspondence ranking-binned_ranking\n",
    "\n",
    "new_bin=0\n",
    "for i in range(2000):   \n",
    "    if i % bining_size_ranking == 0 :            \n",
    "        new_bin =  i\n",
    "    #print i, new_bin    \n",
    "    dict_int_ranking_bin_ranking[i]=new_bin\n",
    "    \n",
    "   \n",
    "# max avg ranking for a team: 994\n",
    "    \n",
    "# for the restricted lin. regrss  (i will remove the last points, lower ranked universities, to reduce noise)\n",
    "num_points= int(1000./ (bining_size_ranking*2.) )\n",
    "print num_points\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "dict_int_ranking_num_folders={}\n",
    "for folder_id in tqdm_notebook(dict_folder_id_folder_attr_ORIGINAL):\n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "    try:\n",
    "        int_ranking=int(dict_folder_id_folder_attr_ORIGINAL[folder_id]['folder_univ_mean_ranking'])\n",
    "        bin_ranking=dict_int_ranking_bin_ranking[int_ranking]\n",
    "\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            dict_int_ranking_num_folders[bin_ranking]\n",
    "        except KeyError:\n",
    "            dict_int_ranking_num_folders[bin_ranking]=0.\n",
    "\n",
    "        dict_int_ranking_num_folders[bin_ranking] +=1.\n",
    "\n",
    "\n",
    "    except ValueError:  # if the avg ranking is NANist_avg_rankings_per_team                                     \n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_int_ranking_num_folders.pickle'\n",
    "# with open(pickle_name, 'wb') as handle:\n",
    "#     pickle.dump(dict_int_ranking_num_folders, handle)\n",
    "# print \"written:\", pickle_name\n",
    "    \n",
    "\n",
    "    \n",
    "# for key in sorted(dict_int_ranking_num_folders):\n",
    "#     print key, dict_int_ranking_num_folders[key]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "cont =0. \n",
    "for key in sorted(dict_int_ranking_num_folders):\n",
    "   cont +=dict_int_ranking_num_folders[key]\n",
    "\n",
    "print cont\n",
    "\n",
    "\n",
    "list_ranking=[]\n",
    "list_num_folders=[]\n",
    "\n",
    "for ranking in sorted(dict_int_ranking_num_folders):\n",
    "    list_ranking.append(ranking)\n",
    "    list_num_folders.append(dict_int_ranking_num_folders[ranking])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### i define the different traces:\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = list_ranking,\n",
    "    y = list_num_folders,\n",
    "\n",
    "#         error_y=dict(\n",
    "#                 type='data',\n",
    "#                 #symmetric=False,\n",
    "#                 array=list_std_values_per_team           \n",
    "#             ),        \n",
    "    mode = 'lines+markers',  \n",
    "    name='data'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# trace1 = go.Scatter(\n",
    "#     x = regr_values_x1,\n",
    "#     y = regr_values_y1,      \n",
    "#     mode = 'line',\n",
    "#     name='lin.regr<br>slope: '+str(slope1)+\"<br>intercept: \"+str(intercept1)+\"<br>p-value: \"+str(pvalue1),     \n",
    "# )\n",
    "\n",
    "\n",
    "# trace2 = go.Scatter(\n",
    "#     x = regr_values_x2,\n",
    "#     y = regr_values_y2,      \n",
    "#     mode = 'line',\n",
    "#     name='lin.regr('+str(num_points)+'points)'+'<br>slope: '+str(slope2)+\"<br>intercept: \"+str(intercept2)+\"<br>p-value: \"+str(pvalue2),     \n",
    "# )\n",
    "\n",
    "# trace2 = go.Scatter(\n",
    "#     x = [0,1000],\n",
    "#     y = [list_avg_values_per_team[0],list_avg_values_per_team[0]],      \n",
    "#     mode = 'line',\n",
    "#     name='',      \n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layout = Layout(    \n",
    "    xaxis=dict(\n",
    "        title=\"average university ranking of the team\",#\"User's university national ranking\"\n",
    "       # range=[1,50]   # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "       # type='log',\n",
    "        titlefont=dict(\n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ), \n",
    "        tickfont=dict(      \n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='number of teams',\n",
    "        #range=[2,300]      # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "       # type='log',\n",
    "        titlefont=dict(\n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ), \n",
    "        tickfont=dict(      \n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [trace0]#, trace1, trace2]#, trace2]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='scatterplot')\n",
    "path_fig='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/'\n",
    "name='number_of_teams_vs_int_ranking'\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename=name,\n",
    "             output_type='file', image_width=1600, image_height=1000, filename=path_fig+name+'.html', validate=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_user_id_user_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bining_size_ranking=10\n",
    "\n",
    "dict_int_ranking_bin_ranking={}  # dict with with correspondence ranking-binned_ranking\n",
    "\n",
    "new_bin=0\n",
    "for i in range(2000):   \n",
    "    if i % bining_size_ranking == 0 :            \n",
    "        new_bin =  i\n",
    "    #print i, new_bin    \n",
    "    dict_int_ranking_bin_ranking[i]=new_bin\n",
    "    \n",
    "   \n",
    "# max avg ranking for a team: 994\n",
    "    \n",
    "# for the restricted lin. regrss  (i will remove the last points, lower ranked universities, to reduce noise)\n",
    "num_points= int(1000./ (bining_size_ranking*2.) )\n",
    "print num_points\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dict_int_ranking_num_folders={}\n",
    "for user_id in dict_user_id_user_attr:\n",
    "    \n",
    "    int_ranking=dict_user_id_user_attr[user_id]['world_ranking']\n",
    "    \n",
    "    try:\n",
    "        bin_ranking=dict_int_ranking_bin_ranking[int_ranking]\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            dict_int_ranking_num_folders[bin_ranking] \n",
    "        except KeyError:\n",
    "            dict_int_ranking_num_folders[bin_ranking] =0.\n",
    "\n",
    "        dict_int_ranking_num_folders[bin_ranking]  +=1\n",
    "    except KeyError:  # if nan\n",
    "        pass\n",
    "\n",
    "    \n",
    "list_ranking=[]\n",
    "list_num_folders=[]\n",
    "for ranking in sorted(dict_int_ranking_num_folders):\n",
    "    list_num_folders.append(dict_int_ranking_num_folders[ranking])\n",
    "    list_ranking.append(ranking)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print \"done. ready to plot\"    \n",
    "\n",
    "######### i define the different traces:\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = list_ranking,\n",
    "    y = list_num_folders,\n",
    "\n",
    "#         error_y=dict(\n",
    "#                 type='data',\n",
    "#                 #symmetric=False,\n",
    "#                 array=list_std_values_per_team           \n",
    "#             ),        \n",
    "    mode = 'lines+markers',  \n",
    "    name='data'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# trace1 = go.Scatter(\n",
    "#     x = regr_values_x1,\n",
    "#     y = regr_values_y1,      \n",
    "#     mode = 'line',\n",
    "#     name='lin.regr<br>slope: '+str(slope1)+\"<br>intercept: \"+str(intercept1)+\"<br>p-value: \"+str(pvalue1),     \n",
    "# )\n",
    "\n",
    "\n",
    "# trace2 = go.Scatter(\n",
    "#     x = regr_values_x2,\n",
    "#     y = regr_values_y2,      \n",
    "#     mode = 'line',\n",
    "#     name='lin.regr('+str(num_points)+'points)'+'<br>slope: '+str(slope2)+\"<br>intercept: \"+str(intercept2)+\"<br>p-value: \"+str(pvalue2),     \n",
    "# )\n",
    "\n",
    "# trace2 = go.Scatter(\n",
    "#     x = [0,1000],\n",
    "#     y = [list_avg_values_per_team[0],list_avg_values_per_team[0]],      \n",
    "#     mode = 'line',\n",
    "#     name='',      \n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layout = Layout(    \n",
    "    xaxis=dict(\n",
    "        title=\"university ranking\",#\"User's university national ranking\"\n",
    "       # range=[1,50]   # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "       # type='log',\n",
    "        titlefont=dict(\n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ), \n",
    "        tickfont=dict(      \n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='number of users',\n",
    "        #range=[2,300]      # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "       # type='log',\n",
    "        titlefont=dict(\n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ), \n",
    "        tickfont=dict(      \n",
    "            family=40,\n",
    "            size=30,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [trace0]#, trace1, trace2]#, trace2]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='scatterplot')\n",
    "path_fig='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/'\n",
    "name='number_of_users_vs_int_ranking'\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename=name,\n",
    "             output_type='file', image_width=1600, image_height=1000, filename=path_fig+name+'.html', validate=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr_values_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print df_users.columns\n",
    "print df_folders.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_selection_folder2=df_folders[df_folders['folder_univ_median_ranking']<=50]\n",
    "print df_selection_folder2.shape\n",
    "\n",
    "df_selection_folder3=df_folders[ df_folders['folder_lifespan'] >1]\n",
    "print df_selection_folder3.shape\n",
    "\n",
    "df_selection_folder4=df_folders[ df_folders['number_active_members'] >1]\n",
    "print df_selection_folder4.shape\n",
    "\n",
    "df_selection_folder5=df_folders[ (df_folders['number_active_members'] >1)  &  (df_folders['folder_lifespan'] >1) ]\n",
    "print df_selection_folder5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_complete_info=df_folders[['folder_univ_median_ranking','folder_activity_GINI' ]].dropna(how='any')  # by default, dropna drops a row if ANY  of the indicated fields are missing (i can also set it to if ALL the fields are missing: how='all')\n",
    "print df_complete_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_non_zeros=df[df['folder_tot_act'] > 0  & df['folder_tot_act'].notnull()]\n",
    "# print df_non_zeros.shape\n",
    "# print sorted(df_non_zeros.folder_tot_act.unique())\n",
    "# #df[df['first_name'].notnull() & (df['nationality'] == \"USA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_folders[\"folder_activity_GINI\"].mean()\n",
    "# df_users.user_univ_ranking.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_folders.folder_univ_mean_ranking.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_folders.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font_legend=40\n",
    "font_axes=40\n",
    "font_ticks=20\n",
    "font='Times new roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######  HEATMAPS (PAIRS OF VARIABLES)  \n",
    "\n",
    "\n",
    "grouping_flag=\"user\"#\"user\"   # or \"folder\"\n",
    "selection_tag=1  # if 1: aLL data \n",
    "\n",
    "\n",
    "\n",
    "v2_string='avg_fract_work_over_diff_folders'\n",
    "\n",
    "\n",
    "\n",
    "if grouping_flag==\"folder\":\n",
    "    df=df_folders\n",
    "    v1_string='folder_univ_median_ranking'\n",
    "    \n",
    "    \n",
    "    if selection_tag==2:        \n",
    "        df=df_selection_folder2\n",
    "                \n",
    "    elif selection_tag==3:        \n",
    "        df=df_selection_folder3 \n",
    "     \n",
    "    elif selection_tag==4:        \n",
    "        df=df_selection_folder4\n",
    "   \n",
    "    elif selection_tag==5:        \n",
    "        df=df_selection_folder5\n",
    "   \n",
    "    \n",
    "        \n",
    "#         'list_act', u'folder_lifespan', u'most_common_categ_num_publ',\n",
    "#        u'most_common_career_stage', u'folder_activity_GINI',\n",
    "#        u'folder_tot_num_edits', u'most_common_categ_num_last_auth',\n",
    "#        u'folder_univ_median_ranking', u'folder_univ_SD_ranking',\n",
    "#        u'fraction_SR', u'most_common_num_cit', u'number_active_members',\n",
    "#        u'list_careers', u'fraction_work_by_SR', u'folder_tot_num_deletes',\n",
    "#        u'list_ranking', u'most_common_univ_ranking', u'folder_tot_act',\n",
    "#        u'folder_tot_num_adds', u'num_folder_members'\n",
    "\n",
    "elif grouping_flag==\"user\":\n",
    "    df=df_users    \n",
    "    v1_string='user_univ_ranking'\n",
    "\n",
    "#[u'k_unfiltered', u'CC_filtered_by_act',\n",
    "#        u'avg_fract_work_over_diff_folders', u'mean_folder_lifespan',\n",
    "#        u'category_total_publ', u'category_total_last_auth',\n",
    "#        u'user_tot_num_edits', u'k_filtered_by_act', u'number_folders',\n",
    "#        u'CC_unfiltered', u'user_tot_num_adds', u'kshell_unfiltered',\n",
    "#        u'user_tot_act', u'career_stage', u'kshell_filtered_by_act',\n",
    "#        u'user_tot_num_deletes', u'list_folders', u'category_total_cit',\n",
    "#        u'SD_fract_work_over_diff_folders', u'user_univ_ranking']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "x = df[v1_string]#.head(5000000)    #np.random.randn(500)\n",
    "y = df[v2_string]#.head(5000000)   #np.random.randn(500)+1\n",
    "\n",
    "\n",
    "trace1= Histogram2d(\n",
    "        x=x,\n",
    "        y=y,\n",
    " #   colorscale = [   # grey scale logaritmic colorscale\n",
    "#         [0, 'rgb(250, 250, 250)'],        #0\n",
    "#         [1./10000, 'rgb(200, 200, 200)'], #10\n",
    "#         [1./1000, 'rgb(150, 150, 150)'],  #100\n",
    "#         [1./100, 'rgb(100, 100, 100)'],   #1000\n",
    "#         [1./10, 'rgb(50, 50, 50)'],       #10000\n",
    "#         [1., 'rgb(0, 0, 0)'],             #100000\n",
    "#         ],\n",
    "   \n",
    "    colorscale = [       # RED scale logaritmic colouser_univ_rankingrscale\n",
    "        [0, 'rgb(250, 250, 250)'],        #0\n",
    "        [1./10000, 'rgb(205,201,201)'], #10\n",
    "        [1./1000, 'rgb(205,155,155)'],  #100\n",
    "        [1./100, 'rgb(238,99,99)'],   #1000\n",
    "        [1./10, 'rgb(205,38,38)'],       #10000\n",
    "        [1., 'rgb(205,0,0)'],             #100000\n",
    "        ],\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "#      colorbar= {\n",
    "#         'tick0': 0,\n",
    "#         'tickmode': 'array',\n",
    "#         'tickvals': [0,100,1000,10000]#[0, 1000, 10000, 20000]\n",
    "#     }\n",
    ")\n",
    "    \n",
    "    \n",
    "layout = Layout(    \n",
    "    xaxis=dict(\n",
    "        title=v1_string.replace(\"_\", \" \").replace(\"uuser_univ_rankingniv \", \"university \").replace(\"folder \", \"folder's \"),#\"User's university national ranking\"\n",
    "       # range=[1,50]   # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "       # type='log',\n",
    "        titlefont=dict(\n",
    "            family=font,\n",
    "            size=font_axes,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ), \n",
    "        tickfont=dict(      \n",
    "            family=font,\n",
    "            size=font_ticks,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=v2_string.replace(\"_\", \" \"),  #'folder_lifespan',\n",
    "        #range=[2,300]      # this doesnt affect the binning for the heatmap, it is only a zoom.\n",
    "       # type='log',\n",
    "        titlefont=dict(\n",
    "            family=font,\n",
    "            size=font_axes,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ), \n",
    "        tickfont=dict(      \n",
    "            family=font,\n",
    "            size=font_ticks,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")       \n",
    "    \n",
    "data = [trace1]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='heatmap')\n",
    "#offline.plot(fig, filename='/home/juliaponcela/heatmap.html')\n",
    "\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename=\"heatmap_\"+v1_string+\"_vs_\"+v2_string ,\n",
    "             output_type='file', image_width=1600, image_height=1000, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/'+\"heatmap_\"+v1_string+\"_vs_\"+v2_string+\".html\", validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v1_string='folder_lifespan'\n",
    "# v2_string='folder_activity_GINI'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x=sorted(df_folders[v1_string].unique())\n",
    "# y=sorted(df_folders[v2_string].unique())\n",
    "# # matrix=pd.crosstab(index=df_folders[v2_string], columns = df_folders[v1_string])    # transform two columns into the count matrix\n",
    "# # z=matrix.values   # transform the dataframe into an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in df_folders.columns():\n",
    "    print c, df_folders[c].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_folders['folder_lifespan'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.scatter_matrix(filename='cufflinks/scatter-matrix', world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_users.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######### ONE-VARIABLE HISTOGRAMS\n",
    "\n",
    "\n",
    "grouping_flag=\"folder\"  #\"user\"   # or \"folder\"\n",
    "\n",
    "if grouping_flag==\"user\":\n",
    "    df=df_users\n",
    "   \n",
    "# grouping by user:\n",
    "# Index([u'mean_folder_lifespan', u'category_total_publ',\n",
    "#        u'category_total_last_auth', u'user_tot_num_edits', u'number_folders',\n",
    "#        u'user_tot_num_adds', u'user_tot_act', u'career_stage',\n",
    "#        u'user_tot_num_deletes', u'category_total_cit', u'user_univ_ranking'],\n",
    "#       dtype='object')\n",
    "\n",
    "elif grouping_flag==\"folder\":\n",
    "    df=df_folders\n",
    "    \n",
    "                    \n",
    "# 'list_act', u'folder_lifespan', u'most_common_categ_num_publ',\n",
    "#        u'most_common_career_stage', u'folder_activity_GINI',\n",
    "#        u'folder_tot_num_edits', u'most_common_categ_num_last_auth',\n",
    "#        u'folder_univ_median_ranking', u'folder_univ_SD_ranking',\n",
    "#        u'fraction_SR', u'most_common_num_cit', u'number_active_members',\n",
    "#        u'list_careers', u'fraction_work_by_SR', u'folder_tot_num_deletes',\n",
    "#        u'list_ranking', u'most_common_univ_ranking', u'folder_tot_act',\n",
    "#        u'folder_tot_num_adds', u'num_folder_members'\n",
    "\n",
    "\n",
    "v1_string='number_active_members'\n",
    "\n",
    "\n",
    "print \"avg:\", df[v1_string].mean(),\"   SD:\", df[v1_string].std()\n",
    "\n",
    "x1 = df[v1_string]\n",
    "\n",
    "\n",
    "trace1= Histogram(\n",
    "        x=x1, \n",
    "     #   cumulative=dict(enabled=True),\n",
    "       # name='top 10',\n",
    "      #histnorm='probability'    # IF I COMMENT THIS LINE, I GET THE RAW COUNTS, NOT PDF\n",
    ")\n",
    " \n",
    "   \n",
    "    \n",
    "layout = Layout(    \n",
    "    xaxis=dict(\n",
    "        title=v1_string.replace(\"_\",\" \").replace(\"user \",\"user's \").replace(\"folder \",\"folder's \").replace(\"univ \",\"university \"),   #\"User's university national ranking\",\n",
    "        titlefont=dict(\n",
    "            family=font,#family='Arial, sans-serif',\n",
    "            size=font_axes,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ),  \n",
    "        tickfont=dict(   \n",
    "            family=font,\n",
    "            size=font_ticks,\n",
    "            color='black'\n",
    "        ),\n",
    "        type='log'\n",
    "    ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        title='Number '+grouping_flag+\"s\",       \n",
    "        titlefont=dict(\n",
    "            family=font,#family='Arial, sans-serif',\n",
    "            size=font_axes,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ),  \n",
    "        tickfont=dict(   \n",
    "            family=font,\n",
    "            size=font_ticks,\n",
    "            color='black'\n",
    "        ),\n",
    "        type='log',\n",
    "    ),\n",
    "#     bargap=0.2,\n",
    "#     bargroupgap=0.1\n",
    ")       \n",
    "    \n",
    "data = [trace1]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='hitogram')\n",
    "#offline.plot(fig, filename='/home/juliaponcela/histogram.html')\n",
    "\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename=\"histogram_\"+v1_string ,\n",
    "             output_type='file', image_width=1600, image_height=1000, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/'+\"histogram_\"+v1_string+\".html\", validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_folders.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######### ONE-VARIABLE HISTOGRAMS  BY GROUPS\n",
    "\n",
    "\n",
    "\n",
    "selection_tag=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_selection_folder2=df_folders[df_folders['folder_univ_median_ranking']<=50]\n",
    "print df_selection_folder2.shape\n",
    "\n",
    "df_selection_folder3=df_folders[ df_folders['folder_lifespan'] >1]\n",
    "print df_selection_folder3.shape\n",
    "\n",
    "df_selection_folder4=df_folders[ df_folders['number_active_members'] >1]\n",
    "print df_selection_folder4.shape\n",
    "\n",
    "df_selection_folder5=df_folders[ (df_folders['number_active_members'] >1)  &  (df_folders['folder_lifespan'] >1) ]\n",
    "print df_selection_folder5.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grouping_flag=\"folder\"#\"user\"   # or \"folder\"\n",
    "\n",
    "\n",
    "\n",
    "v1_string='fraction_work_by_SR'\n",
    "\n",
    "\n",
    "\n",
    "if grouping_flag==\"user\":\n",
    "    df=df_users\n",
    "   \n",
    "# grouping by user:\n",
    "# Index([u'mean_folder_lifespan', u'category_total_publ',\n",
    "#        u'category_total_last_auth', u'user_tot_num_edits', u'number_folders',\n",
    "#        u'user_tot_num_adds', u'user_tot_act', u'career_stage',\n",
    "#        u'user_tot_num_deletes', u'category_total_cit', u'user_univ_ranking'],\n",
    "#       dtype='object')\n",
    "\n",
    "elif grouping_flag==\"folder\":\n",
    "    df=df_folders\n",
    "                \n",
    "# 'list_act', u'folder_lifespan', u'most_common_categ_num_publ',\n",
    "#        u'most_common_career_stage', u'folder_activity_GINI',\n",
    "#        u'folder_tot_num_edits', u'most_common_categ_num_last_auth',\n",
    "#        u'folder_univ_median_ranking', u'folder_univ_SD_ranking',\n",
    "#        u'fraction_SR', u'most_common_num_cit', u'number_active_members',\n",
    "#        u'list_careers', u'fraction_work_by_SR', u'folder_tot_num_deletes',\n",
    "#        u'list_ranking', u'most_common_univ_ranking', u'folder_tot_act',\n",
    "#        u'folder_tot_num_adds', u'num_folder_members'\n",
    "\n",
    "\n",
    "\n",
    "if selection_tag==2:        \n",
    "        df=df_selection_folder2\n",
    "                \n",
    "elif selection_tag==3:        \n",
    "        df=df_selection_folder3 \n",
    "     \n",
    "elif selection_tag==4:        \n",
    "        df=df_selection_folder4\n",
    "   \n",
    "elif selection_tag==5:        \n",
    "        df=df_selection_folder5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### different sets to be displayed separately\n",
    "df_select_top1=df[df['folder_univ_median_ranking']<=10]\n",
    "\n",
    "#df_select_top2=df_selection_folder2[(df_selection_folder2['folder_univ_mean_ranking']>10) ] & (df['folder_univ_mean_ranking']<=50) ]\n",
    "\n",
    "df_select_top2=df[(df['folder_univ_median_ranking']>10) ]# & (df['folder_univ_mean_ranking']<=50) ]\n",
    "\n",
    "#df_select_top3=df_selection_folder2[(df_selection_folder2['folder_univ_mean_ranking']>50) ]# & (df['folder_univ_mean_ranking']<=150) ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print df_select_top1[v1_string].mean(),  df_select_top2[v1_string].mean()#,  df_select_top3[\"folder_lifespan\"].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1 = df_select_top1[v1_string]\n",
    "x2 = df_select_top2[v1_string]\n",
    "#x3 = df_select_top3[v1_string]\n",
    "\n",
    "\n",
    "trace1= Histogram(\n",
    "        x=x1, \n",
    "        name='top 10',\n",
    "       histnorm='probability'\n",
    ")\n",
    " \n",
    "    \n",
    "trace2= Histogram(\n",
    "        x=x2, \n",
    "        name='non top 10',\n",
    "       histnorm='probability'\n",
    ")\n",
    "  \n",
    "        \n",
    "# trace3= Histogram(\n",
    "#         x=x3, \n",
    "#         name=' top > 50',\n",
    "#         histnorm='probability'\n",
    "# )\n",
    " \n",
    "    \n",
    "layout = Layout(    \n",
    "   \n",
    "   # bargap=0.2,\n",
    "    \n",
    "    \n",
    "    \n",
    "    xaxis=dict(\n",
    "        title=v1_string.replace(\"_\",\" \"),   #\"User's university national ranking\",\n",
    "        titlefont=dict(\n",
    "            family=font,#family='Arial, sans-serif',\n",
    "            size=font_axes,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ),  \n",
    "        tickfont=dict(   \n",
    "            family=font,\n",
    "            size=font_ticks,\n",
    "            color='black'\n",
    "        ),\n",
    "        #type='log'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='pdf',\n",
    "        type='log',\n",
    "        titlefont=dict(\n",
    "            family=font,#family='Arial, sans-serif',\n",
    "            size=font_axes,\n",
    "            color='black'\n",
    "        #    color='lightgrey'\n",
    "        ),  \n",
    "        tickfont=dict(   \n",
    "            family=font,\n",
    "            size=font_ticks,\n",
    "            color='black'\n",
    "        ),\n",
    "    ),                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     bargroupgap=0.1\n",
    ")       \n",
    "    \n",
    "data = [trace1, trace2]#, trace3]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='histogram_'+v1_string+'_by_groups.html')\n",
    "#offline.plot(fig, filename='/home/juliaponcela/histogram_'+v1_string+'_by_groups.html')\n",
    "\n",
    "offline.plot(fig, auto_open=True, image = 'png', image_filename=\"histogram_\"+v1_string+\"_by_groups\" ,\n",
    "             output_type='file', image_width=1600, image_height=1200, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Figures/histogram_'+v1_string+'_by_groups.html', validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file = 'Dropbox_datafile_may22_2017_modified_added_univ_country_geolocation_RUCC_population_density_when_available_career_stage_GINI_folder_act_categories.csv'\n",
    "df_original = pd.read_csv(path+input_file, sep=',',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "\n",
    "print df_original.shape\n",
    "\n",
    "###################\n",
    "\n",
    "def get_numerical_ranking(value):\n",
    "    \n",
    "    \n",
    "    ranking=np.nan\n",
    "    try:\n",
    "        ranking=int(value)\n",
    "    except :\n",
    "        try:   # 201-300  or nan\n",
    "            \n",
    "            ranking=int(value.split(\"-\")[0])\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    return ranking\n",
    "\n",
    "\n",
    "#################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dict_ranking_num_users={}\n",
    "dict_ranking_num_folders={}\n",
    "\n",
    "idx=0\n",
    "for world_ranking in df_original.world_ranking.unique():\n",
    "    \n",
    "    df_selection = df_original[df_original['world_ranking'] == world_ranking]\n",
    "   \n",
    "    dict_ranking_num_folders[idx] = {}\n",
    "    dict_ranking_num_users[idx] = {}\n",
    "  \n",
    "    dict_ranking_num_folders[idx][\"counts\"] = len(df_selection.folder_id.unique())\n",
    "    dict_ranking_num_users[idx][\"counts\"] = len(df_selection.user_id.unique())\n",
    "  \n",
    "    dict_ranking_num_folders[idx][\"world_ranking\"] = world_ranking\n",
    "    dict_ranking_num_users[idx][\"world_ranking\"] = world_ranking\n",
    " \n",
    "\n",
    "    idx +=1\n",
    "\n",
    "\n",
    "   \n",
    "print \"done.\"  , len(dict_ranking_num_folders), len(dict_ranking_num_users)\n",
    "    \n",
    "#### i create df from dict\n",
    "\n",
    "df_from_dict_ranking_unive_num_users = pd.DataFrame.from_dict(dict_ranking_num_users,orient='index')\n",
    "df_from_dict_ranking_unive_num_folders = pd.DataFrame.from_dict(dict_ranking_num_folders,orient='index')   \n",
    "\n",
    "        \n",
    "    \n",
    "df_from_dict_ranking_unive_num_users['numerical_ranking']  = df_from_dict_ranking_unive_num_users.world_ranking.apply(get_numerical_ranking)\n",
    "df_from_dict_ranking_unive_num_folders['numerical_ranking']  = df_from_dict_ranking_unive_num_folders.world_ranking.apply(get_numerical_ranking)\n",
    "\n",
    "\n",
    "\n",
    "df_from_dict_ranking_unive_num_folders.sort_values(by='numerical_ranking', axis=0, ascending=True, inplace=True)\n",
    "df_from_dict_ranking_unive_num_users.sort_values(by='numerical_ranking', axis=0, ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "### i rename index as column\n",
    "# df_from_dict_ranking_unive_num_folders['world_ranking'] = df_from_dict_ranking_unive_num_folders.index\n",
    "# df_from_dict_ranking_unive_num_users['world_ranking'] = df_from_dict_ranking_unive_num_users.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_from_dict_ranking_unive_num_folders.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######### Bar plots\n",
    "\n",
    "\n",
    "\n",
    "#v2_string='user_univ_ranking'\n",
    "\n",
    "x = df_from_dict_ranking_unive_num_users['numerical_ranking']#.head(5000000)    #np.random.randn(500)\n",
    "y = df_from_dict_ranking_unive_num_users['counts']\n",
    "\n",
    "trace1= Bar(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        \n",
    ")\n",
    "    \n",
    "    \n",
    "layout = Layout(    \n",
    "    xaxis=dict(\n",
    "        title=\"University ranking\",\n",
    "        #type='log'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number users',\n",
    "        #type='log'\n",
    "    ),\n",
    "    bargap=0.,\n",
    "    bargroupgap=0.1\n",
    ")       \n",
    "    \n",
    "data = [trace1]\n",
    "\n",
    "\n",
    "\n",
    "# data = [go.Histogram(x=x,\n",
    "#                      histnorm='probability')]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='hstogram')\n",
    "offline.plot(fig, filename='/home/juliaponcela/histogram.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/\"\n",
    "input_file = 'Merged_linkedin-WoS_GS_extra70univ_anonymized_groups.xlsx'\n",
    "df_wos = pd.read_excel(path+input_file)#, sep=',',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "df_wos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df_wos.columns:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wos.Field.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wos.full_name_linkedin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### histograms variables WOS  by field\n",
    "\n",
    "# 'humanities', 'science', 'business econ finances government',\n",
    "#        'art', 'medicine dentistry nursing pharmacology', 'other'\n",
    "\n",
    "\n",
    "selection1='science'\n",
    "selection2='medicine dentistry nursing pharmacology'\n",
    "selection3='humanities'\n",
    "#selection4='other'\n",
    "selection4='business econ finances government'\n",
    "selection5='art'\n",
    "\n",
    "\n",
    "\n",
    "variable= 'total_pubs'   #'num_citations'     #'num_papers_last'     #'total_pubs'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_selection1=df_wos[df_wos['Field'] == selection1]\n",
    "\n",
    "df_selection2=df_wos[df_wos['Field'] == selection2]\n",
    "\n",
    "df_selection3=df_wos[df_wos['Field'] == selection3]\n",
    "\n",
    "df_selection4=df_wos[df_wos['Field'] == selection4]\n",
    "\n",
    "df_selection5=df_wos[df_wos['Field'] == selection5]\n",
    "\n",
    "df_selection6=df_wos[df_wos['Field'] == selection6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1=df_selection1[variable]\n",
    "x2=df_selection2[variable]\n",
    "x3=df_selection3[variable]\n",
    "x4=df_selection4[variable]\n",
    "x5=df_selection5[variable]\n",
    "x6=df_selection6[variable]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trace1= Histogram(\n",
    "        x=x1, \n",
    "        cumulative=dict(enabled=True),\n",
    "        name=selection1,       \n",
    "        #histnorm='probability'\n",
    ")\n",
    " \n",
    "    \n",
    "trace2= Histogram(\n",
    "        x=x2, \n",
    "         cumulative=dict(enabled=True),   \n",
    "        name=selection2,\n",
    "        #histnorm='probability'\n",
    ")\n",
    "  \n",
    "        \n",
    "trace3= Histogram(\n",
    "        x=x3, \n",
    "        cumulative=dict(enabled=True),\n",
    "        name=selection3,\n",
    "       #histnorm='probability'\n",
    ")\n",
    " \n",
    " \n",
    "trace4= Histogram(\n",
    "        x=x4, \n",
    "        cumulative=dict(enabled=True),\n",
    "        name=selection4,       \n",
    "        #histnorm='probability'\n",
    ")\n",
    " \n",
    "    \n",
    "trace5= Histogram(\n",
    "        x=x5, \n",
    "         cumulative=dict(enabled=True),   \n",
    "        name=selection5,\n",
    "        #histnorm='probability'\n",
    ")\n",
    "  \n",
    "        \n",
    "trace6= Histogram(\n",
    "        x=x6, \n",
    "        cumulative=dict(enabled=True),\n",
    "        name=selection6,\n",
    "       #histnorm='probability', \":  \"\n",
    ")\n",
    " \n",
    "   \n",
    "layout = Layout(   \n",
    "    width=1000,\n",
    "    height=500,\n",
    "    xaxis=dict(\n",
    "        title=variable,   \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='cumulative count',\n",
    "        type='log'\n",
    "    ),\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")       \n",
    "    \n",
    "data = [trace1, trace2, trace3, trace4, trace5]#, trace6]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='hstogram')\n",
    "offline.plot(fig, filename='/home/juliaponcela/histogram.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "variable= 'num_papers_last'   #'num_citations'     #'num_papers_last'     #'total_pubs'\n",
    "\n",
    "\n",
    "\n",
    "print variable\n",
    "\n",
    "print selection1, \" \", len(df_selection1) ,\"people  :\",  df_selection1[variable].mean(), df_selection1[variable].median(), df_selection1[variable].max(), df_selection1[variable].min(), df_selection1[variable].dropna().quantile([.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9])\n",
    "print selection2, \" \", len(df_selection2) ,\"people  :\", df_selection2[variable].mean(), df_selection2[variable].median(), df_selection2[variable].max(), df_selection2[variable].min(), df_selection2[variable].dropna().quantile([.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9])\n",
    "print selection3, \" \", len(df_selection3) ,\"people  :\", df_selection3[variable].mean(), df_selection3[variable].median(), df_selection3[variable].max(), df_selection3[variable].min(), df_selection3[variable].dropna().quantile([.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9])\n",
    "print selection4, \" \", len(df_selection4) ,\"people  :\", df_selection4[variable].mean(), df_selection4[variable].median(), df_selection4[variable].max(), df_selection4[variable].min(), df_selection4[variable].dropna().quantile([.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9])\n",
    "print selection5, \" \", len(df_selection5) ,\"people  :\", df_selection5[variable].mean(), df_selection5[variable].median(), df_selection5[variable].max(), df_selection5[variable].min(), df_selection5[variable].dropna().quantile([.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9])\n",
    "print \n",
    "print \"ALL:  \", \" \", len(df_wos) ,\"people  :\",  df_wos[variable].mean(), df_wos[variable].median(), df_wos[variable].max(), df_wos[variable].min(), df_wos[variable].dropna().quantile([.1, .2, .25, .3, .4, .5, .6, .7, .75, .8, .9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print selection1, \"\\t\\t\\t\\t\\t \", len(df_selection1) ,\"people  \",len(df_selection1) /float(len(df_wos))\n",
    "print selection2, \" \\t\", len(df_selection2) ,\"people  \",len(df_selection2) /float(len(df_wos))\n",
    "print selection3, \" \\t\\t\\t\\t\\t\", len(df_selection3) ,\"people  \",len(df_selection3) /float(len(df_wos))\n",
    "print selection4, \" \\t\", len(df_selection4) ,\"people  \",len(df_selection4)/float(len(df_wos))\n",
    "print selection5, \" \\t\\t\\t\\t\\t\", len(df_selection5) ,\"people  \",len(df_selection5) /float(len(df_wos))\n",
    "print \n",
    "print \"ALL:  \", \" \", len(df_wos) ,\"people  :\",  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "48.5*.25+39.4*.25+28.5*.23+28.4*.07+25.4*0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def gini(list_of_values):\n",
    "#     sorted_list = sorted(list_of_values)\n",
    "#     height, area = 0, 0\n",
    "#     for value in sorted_list:\n",
    "#         height += value\n",
    "#         area += height - value / 2.\n",
    "#     fair_area = height * len(list_of_values) / 2.\n",
    "#     try:\n",
    "#         return (fair_area - area) / fair_area\n",
    "#     except ZeroDivisionError:\n",
    "# #         print \"problems with:\",list_of_values   # if lista=[0,0,0]  or [0]\n",
    "# #         raw_input()\n",
    "#         return np.nan\n",
    "\n",
    "\n",
    "    \n",
    "# lista_activity=[11]   \n",
    "    \n",
    "# GINI=gini(lista_activity)\n",
    "# print GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
