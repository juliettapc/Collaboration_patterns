{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "    \n",
    " \n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.15 s, sys: 764 ms, total: 5.92 s\n",
      "Wall time: 8.61 s\n"
     ]
    }
   ],
   "source": [
    "path_merge_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "filename=\"Merged_linkedin-WoS_GS_extra70univ.pickle\"\n",
    "%time df_merged = pd.read_pickle(path_merge_linux+filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in df_merged.columns:\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79948\n"
     ]
    }
   ],
   "source": [
    "aux=df_merged['author_disambig_id_wos'].dropna().tolist()\n",
    "lista_authors_merge = [int(x) for x in aux] \n",
    "print len(lista_authors_merge) #   79948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 100 ms, total: 4.1 s\n",
      "Wall time: 4.85 s\n",
      "# involved papers: 2674932 2674932\n"
     ]
    }
   ],
   "source": [
    "#file_pickle = open(path_merge_linux+\"list_relevant_papers_partial.pickle\",'rb') \n",
    "file_pickle = open(path_merge_linux+\"list_involved_papers_all_lines.pickle\",'rb')        ### num papers:  2674932\n",
    "%time list_involved_papers  = pickle.load(file_pickle)\n",
    "set_list_involved_papers=set(list_involved_papers)\n",
    "\n",
    "print \"# involved papers:\", len(list_involved_papers), len(set_list_involved_papers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### input file (ALL disambiguated WoS)\n",
    "path='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/WoS_data/Disambiguated_authors/'\n",
    "filename='final.tsv'\n",
    "#### tot  number of lines:    34556437\n",
    "\n",
    "nun_lines_testing=50000\n",
    "\n",
    "\n",
    "\n",
    "string_lines=\"_all_lines\"\n",
    "if nun_lines_testing >= 34556437:\n",
    "    print \"tot # lines to read: 34556437    .......\"\n",
    "else:\n",
    "    print \"tot # lines to read:\", nun_lines_testing,\"     .......\"\n",
    "    string_lines=\"_\"+str(nun_lines_testing)+\"lines\"\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "master_dict_author_id_att={}\n",
    "\n",
    "dict_paper_list_authors={}\n",
    "\n",
    "dict_author_dict_paper_seq={}\n",
    "dict_paper_dict_author_seq={}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cont=0\n",
    "cont_included=0\n",
    "with open(path+filename) as f:\n",
    "    for line in  tqdm_notebook(f):  # line is a str  #### one line per WOS author      \n",
    "        line=line.strip(\"\\n\")  #author_id\tuid\tseq\tyear\tauthor_name\taffiliation\ttotal_pubs\n",
    "        #print \"\\n\",line\n",
    "        if cont >0:\n",
    "\n",
    "            flag_write=0\n",
    "            \n",
    "#example:   879592\tWOS:000355773000004|WOS:000340362000001\t1|1\t2015|2014\tBarker, J. G.|Barker, John G.\tNIST, NIST Ctr Neutron Res, Gaithersburg, MD 20899 USA||NIST, Gaithersburg, MD 20899 USA\t2\n",
    "            \n",
    "            if cont == nun_lines_testing:   \n",
    "                  break    \n",
    "         \n",
    "\n",
    "            author_id=int(line.split(\"\\t\")[0] )\n",
    "            \n",
    "            list_uid=line.split(\"\\t\")[1].replace(\"WOS:\",\"\").split(\"|\")  \n",
    "                #list_uid=[x.replace(\"WOS:\",\"\") for x in uid]\n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if   len(set_list_involved_papers & set(list_uid)) >0   :     # i need to take into account also authors not from Linkedin but who are their co-authors!!   \n",
    "            \n",
    "                cont_included +=1\n",
    "                #print cont_included\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "                seq=line.split(\"\\t\")[2].split(\"|\")\n",
    "                list_seq=[int(x) for x in seq]       # o-index, also, if -1 means ranking unknown for that particular paper               \n",
    " \n",
    "               \n",
    "#                 if -1 in list_seq:\n",
    "#                     print list_seq\n",
    "#                     raw_input()\n",
    "    \n",
    "                \n",
    "                \n",
    "                total_pub=float(line.split(\"\\t\")[6])\n",
    "\n",
    "                \n",
    "                cont_1st=0. # i cant know if last author here because i dont know the number of authors in the paper\n",
    "                for seq in list_seq:\n",
    "                    if seq==0:\n",
    "                        cont_1st +=1.                     \n",
    "                \n",
    "                \n",
    "#                 if len(list_seq)  != len(list_uid):\n",
    "#                     print list_seq\n",
    "#                     print list_uid\n",
    "#                     raw_input()\n",
    "                \n",
    "                dict_author_dict_paper_seq[author_id]={}\n",
    "                for i in range(len(list_uid)):\n",
    "                    paper=list_uid[i]\n",
    "                    rank=list_seq[i]\n",
    "                    \n",
    "                    dict_author_dict_paper_seq[author_id][paper]=rank\n",
    "                                \n",
    "                    try:\n",
    "                        dict_paper_dict_author_seq[paper]\n",
    "                    except KeyError:\n",
    "                        dict_paper_dict_author_seq[paper]={}                                 \n",
    "                                    \n",
    "                    dict_paper_dict_author_seq[paper][author_id]=rank\n",
    "                        \n",
    "                        \n",
    "                                                           \n",
    "                    try:                             \n",
    "                        dict_paper_list_authors[paper]\n",
    "                    except KeyError:\n",
    "                        dict_paper_list_authors[paper]=[]             \n",
    "                        \n",
    "                    dict_paper_list_authors[paper].append(author_id)\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "      \n",
    "                master_dict_author_id_att[author_id]={}             \n",
    "    \n",
    "              \n",
    "                master_dict_author_id_att[author_id]['num_papers']=total_pub                \n",
    "                master_dict_author_id_att[author_id]['papers_1st']=cont_1st\n",
    "                \n",
    "                ##### to be calculated later on:\n",
    "                master_dict_author_id_att[author_id]['papers_last']=0.   \n",
    "                master_dict_author_id_att[author_id]['papers_unique_author']=0.\n",
    "                master_dict_author_id_att[author_id]['coauthors']=[]   # OJO!!!! i also need to include as coauthors those outside the LinkedIn dataset!!!\n",
    "                   \n",
    "                    \n",
    "             \n",
    "                \n",
    "\n",
    "        cont +=1\n",
    "        \n",
    "\n",
    "\n",
    "print \"# lines read (# authors in WoS file):\", cont, \"   included (found from merged file):\", len(master_dict_author_id_att), cont_included\n",
    "print \"# papers involved:\",len(dict_paper_list_authors)\n",
    "\n",
    "print \"# wos authors from merged file:\",len(lista_authors_merge), \"  # authors in dict:\", len(master_dict_author_id_att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(master_dict_author_id_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # i load dict-to-be-filled-in FROM the CLUSTER\n",
    "# # file_pickle = open(path_merge_linux+\"dict_author_dict_paper_seq_all_lines_to_be_filled_in.pickle\",'rb')        ### num papers:  2674932\n",
    "# # %time dict_author_dict_paper_seq_all_lines  = pickle.load(file_pickle)\n",
    "# # print len(dict_author_dict_paper_seq_all_lines)\n",
    "\n",
    "# # file_pickle = open(path_merge_linux+\"dict_paper_dict_author_seq_all_lines_to_be_filled_in.pickle\",'rb')        ### num papers:  2674932\n",
    "# # %time dict_paper_dict_author_seq_all_lines  = pickle.load(file_pickle)\n",
    "# # print len(dict_paper_dict_author_seq_all_lines)\n",
    "\n",
    "# file_pickle = open(path_merge_linux+\"dict_paper_list_authors_all_lines_to_be_filled_in.pickle\",'rb')        ### num papers:  2674932\n",
    "# %time dict_paper_list_authors_all_lines  = pickle.load(file_pickle)\n",
    "# print len(dict_paper_list_authors_all_lines) ###\n",
    "\n",
    "# file_pickle = open(path_merge_linux+\"master_dict_author_id_att_all_lines_to_be_filled_in.pickle\",'rb')        ### num papers:  2674932\n",
    "# %time master_dict_author_id_att_all_lines  = pickle.load(file_pickle)\n",
    "# print len(master_dict_author_id_att_all_lines)###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper_id in dict_paper_list_authors:\n",
    "    list_coathors_current_paper=dict_paper_list_authors[paper_id]\n",
    "    \n",
    "    for author_id in list_coathors_current_paper:\n",
    "        if author_id not in master_dict_author_id_att[author_id]['coauthors']:\n",
    "            master_dict_author_id_att[author_id]['coauthors'].append(author_id)          \n",
    "         \n",
    "    \n",
    "    \n",
    "    \n",
    "# i remove redundancy in list of coauthors     \n",
    "for author_id in master_dict_author_id_att:             \n",
    "       # HOW TO REMOVE ELEMENTS FROM A LIST BY VALUE (WHEN THERE MAY BE REPETITIONS):\n",
    "        #     a = [1, 2, 3, 4, 2, 3, 4, 2, 7, 2]\n",
    "        # >>> a = [x for x in a if x != 2]\n",
    "        \n",
    "        # I REMOVE THE AUTHOR HERSELF FROM THE LIST OF COAUTHORS\n",
    "        master_dict_author_id_att[author_id]['coauthors']=[ x for x in list(set(master_dict_author_id_att[author_id]['coauthors'])) if x != author_id ]  \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_merge_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "\n",
    "\n",
    "filename_pickle=path_merge_linux+\"master_dict_author_id_att\"+string_lines+\".pickle\"    \n",
    "pickle.dump(master_dict_author_id_att, open(filename_pickle, 'wb'))\n",
    "print \"written:\",filename_pickle  \n",
    "print len(master_dict_author_id_att)\n",
    "\n",
    "\n",
    "filename_pickle=path_merge_linux+\"dict_paper_list_authors\"+string_lines+\".pickle\"        \n",
    "pickle.dump(dict_paper_list_authors, open(filename_pickle, 'wb'))\n",
    "print \"written:\",filename_pickle  \n",
    "print len(dict_paper_list_authors)\n",
    "\n",
    "\n",
    "filename_pickle=path_merge_linux+\"dict_paper_dict_author_seq\"+string_lines+\".pickle\"        \n",
    "pickle.dump(dict_paper_dict_author_seq, open(filename_pickle, 'wb'))\n",
    "print \"written:\",filename_pickle  \n",
    "print len(dict_paper_dict_author_seq)\n",
    "\n",
    "\n",
    "filename_pickle=path_merge_linux+\"dict_author_dict_paper_seq\"+string_lines+\".pickle\"        \n",
    "pickle.dump(dict_author_dict_paper_seq, open(filename_pickle, 'wb'))\n",
    "print \"written:\",filename_pickle  \n",
    "print len(dict_author_dict_paper_seq)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for author in master_dict_author_id_att:\n",
    "    if len(master_dict_author_id_att[author]['coauthors'])>0:\n",
    "        print author, master_dict_author_id_att[author]\n",
    "        print \"author-paper seq\",dict_author_dict_paper_seq[author]\n",
    "        for paper in dict_author_dict_paper_seq[author]:\n",
    "            print paper, dict_paper_dict_author_seq[paper]\n",
    "        raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_author_dict_paper_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_paper_dict_author_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_dict_author_id_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
