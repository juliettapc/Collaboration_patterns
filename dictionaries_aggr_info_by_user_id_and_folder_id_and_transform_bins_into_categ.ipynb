{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle  ##################################\n",
    "   #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "import time  \n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "##### for getting geolocation data  and to calculate distance between two geolocations\n",
    "import requests\n",
    "import json\n",
    "import geopy.distance   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time.sleep(36000)    # waiting time in seconds\\n\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403349, 38)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file = 'Dropbox_datafile_complete_new_ranking.csv'\n",
    "#input_file = 'Dropbox_datafile_may22_2017_modified_added_univ_country_geolocation_RUCC_population_density_when_available_career_stage_GINI_folder_act_categories.csv'\n",
    "df = pd.read_csv(path+input_file, sep=';',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(df[df.folder_id == 768713].Cleaned_university_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#df.shape\n",
    "#df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1'],inplace=True,axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.world_ranking.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_var_dict_bins_categories={}\n",
    "dict_var_dict_bins_categories[\"group_total_publ\"]={}\n",
    "dict_var_dict_bins_categories[\"group_num_papers_last\"]={}\n",
    "dict_var_dict_bins_categories[\"group_num_citations\"]={}\n",
    "\n",
    "\n",
    "\n",
    "dict_var_dict_bins_categories[\"group_total_publ\"][\"1.0-2.0\"]=1\n",
    "dict_var_dict_bins_categories[\"group_total_publ\"][\"2.0-8.0\"]=2\n",
    "dict_var_dict_bins_categories[\"group_total_publ\"][\"8.0-22.0\"]=3\n",
    "dict_var_dict_bins_categories[\"group_total_publ\"][\"22.0-56.0\"]=4\n",
    "dict_var_dict_bins_categories[\"group_total_publ\"][\"56.0-1350.0\"]=5\n",
    "\n",
    "\n",
    "\n",
    "dict_var_dict_bins_categories[\"group_num_papers_last\"][\"0.0-1.0\"]=1\n",
    "dict_var_dict_bins_categories[\"group_num_papers_last\"][\"1.0-5.0\"]=2\n",
    "dict_var_dict_bins_categories[\"group_num_papers_last\"][\"5.0-18.0\"]=3\n",
    "dict_var_dict_bins_categories[\"group_num_papers_last\"][\"18.0-1216.0\"]=4\n",
    "\n",
    "\n",
    "\n",
    "dict_var_dict_bins_categories[\"group_num_citations\"][\"0.0-1.0\"]=1\n",
    "dict_var_dict_bins_categories[\"group_num_citations\"][\"1.0-30.0\"]=2\n",
    "dict_var_dict_bins_categories[\"group_num_citations\"][\"30.0-229.0\"]=3\n",
    "dict_var_dict_bins_categories[\"group_num_citations\"][\"229.0-1183.0\"]=4\n",
    "dict_var_dict_bins_categories[\"group_num_citations\"][\"1183.0-146545.0\"]=5\n",
    "\n",
    "\n",
    "\n",
    "# group_total_publ\n",
    "# 1.0-2.0        84560\n",
    "# 2.0-8.0        42471\n",
    "# 8.0-22.0       51958\n",
    "# 22.0-56.0      66337\n",
    "# 56.0-1350.0    70420\n",
    "\n",
    "# group_num_papers_last\n",
    "# 0.0-1.0        102479\n",
    "# 1.0-5.0         51978\n",
    "# 5.0-18.0        74631\n",
    "# 18.0-1216.0     86658\n",
    "\n",
    "\n",
    "# group_num_citations\n",
    "# 0.0-1.0            72323\n",
    "# 1.0-30.0           48710\n",
    "# 30.0-229.0         57632\n",
    "# 229.0-1183.0       64114\n",
    "# 1183.0-146545.0    72967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_nans(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass            \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "############################3\n",
    "\n",
    "\n",
    "\n",
    "def remove_nans_for_strings(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(lista[i])\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "             aux_lista.append(lista[i])#pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "\n",
    "def remove_nans_replace_by_zeros(lista):\n",
    "   # print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                aux_lista.append(0.)        #pass#print \"nan found\"\n",
    "            else: # (when not-nan):           \n",
    "                aux_lista.append(float(lista[i]))\n",
    "            #print \"no problem\"\n",
    "        except : ## whenever it is a STR            \n",
    "            pass             \n",
    "            \n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### get dict with  folder_id lifespan:\n",
    "def remove_nans_replace_intervals_with_starting_value(lista):\n",
    "    #print \"\\n\",lista\n",
    "    aux_lista=[]\n",
    "    for i in range(len(lista)):    \n",
    "       # print lista[i]\n",
    "        try:\n",
    "            if np.isnan(lista[i]) == True:  # (when/ nan):   # OJO!!! NO SIRVE SI HAGO: if lista[I]== np.nan   :(   !!!\n",
    "                pass#print \"nan found\"\n",
    "        except TypeError: # (when not-nan):\n",
    "            #print lista[i]   \n",
    "            try:  \n",
    "                aux_lista.append(float(lista[i]))\n",
    "                #print \"no problem\"\n",
    "            except ValueError:  # sometimes, the ranking is 75-82\n",
    "                #print \"issue found\"\n",
    "                value=lista[i]\n",
    "#                 v1=float(value.split(\"-\")[0])\n",
    "#                 v2=float(value.split(\"-\")[1])\n",
    "                \n",
    "                new_value=float(value.split(\"-\")[0])#np.median([v1,v2])  \n",
    "                aux_lista.append(new_value)\n",
    "            \n",
    "    #print aux_lista   \n",
    "    return aux_lista\n",
    "\n",
    "\n",
    "######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliaponcela/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/home/juliaponcela/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning:\n",
      "\n",
      "Degrees of freedom <= 0 for slice\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Unnamed: 0.1', u'folder_id',\n",
    "#        u'num_folder_members', u'folder_creation_date', u'date_last_change',\n",
    "#        u'user_id', u'email_domain', u'num_adds', u'num_edits', u'num_deletes',\n",
    "#        u'major_content_type', u'major_content_ext', u'group_total_publ',\n",
    "#        u'group_num_papers_last', u'group_num_citations', u'folder_lifespan',\n",
    "#        u'simplified_domain', u'University_Name', u'Cleaned_university_name',\n",
    "#        u'Country', u'Geolocation', u'lat', u'long', u'zip',\n",
    "#        u'Rural_Urban_Continuum_Code', u'State_Name', u'Description',\n",
    "#        u'Population_2010', u'Land-Sq-Mi', u'Density_Per_Sq_Mile',\n",
    "#        u'world_ranking', u'national_ranking', u'career_stage',\n",
    "#        u'median_num_publ', u'median_num_last_auth', u'folder_activity_GINI',\n",
    "#        u'category_total_publ', u'category_total_last_auth',\n",
    "#        u'category_total_cit'],\n",
    "#       dtype='object')\n",
    "\n",
    "################\n",
    "\n",
    "#to get dict for the folder_id vs lifespan    'folder_lifespan'\n",
    "\n",
    "def grouping(input_df,dict_folder_id_folder_attr):\n",
    "    #print input_df\n",
    "   \n",
    "    folder_id=input_df.folder_id.iloc[0]\n",
    "    dict_folder_id_folder_attr[folder_id]={}\n",
    "    \n",
    "    folder_lifespan=input_df.folder_lifespan.iloc[0]\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_lifespan\"]=folder_lifespan\n",
    "    \n",
    "    \n",
    "    num_folder_members=input_df.num_folder_members.iloc[0]\n",
    "    dict_folder_id_folder_attr[folder_id][\"num_folder_members\"]=num_folder_members\n",
    "    \n",
    "    \n",
    "    list_univ_rankings=remove_nans(list(input_df.world_ranking))\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_univ_median_ranking\"]=np.median(list_univ_rankings)\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_univ_SD_ranking\"]=np.std(list_univ_rankings)\n",
    "    dict_folder_id_folder_attr[folder_id][\"list_ranking\"]=list(input_df.world_ranking)\n",
    "    dict_folder_id_folder_attr[folder_id][\"list_univ\"]=list(input_df.Cleaned_university_name)\n",
    "    dict_folder_id_folder_attr[folder_id][\"list_countries\"]=list(input_df.Country)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"multi_univ_collab\"]=1\n",
    "    lista_univ=list(input_df.Cleaned_university_name.unique())       \n",
    "    dict_folder_id_folder_attr[folder_id][\"multi_univ_collab\"]=len(lista_univ)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dict_folder_id_folder_attr[folder_id][\"num_countries\"]=1\n",
    "    lista_countr=list(input_df.Country.unique())       \n",
    "    dict_folder_id_folder_attr[folder_id][\"num_countries\"]=len(lista_countr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        most_common=max(set(list_univ_rankings), key=list_univ_rankings.count)\n",
    "    except ValueError:  # when empty list\n",
    "        most_common=np.nan\n",
    "    dict_folder_id_folder_attr[folder_id][\"most_common_univ_ranking\"]=most_common\n",
    "    \n",
    "            \n",
    "    \n",
    "    folder_activity_GINI= input_df.folder_activity_GINI.iloc[0]\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_activity_GINI\"]=folder_activity_GINI\n",
    "    \n",
    "    \n",
    "    tot_num_adds=sum(remove_nans_replace_by_zeros(list(input_df.num_adds)))\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_tot_num_adds\"]=tot_num_adds\n",
    "    \n",
    "    \n",
    "    tot_num_edits=sum(remove_nans_replace_by_zeros(list(input_df.num_edits)))\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_tot_num_edits\"]=tot_num_edits\n",
    "    \n",
    "        \n",
    "    tot_num_deletes=sum(remove_nans_replace_by_zeros(list(input_df.num_deletes)))\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_tot_num_deletes\"]=tot_num_deletes\n",
    "    \n",
    "    \n",
    "    tot_act=tot_num_adds+tot_num_edits+tot_num_deletes\n",
    "    dict_folder_id_folder_attr[folder_id][\"folder_tot_act\"]=tot_act\n",
    "    #dict_folder_id_folder_attr[folder_id][\"list_act\"]=list(input_df.num_adds)+list(input_df.num_edits)+list(input_df.num_deletes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lista=remove_nans_for_strings(list(input_df.career_stage))  \n",
    "    try:\n",
    "        most_common=max(set(lista), key=lista.count)\n",
    "    except ValueError:  # when empty list\n",
    "        most_common=np.nan\n",
    "    dict_folder_id_folder_attr[folder_id][\"most_common_career_stage\"]=most_common\n",
    "    \n",
    "    try:    \n",
    "        dict_folder_id_folder_attr[folder_id][\"fraction_SR\"]=lista.count(\"sr\")/float(len(lista))\n",
    "    except ZeroDivisionError:\n",
    "        dict_folder_id_folder_attr[folder_id][\"fraction_SR\"]=np.nan\n",
    "    \n",
    "    #dict_folder_id_folder_attr[folder_id][\"list_careers\"]=list(input_df.career_stage)\n",
    "    \n",
    "    \n",
    "    df_selection1= input_df[input_df['career_stage'] == \"sr\"]\n",
    "    act_sr=sum(remove_nans_replace_by_zeros(list(df_selection1.num_deletes))) +\\\n",
    "    sum(remove_nans_replace_by_zeros(list(df_selection1.num_edits)))+ \\\n",
    "    sum(remove_nans_replace_by_zeros(list(df_selection1.num_adds)))\n",
    "    try:\n",
    "        dict_folder_id_folder_attr[folder_id][\"fraction_work_by_SR\"]=  act_sr/float(tot_act)\n",
    "    except ZeroDivisionError:    \n",
    "        dict_folder_id_folder_attr[folder_id][\"fraction_work_by_SR\"]= np.nan\n",
    "        \n",
    "        \n",
    "    lista=remove_nans_for_strings(list(input_df.career_stage))\n",
    "    if lista.count(\"sr\")==0:\n",
    "        dict_folder_id_folder_attr[folder_id][\"fraction_work_by_SR\"]= np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "                        \n",
    "    lista=remove_nans(list(input_df.category_total_publ))\n",
    "    try:\n",
    "        most_common=max(set(lista), key=lista.count)\n",
    "    except ValueError:  # empty list\n",
    "        most_common=np.nan\n",
    "    dict_folder_id_folder_attr[folder_id][\"most_common_categ_num_publ\"]=most_common\n",
    "    \n",
    "    #print \"\\n\",input_df.category_total_last_auth\n",
    "    lista=remove_nans(list(input_df.category_total_last_auth))\n",
    "    #print \"lista:\",lista\n",
    "    try:\n",
    "        most_common=max(set(lista), key=lista.count)\n",
    "    except ValueError:  # empty list\n",
    "        most_common=np.nan\n",
    "    dict_folder_id_folder_attr[folder_id][\"most_common_categ_num_last_auth\"]=most_common\n",
    "#     print \"most common\", most_common\n",
    "#     raw_input()\n",
    "    \n",
    "     \n",
    "    lista=remove_nans(list(input_df.category_total_cit))\n",
    "    try:\n",
    "        most_common=max(set(lista), key=lista.count)\n",
    "    except ValueError:  # empty list\n",
    "        most_common=np.nan\n",
    "    dict_folder_id_folder_attr[folder_id][\"most_common_num_cit\"]=most_common\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    " \n",
    " ##########################\n",
    "\n",
    "\n",
    "dict_folder_id_folder_attr={}\n",
    "for folder_id in df['folder_id'].unique():\n",
    "    df_selection= df[df['folder_id'] == folder_id]\n",
    "    grouping(df_selection,dict_folder_id_folder_attr)\n",
    "    dict_folder_id_folder_attr[folder_id][\"number_active_members\"]=len(df_selection)\n",
    "    #print folder_id\n",
    "\n",
    "\n",
    "print \"done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'folder_activity_GINI': nan,\n",
       " 'folder_lifespan': 1584,\n",
       " 'folder_tot_act': 0.0,\n",
       " 'folder_tot_num_adds': 0.0,\n",
       " 'folder_tot_num_deletes': 0.0,\n",
       " 'folder_tot_num_edits': 0.0,\n",
       " 'folder_univ_SD_ranking': 0.0,\n",
       " 'folder_univ_median_ranking': 51.0,\n",
       " 'fraction_SR': nan,\n",
       " 'fraction_work_by_SR': nan,\n",
       " 'list_ranking': [51.0, 51.0],\n",
       " 'list_univ': ['university of southern california',\n",
       "  'university of southern california'],\n",
       " 'most_common_career_stage': nan,\n",
       " 'most_common_categ_num_last_auth': nan,\n",
       " 'most_common_categ_num_publ': nan,\n",
       " 'most_common_num_cit': nan,\n",
       " 'most_common_univ_ranking': 51.0,\n",
       " 'multi_univ_collab': 1,\n",
       " 'num_folder_members': 2,\n",
       " 'number_active_members': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dict_folder_id_folder_attr[768713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "\n",
    "#df[['folder_id','folder_creation_date','date_last_change','folder_lifespan','user_id','num_adds', 'num_edits', 'num_deletes', 'group_total_publ', 'group_num_papers_last','group_num_citations', 'folder_lifespan', 'national_ranking', 'career_stage', 'median_num_publ', 'median_num_last_auth','folder_activity_GINI','category_total_publ','category_total_last_auth', 'category_total_cit']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns\n",
    "print sorted( df.world_ranking.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr.pickle\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr.csv\n"
     ]
    }
   ],
   "source": [
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_id_folder_attr.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_folder_id_folder_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_folder_id_folder_attr,orient='index')\n",
    "df_from_dict.to_csv(pickle_name.strip(\"dict_\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.strip(\"dict_\").strip(\".pickle\")+\".csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_from_dict.drop('list_careers', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_from_dict.head(100)\n",
    "#df_folder_aggr = pd.DataFrame.from_dict(dict_folder_id_folder_attr,orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dict_folder_id_folder_attr[592732]\n",
    "df_from_dict.fraction_SR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Unnamed: 0.1', u'folder_id',\n",
    "#        u'num_folder_members', u'folder_creation_date', u'date_last_change',\n",
    "#        u'user_id', u'email_domain', u'num_adds', u'num_edits', u'num_deletes',\n",
    "#        u'major_content_type', u'major_content_ext', u'group_total_publ',\n",
    "#        u'group_num_papers_last', u'group_num_citations', u'folder_lifespandict_user_id_user_attr[user_id][\"user_univ_ranking\"]=univ_ra',\n",
    "#        u'simplified_domain', u'University_Name', u'Cleaned_university_name',\n",
    "#        u'Country', u'Geolocation', u'lat', u'long', u'zip',\n",
    "#        u'Rural_Urban_Continuum_Code', u'State_Name', u'Description',\n",
    "#        u'Population_2010', u'Land-Sq-Mi', u'Density_Per_Sq_Mile',\n",
    "#        u'world_ranking', u'national_ranking', u'career_stage',\n",
    "#        u'median_num_publ', u'median_num_last_auth', u'folder_activity_GINI',\n",
    "#        u'category_total_publ', u'category_total_last_auth',\n",
    "#        u'category_total_cit'],\n",
    "#       dtype='object')\n",
    "\n",
    "\n",
    "          \n",
    "            \n",
    "          \n",
    "\n",
    "################\n",
    "\n",
    "#to get dict for the user_id vs attr\n",
    "\n",
    "def grouping(input_df,dict_user_id_user_attr):\n",
    "    #print input_df\n",
    "   \n",
    "    user_id=input_df.user_id.iloc[0]\n",
    "    dict_user_id_user_attr[user_id]={}\n",
    "    \n",
    "    \n",
    "    dict_user_id_user_attr[user_id][\"mean_folder_lifespan\"]=np.mean(list(input_df.folder_lifespan))\n",
    "    \n",
    "  \n",
    "    \n",
    "    try:\n",
    "        univ_ranking=float(input_df.world_ranking.iloc[0])\n",
    "    except ValueError:  # if 101-150\n",
    "        univ_ranking=float(input_df.world_ranking.iloc[0].split(\"-\")[0])\n",
    "    dict_user_id_user_attr[user_id][\"user_univ_ranking\"]=univ_ranking\n",
    "    \n",
    "    \n",
    "#     folder_activity_GINI= input_df.folder_activity_GINI.iloc[0]\n",
    "#     dict_user_id_user_attr[user_id][\"folder_activity_GINI\"]=folder_activity_GINI\n",
    "    \n",
    "    \n",
    "    tot_num_adds=sum(remove_nans_replace_by_zeros(list(input_df.num_adds)))\n",
    "    dict_user_id_user_attr[user_id][\"user_tot_num_adds\"]=tot_num_adds\n",
    "    \n",
    "    \n",
    "    tot_num_edits=sum(remove_nans_replace_by_zeros(list(input_df.num_edits)))\n",
    "    dict_user_id_user_attr[user_id][\"user_tot_num_edits\"]=tot_num_edits\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########  FALTA CREAR: NUMERO TOTAL DE COLABORADORES (UNIQUE USER_IDS, NOT NUM_FOLDER_MEMBERS)\n",
    "    \n",
    "    \n",
    "        \n",
    "    tot_num_deletes=sum(remove_nans_replace_by_zeros(list(input_df.num_deletes)))\n",
    "    dict_user_id_user_attr[user_id][\"user_tot_num_deletes\"]=tot_num_deletes\n",
    "    \n",
    "    \n",
    "    tot_act=tot_num_adds+tot_num_edits+tot_num_deletes\n",
    "    dict_user_id_user_attr[user_id][\"user_tot_act\"]=tot_act\n",
    "    \n",
    "    \n",
    "    career_stage=input_df.career_stage.iloc[0]   \n",
    "    dict_user_id_user_attr[user_id][\"career_stage\"]=career_stage\n",
    "                \n",
    "    \n",
    "    category_total_publ=input_df.category_total_publ.iloc[0]       \n",
    "    dict_user_id_user_attr[user_id][\"category_total_publ\"]=category_total_publ\n",
    "    \n",
    "    \n",
    "    category_total_last_auth=input_df.category_total_last_auth.iloc[0]       \n",
    "    dict_user_id_user_attr[user_id][\"category_total_last_auth\"]=category_total_last_auth\n",
    "    \n",
    "   \n",
    "    category_total_cit=input_df.category_total_cit.iloc[0]      \n",
    "    dict_user_id_user_attr[user_id][\"category_total_cit\"]=category_total_cit\n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    " \n",
    " #########################\n",
    "\n",
    "\n",
    "dict_user_id_user_attr={}\n",
    "for user_id in df['user_id'].unique():\n",
    "    df_selection= df[df['user_id'] == user_id]\n",
    "    grouping(df_selection,dict_user_id_user_attr)\n",
    "    #print folder_id\n",
    "    dict_user_id_user_attr[user_id][\"number_folders\"]=len(df_selection)\n",
    "\n",
    "print \"done\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head(100).sort_values(by=\"user_id\", axis=0, ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr.pickle'\n",
    "with open(pickle_name, 'wb') as handle:\n",
    "    pickle.dump(dict_user_id_user_attr, handle)\n",
    "print \"written:\", pickle_name\n",
    "\n",
    "df_from_dict = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "df_from_dict.to_csv(pickle_name.strip(\"dict_\").strip(\".pickle\")+\".csv\", sep=';')\n",
    "print \"written:\", pickle_name.strip(\"dict_\").strip(\".pickle\")+\".csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for user in dict_user_id_user_attr:\n",
    "#     if dict_user_id_user_attr[user]['category_total_cit']>2:\n",
    "#         print dict_user_id_user_attr[user]\n",
    "#         raw_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
