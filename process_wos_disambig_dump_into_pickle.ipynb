{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# from tqdm import tnrange, tqdm_notebook\n",
    "# from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "from IPython.core.display import display,HTML\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 4.25 s, total: 1min 27s\n",
      "Wall time: 2min 20s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>year</th>\n",
       "      <th>author_names</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>total_pubs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14972627</td>\n",
       "      <td>1973|1980|1983|1992|1993|1994|1995|1996|2000|2...</td>\n",
       "      <td>Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|...</td>\n",
       "      <td>Univ Milan, I-20122 Milan, Italy|OSPED CAMPOSA...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8198127</td>\n",
       "      <td>1971|1973|1987|1989|1990|1991|1993|1994|1995|1...</td>\n",
       "      <td>Johnson, TM|JOHNSON, TM|Johnson, T|JOHNSON, T|...</td>\n",
       "      <td>UTAH STATE UNIV,DEPT BIOL,LOGAN,UT 84322|UNIV ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>879592</td>\n",
       "      <td>2014|2015</td>\n",
       "      <td>Barker, J. G.|Barker, John G.</td>\n",
       "      <td>NIST, NIST Ctr Neutron Res, Gaithersburg, MD 2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id                                               year  \\\n",
       "0   14972627  1973|1980|1983|1992|1993|1994|1995|1996|2000|2...   \n",
       "1    8198127  1971|1973|1987|1989|1990|1991|1993|1994|1995|1...   \n",
       "2     879592                                          2014|2015   \n",
       "\n",
       "                                        author_names  \\\n",
       "0  Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|...   \n",
       "1  Johnson, TM|JOHNSON, TM|Johnson, T|JOHNSON, T|...   \n",
       "2                      Barker, J. G.|Barker, John G.   \n",
       "\n",
       "                                        affiliations  total_pubs  \n",
       "0  Univ Milan, I-20122 Milan, Italy|OSPED CAMPOSA...         116  \n",
       "1  UTAH STATE UNIV,DEPT BIOL,LOGAN,UT 84322|UNIV ...          24  \n",
       "2  NIST, NIST Ctr Neutron Res, Gaithersburg, MD 2...           2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### code to reformat the WoS text file (where all columns are STRINGS, since it is a cvs filem, even if they look like lists...!), \n",
    "##    and create a pickled dataframe for later merging with linkedin data\n",
    "\n",
    "\n",
    "fields = ['author_id','year','author_name','affiliation','total_pubs']  # i only upload certain fields\n",
    "#fields = ['author_id','uid','seq','year','author_name','affiliation','total_pubs']\n",
    "\n",
    "\n",
    "#path_wos_win='C:\\\\Users\\\\julietta\\\\Work\\\\Dropbox_studies\\\\Data\\\\WoS_data\\\\Disambiguated_authors\\\\'\n",
    "path_wos_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/WoS_data/Disambiguated_authors/'\n",
    "\n",
    "#%time df_disamb_wos_test=pd.read_csv(path_wos_linux+'only_USA_active_years_2000-2015_filtered_WoS_file.tsv', usecols=fields, sep=\"\\t\")#, nrows=100000)\n",
    "%time df_disamb_wos_test=pd.read_csv(path_wos_linux+'only_USA_active_years_2005-2015_filtered_WoS_file_simplified.tsv', usecols=fields, sep=\"\\t\")#, nrows=100000)\n",
    "\n",
    "df_disamb_wos_test.rename(columns={'affiliation':'affiliations'}, inplace=True) \n",
    "df_disamb_wos_test.rename(columns={'author_name':'author_names'}, inplace=True) \n",
    "#df_disamb_wos_test.rename(columns={'seq':'seqs'}, inplace=True) \n",
    "\n",
    "\n",
    "# fields = ['author_id','uid','seq','year','author_name','affiliation','total_pubs']\n",
    "\n",
    "# df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)\n",
    "\n",
    "df_disamb_wos_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6457847, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_disamb_wos_test.author_names.iloc[0]\n",
    "#df_disamb_wos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_department_names(string):\n",
    "    \n",
    "    #raw_input()\n",
    "   #print \"\\n\\nORIGINAL:\",string  \n",
    "    \n",
    "\n",
    "        #example of complete affiliation for one author\n",
    "        ####   || separates papers, | separates multiple affil for the same author in a paper, _?_ means affill not sure (ambiguity)\n",
    "         ### there are as many affill (sep by ||) as unique affil for an author (not necesarily as many as papers!!!)\n",
    "        \n",
    "    # #         Univ Edinburgh, Queens Med Res Inst, Ctr Inflammat Res, MRC, Edinburgh EH16 4TJ, Midlothian, Scotland||\n",
    "    # _?_Brigham & Womens Hosp, Ctr Expt Therapeut & Reperfus Injury, Boston, MA 02115 USA|\n",
    "    # Harvard Univ, Sch Med, Dept Oral Med Infect & Immun, Harvard Sch Dent Med, Boston, MA 02115 USA|\n",
    "    # Kings Coll London, Div Cardiovasc, London WC2R 2LS, England|\n",
    "    # UCL, Ctr Clin Pharmacol & Therapeut, Div Med, London, England|\n",
    "    # Univ Edinburgh, MRC Ctr Inflammat Res, Queens Med Res Inst, Edinburgh, Midlothian, Scotland|\n",
    "    # Trinity Coll Dublin, Sch Biochem & Immunol, Dublin, Ireland|\n",
    "    # Queen Mary Univ London, William Harvey Res Inst, London, England|\n",
    "    # Univ Calgary, Inflammat Res Network, Calgary, AB, Canada||\n",
    "    # Univ Edinburgh, Queens Med Res Inst, Ctr Inflammat Res, MRC, Edinburgh, Midlothian, Scotland||\n",
    "    # Univ Edinburgh, Queens Med Res Inst, Med Res Council Ctr Inflammat Res, Edinburgh, Midlothian, Scotland||\n",
    "    # Univ Edinburgh, MRC, Queens Med Res Inst, Ctr Inflammat Res, Edinburgh, Midlothian, Scotland||\n",
    "    # _?_Univ Modena, Dipartimento Med & Special Med, Div Med 3, Policlin, I-41100 Modena, Italy\n",
    " \n",
    "   \n",
    "   \n",
    "           \n",
    "    string= string.replace(\"||\",\"|\").replace(\"_?_\",\"\").replace(\"?\",\"\").replace(\"||\",\"|\").strip(\"|\").strip().title()\n",
    "         \n",
    "        \n",
    "#     print    \n",
    "#     print string\n",
    "        \n",
    "#     if \"Dept \" in string or \"Sch\" in string  or \"Coll\" in string or \"Inst\" in string or \"Hosp\" in string:\n",
    "                 \n",
    "    string=string.replace(\"Dept \",\"Department \")\n",
    "    string=string.replace(\"Dept,\",\"Department,\")\n",
    "    #new_string=new_string.replace(\"Med,\",\"Medicine,\")\n",
    "    string=string.replace(\"Sch \",\"School \")\n",
    "    string=string.replace(\"Sch,\",\"School,\")\n",
    "    string=string.replace(\"Coll \",\"College \")\n",
    "    string=string.replace(\"Coll,\",\"College, \")\n",
    "    string=string.replace(\"Hosp,\",\"Hospital,\")\n",
    "    string=string.replace(\"Hosp \",\"Hospital \")\n",
    "    string=string.replace(\"Inst,\",\"Institute,\")\n",
    "    string=string.replace(\"Inst \",\"Institute \")\n",
    "    string=string.replace(\"Ctr \",\"Center \")\n",
    "    string=string.replace(\"Ctr,\",\"Center,\")            \n",
    "    \n",
    "    \n",
    "#     print \"\\n\\nORIGINAL:\",string  \n",
    "          \n",
    "            \n",
    "            \n",
    "    #     ['Osped S Carlo, UO Oncol Med, Potenza, Italy', 'Osped Civile, UO Oncol Med, Nola, Na, Italy', \n",
    "    #      'Univ Edinburgh, Queens Med Res Institute, Center Inflammat Res, Edinburgh, Midlothian, Scotland', \n",
    "    #      'MRC, Edinburgh, Midlothian, Scotland', 'Univ Edinburgh, School Med, MRC Center Inflammat Res, Queens Med Res Institute, Edinburgh EH16 4TJ, Midlothian, Scotland', \n",
    "    #      'Univ Highlands and Islands, Inverness IV2 3BL, Scotland', 'OSPED MAGGIORE CA PIZZARDI,ENTE OSPED REG,SERV FIS SANITARIA,BOLOGNA,ITALY', \n",
    "    #      'Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland', 'Univ Edinburgh, School Med, Queens Med Res Institute, Center Inflammat Res,MRC, Edinburgh, Midlothian, Scotland']\n",
    "\n",
    "    \n",
    "    \n",
    "    new_string_list= string.split(\"|\")              \n",
    "\n",
    "#     print \"LISTA:\",new_string_list\n",
    "\n",
    "    flag_return=0\n",
    "    lista_dept=[]\n",
    "    for i in range(len(new_string_list)):\n",
    "        \n",
    "        try:\n",
    "            dept=new_string_list[i].split(\",\")[1].strip()\n",
    "        except IndexError:\n",
    "            dept=\"\"\n",
    "            print new_string_list[i]\n",
    "            #raw_input()\n",
    "       \n",
    "        if \"Department\" in dept: \n",
    "           lista_dept.append(dept)\n",
    "           flag_return=1 \n",
    "        elif \"Sch\" in dept  :\n",
    "            lista_dept.append(dept)\n",
    "            flag_return=1\n",
    "        elif \"Coll\" in dept :\n",
    "            lista_dept.append(dept)\n",
    "            flag_return=1#print df_disamb_wos_test['author_names'].iloc[10]    # list with one single element, including all name spellings for an author:    ['Fransen, C.|Fransen, Ch|Fransen, C']\n",
    "    \n",
    "        elif \"Inst\" in dept :\n",
    "            lista_dept.append(dept)\n",
    "            flag_return=1\n",
    "        elif \"Hosp\" in dept  :\n",
    "            lista_dept.append(dept)\n",
    "            flag_return=1\n",
    "        elif \"Lab\" in dept :\n",
    "            lista_dept.append(dept)\n",
    "            flag_return=1\n",
    "        elif \"Center\" in dept:\n",
    "            lista_dept.append(dept)\n",
    "            flag_return=1\n",
    "\n",
    "    \n",
    "    if flag_return >0:\n",
    "#         print  \"-----------\",list(set(lista_dept))  # i get all the unique dept   \n",
    "#         raw_input()\n",
    "        return list(set(lista_dept))\n",
    "    else:\n",
    "        #print None\n",
    "        return None\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "########################\n",
    "#####################\n",
    "\n",
    "#print df_disamb_wos_test['author_names'].iloc[10]    # list with one single element, including all name spellings for an author:    ['Fransen, C.|Fransen, Ch|Fransen, C']\n",
    "# for item in df_disamb_wos_test['author_names'].iloc[10]:\n",
    "#     print item\n",
    "    \n",
    "\n",
    "\n",
    "def fix_university_names(string):\n",
    "  \n",
    "#     print \"ORIGINAL:  \",string\n",
    "\n",
    "    #new_string= string.replace(\"||?||\",\"\").replace(\"||\",\"\\r\\n \").replace(\"|\",\"\\r\\n \").replace(\"_?_\",\"\")\n",
    "    new_string= string.replace(\"||\",\"|\").replace(\"_?_\",\"\").replace(\"?\",\"\").replace(\"||\",\"|\").strip(\"|\").title()\n",
    "    \n",
    "      \n",
    "    new_string=new_string.replace(\"Mit\",\"Massachusetts Institute of Technology\")\n",
    "    new_string=new_string.replace(\"Georgia Inst Technol\",\"Georgia Institute of Technology\")\n",
    "    new_string=new_string.replace(\"Penn State\",\"Pennsylvania State\")\n",
    "    new_string=new_string.replace(\"Univ Calif Berkeley\",\"University of California Berkeley\")\n",
    "    new_string=new_string.replace(\"Univ Calif Los Angeles\",\"University of California Los Angeles\")\n",
    "    new_string=new_string.replace(\"Univ Calif Davis\",\"University of California Davis\")\n",
    "    new_string=new_string.replace(\"Univ Calif San Diego\",\"University of California San Diego\")\n",
    "    new_string=new_string.replace(\"Penn State Univ,\",\"Pennsylvania State University,\")\n",
    "    new_string=new_string.replace(\"Univ So Calif\",\"University of Southern California\")\n",
    "    new_string=new_string.replace(\"NYU\",\"New York University\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    new_string=new_string.replace('Univ,','University,')\n",
    "    new_string=new_string.replace('Univ ','University ')\n",
    "    \n",
    "    new_string=new_string.replace('Natl,','National,')\n",
    "    new_string=new_string.replace('Natl ','National ')\n",
    "    \n",
    "    new_string=new_string.replace('Hosp,','Hospital,')\n",
    "    new_string=new_string.replace('Hosp ','Hospital ')\n",
    "   \n",
    "    new_string=new_string.replace(\"Sch \",\"School \")\n",
    "    new_string=new_string.replace(\"Sch,\",\"School,\")\n",
    "    \n",
    "    new_string=new_string.replace(\"Coll \",\"College \")\n",
    "    new_string=new_string.replace(\"Coll,\",\"College, \")\n",
    "\n",
    "    new_string=new_string.replace(\"Inst,\",\"Institute,\")\n",
    "    new_string=new_string.replace(\"Inst \",\"Institute \")\n",
    "    \n",
    "    new_string=new_string.replace(\"Ctr \",\"Center \")\n",
    "    new_string=new_string.replace(\"Ctr,\",\"Center,\")  \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    new_string=new_string.strip()\n",
    "    \n",
    "    new_string_list= new_string.split(\"|\")\n",
    "    for i in range(len(new_string_list)):\n",
    "        new_string_list[i]=new_string_list[i].split(\",\")[0]\n",
    "   \n",
    "#     print          \n",
    "#     print \"AFTER:   \",list(set(new_string_list))\n",
    "#     print \n",
    "#     raw_input()#print df_disamb_wos_test['author_names'].iloc[10]    # list with one single element, including all name spellings for an author:    ['Fransen, C.|Fransen, Ch|Fransen, C']\n",
    "# for item in df_disamb_wos_test['author_names'].iloc[10]:\n",
    "#     print item\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return list(set(new_string_list))\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_first_name_initial(string):    # example of string:      'Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|Rossi, A|Rossi, AG|ROSSI, AG|Rossi, A.|ROSSI, A'\n",
    "    \n",
    "    if \",\" not in string:       \n",
    "        if \" \" in string:            \n",
    "            string = string.replace(\" \",\", \")   # chinese people at NICO told me that most names without a comma look like they have the format: LAST FIRST\n",
    "      \n",
    "        \n",
    "    \n",
    "    try:                              \n",
    "        new_string = string.split(\"|\")[0].split(\",\")[1].replace(\".\",\"\").strip().lower()        \n",
    "        return new_string[0]       \n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_first_name_or_initial(string):    # example of string:   'Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|Rossi, A|Rossi, AG|ROSSI, AG|Rossi, A.|ROSSI, A'\n",
    "    \n",
    "    try:\n",
    "        #print string            \n",
    "        \n",
    "        lista_candidatos=[]\n",
    "        \n",
    "        for item in string.split(\"|\"):\n",
    "            \n",
    "            if \",\" not in item:       \n",
    "                if \" \" in item:            \n",
    "                    item=item.replace(\" \",\", \")   # chinese people at NICO told me that most names without a comma look like they have the format: LAST FIRST\n",
    "                                 \n",
    "            lista_candidatos.append(item.replace(\".\",\"\").split(\",\")[1].strip().lower())\n",
    "        \n",
    "        new_string = max(lista_candidatos, key=len)  # ipick the longes first name \n",
    "       \n",
    "        return new_string\n",
    "    \n",
    "    except :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_middle_initial(string):    # example of string:   'Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|Rossi, A|Rossi, AG|ROSSI, AG|Rossi, A.|ROSSI, A'\n",
    "    \n",
    "   \n",
    "           \n",
    "        \n",
    "    new_string=None\n",
    "        \n",
    "    #try:\n",
    "    lista_candidatos=[\"\"]\n",
    "\n",
    "    for item in string.split(\"|\"):\n",
    "\n",
    "        if \",\" not in item:       \n",
    "            if \" \" in item:            \n",
    "                item=item.replace(\" \",\", \")   # chinese people at NICO told me that most names without a comma look like they have the format: LAST FIRST\n",
    "        try:                     \n",
    "            lista_candidatos.append(item.replace(\".\",\"\").split(\",\")[1].strip().lower().split(\" \")[1]   )\n",
    "\n",
    "        except IndexError: pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        new_string = max(lista_candidatos, key=len)  # ipick the longes first name \n",
    "\n",
    "        return new_string\n",
    "    except TypeError:pass\n",
    "\n",
    "   # except  TypeError: pass      # for the cases where there is no info   \n",
    "   \n",
    "       \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-e15de9cfb912>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-e15de9cfb912>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    http://www.mccormick.northwestern.edu/research-faculty/directory/profiles/zhang-haoqi.htm\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_only_firstname(string):     #   'Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|Rossi, A|Rossi, AG|ROSSI, AG|Rossi, A.|ROSSI, A'\n",
    "   \n",
    "       \n",
    "        \n",
    "    lista_candidatos=[\"\"]\n",
    "\n",
    "    for item in string.split(\"|\"):\n",
    "\n",
    "        if \",\" not in item:       \n",
    "            if \" \" in item:            \n",
    "                item=item.replace(\" \",\", \")   # chinese people at NICO told me that most names without a comma look like they have the format: LAST FIRST\n",
    "\n",
    "\n",
    "        try:\n",
    "            lista_candidatos.append(item.replace(\".\",\"\").split(\",\")[1].strip().lower().split(\" \")[0]    )\n",
    "        except IndexError: pass\n",
    "    try:\n",
    "        new_string = max(lista_candidatos, key=len)  # ipick the longes first name \n",
    "\n",
    "        return new_string\n",
    "    except TypeError:pass\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_lastname(string):\n",
    "  \n",
    "      \n",
    "\n",
    "    lista_candidatos=[\"\"]\n",
    "\n",
    "    for item in string.split(\"|\"):\n",
    "\n",
    "        if \",\" not in item:       \n",
    "            if \" \" in item:            \n",
    "                item=item.replace(\" \",\", \")   # chinese people at NICO told me that most names without a comma look like they have the format: LAST FIRST\n",
    "\n",
    "        lista_candidatos.append(item.replace(\".\",\"\").split(\",\")[0].strip().lower())\n",
    "\n",
    "    try:\n",
    "        new_string = max(lista_candidatos, key=len)  # ipick the longes first name \n",
    "\n",
    "        return new_string\n",
    "    \n",
    "    except TypeError: pass\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_disamb_wos_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fce11676dff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"time df_disamb_wos_test['Department'] = df_disamb_wos_test.affiliations.apply(get_department_names)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Department done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-0b6cd7be9a34>\u001b[0m in \u001b[0;36mget_department_names\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dept,\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Department,\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#new_string=new_string.replace(\"Med,\",\"Medicine,\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sch \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"School \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sch,\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"School,\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coll \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"College \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "      \n",
    "# FALTA:      \"España - Wikimedia Commons\".replace(\"ñ\",\"n\")\n",
    "\n",
    " \n",
    "   \n",
    "\n",
    "# ###### i add  new columns with processed info: \n",
    "## example (it is a string):  'Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|Rossi, A|Rossi, AG|ROSSI, AG|Rossi, A.|ROSSI, A'\n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "%time df_disamb_wos_test['Department'] = df_disamb_wos_test.affiliations.apply(get_department_names)\n",
    "\n",
    "print \"Department done\"     \n",
    "   \n",
    "    \n",
    "\n",
    "df_disamb_wos_test['firstname'] = df_disamb_wos_test.author_names.apply(get_only_firstname)\n",
    "\n",
    "print \"only firstname done\"                \n",
    "    \n",
    "    \n",
    "df_disamb_wos_test['firstname_initial'] = df_disamb_wos_test.author_names.apply(get_first_name_initial)\n",
    "df_disamb_wos_test['middle'] = df_disamb_wos_test.author_names.apply(get_middle_initial)\n",
    "\n",
    "\n",
    "print \"first and middle initial done\"          \n",
    "     \n",
    "\n",
    "df_disamb_wos_test['lastname'] = df_disamb_wos_test.author_names.apply(get_lastname)\n",
    "\n",
    "print \"lastnames done\"   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "df_disamb_wos_test['list_author_names'] = df_disamb_wos_test.apply(lambda row: list(set(row.author_names.lower().replace(\".|\",\"|\").replace(\". \",\".\").replace(\".\",\" \").split(\"|\"))), axis=1)\n",
    "\n",
    "print \"list_author_names done\"     \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "%time df_disamb_wos_test['University'] = df_disamb_wos_test.affiliations.apply(fix_university_names)\n",
    " \n",
    "print \"University done\"      \n",
    "    \n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "df_disamb_wos_test['list_years'] = df_disamb_wos_test.apply(lambda row: sorted(list(set(row.year.split(\"|\")))), axis=1)\n",
    "\n",
    "print \"years done\"     \n",
    "   \n",
    "\n",
    "# df_disamb_wos_test.firstname = df_disamb_wos_test.firstname.fillna('')  # i convert NaN into empty strings, so i can concatenate them without errors\n",
    "# df_disamb_wos_test.lastname = df_disamb_wos_test.lastname.fillna('')\n",
    "\n",
    "\n",
    "df_disamb_wos_test['full_name'] = df_disamb_wos_test['firstname'] +\" \"+ df_disamb_wos_test['middle']+\" \"+ df_disamb_wos_test['lastname']  #harold y hwang          ###   rick john w       ###   yanagisako sylvia\n",
    "df_disamb_wos_test['full_name'] = df_disamb_wos_test.apply(lambda row: row.full_name.replace(\"  \",\" \"), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \"full name done\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df_disamb_wos_test.head(30)\n",
    "#df_disamb_wos_test.middle_initial.unique()\n",
    "\n",
    "# print df_disamb_wos_test.iloc[792]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print df_disamb_wos_test.author_names.iloc[434],df_disamb_wos_test.firstname.iloc[434]\n",
    "# print df_disamb_wos_test.list_author_names.iloc[434]\n",
    "\n",
    "\n",
    "# print df_disamb_wos_test.author_names.iloc[0]\n",
    "# print \n",
    "# print df_disamb_wos_test.affiliations.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_disamb_wos_test.head(3)\n",
    "\n",
    "# df_disamb_wos_test.list_author_names.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/WoS_data/Disambiguated_authors/wos_author_disambiguated_2000-2015_USA_processed.pickle'\n",
    "#DataFrame.to_pickle(path)[source]\n",
    "\n",
    "%time df_disamb_wos_test.to_pickle(path)\n",
    "#df_disamb_wos_test.shape\n",
    "print \"pickle done\"\n",
    "\n",
    "\n",
    "\n",
    "%time df_disamb_wos_test.to_csv(path.split(\".pickle\")[0]+\".tsv\", sep='\\t', encoding='utf-8')#, columns = list_headers)\n",
    "print \"csv done\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \", 'Jetzt', 'Ponmudi', 'Nussbaum', 'Psarros', \n",
    "# #type(df_disamb_wos_test.University.iloc[0]))\n",
    "\n",
    "\n",
    "\n",
    "# list_unique_lastnames=list(set(df_disamb_wos_test.lastname.unique()))\n",
    "# # print list_unique_lastnames\n",
    "\n",
    "\n",
    "# filename_pickle=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/list_unique_lastnames.pickle\"\n",
    "# %time pickle.dump(list_unique_lastnames, open(filename_pickle, 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(list_unique_lastnames)    #414123\n",
    "\n",
    "# for unique_lastname in tqdm_notebook(list_unique_lastnames):\n",
    "\n",
    "#     aux_df=df_disamb_wos_test[ df_disamb_wos_test.lastname == unique_lastname]\n",
    "\n",
    "#     path='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/WoS_data/Disambiguated_authors/By_lastname/wos_author_disambiguated_2010-2015_USA_'+unique_lastname+'.pickle'\n",
    "\n",
    "#     aux_df.to_pickle(path)\n",
    "    \n",
    "# print \"/ndone\"\n",
    "\n",
    "\n",
    "# filename_pickle=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/list_unique_lastnames.pickle\"\n",
    "# %time pickle.dump(list_unique_lastnames, open(filename_pickle, 'wb'))\n",
    "\n",
    "# import time\n",
    " \n",
    "# # Wait for 5 seconds\n",
    "# for i in range(10):\n",
    "#     time.sleep(50)\n",
    "#     localtime = time.localtime(time.time())\n",
    "#     print \"Local current time :\", localtime\n",
    "    \n",
    "    \n",
    "# print \"done\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
