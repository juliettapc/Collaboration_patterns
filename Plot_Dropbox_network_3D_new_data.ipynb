{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2592500, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_id</th>\n",
       "      <th>num_folder_members</th>\n",
       "      <th>folder_creation_date</th>\n",
       "      <th>date_last_change</th>\n",
       "      <th>user_id</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>num_adds</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_deletes</th>\n",
       "      <th>major_content_type</th>\n",
       "      <th>major_content_ext</th>\n",
       "      <th>group_total_publ</th>\n",
       "      <th>group_num_papers_last</th>\n",
       "      <th>group_num_citations</th>\n",
       "      <th>folder_lifespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592732</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-12</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>77422</td>\n",
       "      <td>cornell.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>office_docs</td>\n",
       "      <td>doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592732</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-12</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>79630</td>\n",
       "      <td>cornell.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>office_docs</td>\n",
       "      <td>doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>592732</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-12</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>77619</td>\n",
       "      <td>cornell.edu</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>office_docs</td>\n",
       "      <td>doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604794</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-27</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>86572</td>\n",
       "      <td>unc.edu</td>\n",
       "      <td>21798.0</td>\n",
       "      <td>40498.0</td>\n",
       "      <td>10660.0</td>\n",
       "      <td>pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680152</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-08-26</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>76579</td>\n",
       "      <td>cs.princeton.edu</td>\n",
       "      <td>644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder_id  num_folder_members folder_creation_date date_last_change  \\\n",
       "0     592732                   4           2008-06-12       2012-12-25   \n",
       "1     592732                   4           2008-06-12       2012-12-25   \n",
       "2     592732                   4           2008-06-12       2012-12-25   \n",
       "3     604794                   2           2008-06-27       2012-12-23   \n",
       "4     680152                   2           2008-08-26       2013-01-04   \n",
       "\n",
       "   user_id      email_domain  num_adds  num_edits  num_deletes  \\\n",
       "0    77422       cornell.edu       NaN        NaN          NaN   \n",
       "1    79630       cornell.edu       NaN        NaN          NaN   \n",
       "2    77619       cornell.edu      80.0       72.0          0.0   \n",
       "3    86572           unc.edu   21798.0    40498.0      10660.0   \n",
       "4    76579  cs.princeton.edu     644.0        0.0        112.0   \n",
       "\n",
       "  major_content_type major_content_ext group_total_publ group_num_papers_last  \\\n",
       "0        office_docs               doc              NaN                   NaN   \n",
       "1        office_docs               doc              NaN                   NaN   \n",
       "2        office_docs               doc              NaN                   NaN   \n",
       "3                pdf               pdf              NaN                   NaN   \n",
       "4                pdf               pdf              NaN                   NaN   \n",
       "\n",
       "  group_num_citations  folder_lifespan  \n",
       "0                 NaN             1658  \n",
       "1                 NaN             1658  \n",
       "2                 NaN             1658  \n",
       "3                 NaN             1641  \n",
       "4                 NaN             1593  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file='Dropbox_datafile_may22_2017_modified.csv'\n",
    "df=pd.read_csv(path+input_file, sep=',',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in df.email_domain.unique():\n",
    "    print item,\"   \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-05-01 00:00:00 2014-10-28 00:00:00\n",
      "2014-10-28 00:00:00 2015-04-26 00:00:00\n",
      "2015-04-26 00:00:00 2015-10-23 00:00:00\n",
      "2015-10-23 00:00:00 2016-04-20 00:00:00\n",
      "2016-04-20 00:00:00 2016-10-17 00:00:00\n",
      "2016-10-17 00:00:00 2017-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#### time window for temporal networks\n",
    "string_start_date='2014-05-01'\n",
    "start_date=pd.Timestamp(string_start_date)\n",
    "\n",
    "#string_end_date='2014-11-01'\n",
    "end_date=start_date + pd.Timedelta('180 days')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_tupla_dates=[]\n",
    "for i in range(6):\n",
    "    print start_date, end_date    \n",
    "    tupla_dates=[start_date,end_date]\n",
    "    list_tupla_dates.append(tupla_dates)\n",
    "\n",
    "    \n",
    "    start_date += pd.Timedelta('180 days')\n",
    "    end_date += pd.Timedelta('180 days')\n",
    "\n",
    "# 2014-05-01_2014-10-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### for plotting time series directly from data\n",
    "#df.plot(x='folder_creation_date',y='folder_lifespan',ls='',marker='.') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Timestamp('2014-10-28 00:00:00'), Timestamp('2015-04-26 00:00:00')],\n",
       " [Timestamp('2015-04-26 00:00:00'), Timestamp('2015-10-23 00:00:00')],\n",
       " [Timestamp('2015-10-23 00:00:00'), Timestamp('2016-04-20 00:00:00')],\n",
       " [Timestamp('2016-04-20 00:00:00'), Timestamp('2016-10-17 00:00:00')],\n",
       " [Timestamp('2016-10-17 00:00:00'), Timestamp('2017-04-15 00:00:00')],\n",
       " [Timestamp('2017-04-15 00:00:00'), Timestamp('2017-10-12 00:00:00')]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tupla_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print df.folder_creation_date.min(), df.folder_creation_date.max()   ###  2008-05-01 00:00:00     2017-05-16 00:00:00\n",
    "#print df.date_last_change.min(), df.date_last_change.max()   ###          2012-11-07 00:00:00     2017-05-17 00:00:00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.user_id == 86572]\n",
    "\n",
    "#table[table.column_name == some_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buiding network for time window: 2014-05-01 -- 2014-10-28\n",
      "(2592500, 15)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-26d1e46e40a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0memail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"email_domain\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0medits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_edits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0madds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_adds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdeletes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_deletes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mfolder_lifespan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"folder_lifespan\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# if we have something that is Index-like, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0;31m# use this, e.g. DatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;34m\"\"\" return the internal repr of this data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flag_GC=\"yes\"  # yes: only plot the GC;    no: i plot the entire network,   m: i select multiple big connected components for plotting\n",
    "\n",
    "Num_con_comp=10\n",
    "\n",
    "\n",
    "#focus_university=\"harvard.edu\"           #### harvard   missouri      northwestern   berkeley  ucla.  cambridge    ox.ac.uk\n",
    "# list_focus_univ=[\"missouri.edu\",\"harvard.edu\",\"northwestern.edu\", \"berkeley\",\"ucla.\",\"cambridge\",\"ox.ac.uk\",\"ucdavis\",\"princeton\",\"uchicago\",\"umass\",\"columbia\",\"unizar.es\",\"duke.edu\"]\n",
    "list_focus_univ=[\"northwestern.edu\"]\n",
    "# list_focus_univ=[\"berkeley\"]\n",
    "\n",
    "\n",
    "for tupla_dates in tqdm_notebook(list_tupla_dates):\n",
    "    \n",
    "\n",
    "\n",
    "    start_date=tupla_dates[0]\n",
    "    end_date=tupla_dates[1]\n",
    "\n",
    "    print \"buiding network for time window:\",str(start_date).replace(\"00:00:00\",\"\").strip(),\"--\",str( end_date).replace(\"00:00:00\",\"\").strip()\n",
    "\n",
    "    \n",
    "    G=nx.Graph()\n",
    "\n",
    "    dict_folder_list_domains={}\n",
    "    dict_folder_list_users={}\n",
    "    dict_user_id_domain={}\n",
    "    dict_user_id_edit={}\n",
    "    dict_user_id_del={}\n",
    "    dict_user_id_add={}\n",
    "    dict_user_id_folder_lifespan={}\n",
    "\n",
    "\n",
    "\n",
    "    print df.shape\n",
    "    cont=0\n",
    "\n",
    "\n",
    "    for row in tqdm_notebook(df.iterrows()):\n",
    "\n",
    "        folder=row[1][\"folder_id\"]\n",
    "        user_id=row[1][\"user_id\"]                              \n",
    "        email=row[1][\"email_domain\"]    \n",
    "        edits=row[1][\"num_edits\"]\n",
    "        adds=row[1][\"num_adds\"]\n",
    "        deletes=row[1][\"num_deletes\"]   \n",
    "        folder_lifespan=row[1][\"folder_lifespan\"]\n",
    "        num_members=row[1][\"num_folder_members\"]\n",
    "\n",
    "\n",
    "        folder_creation_date=row[1][\"folder_creation_date\"]\n",
    "        date_last_change=row[1][\"date_last_change\"]\n",
    "\n",
    "\n",
    "        #     for focus_university in list_focus_univ:                 \n",
    "    #         if focus_university in email:\n",
    "    #             flag_useful_line =1\n",
    "    #             break\n",
    "\n",
    "\n",
    "        flag_useful_line=0    \n",
    "        if (folder_creation_date >= start_date  and folder_creation_date <= end_date)     or     ( date_last_change >= start_date  and  date_last_change <= end_date ):\n",
    "            flag_useful_line =1\n",
    "\n",
    "\n",
    "\n",
    "        if flag_useful_line ==1:\n",
    "                try: \n",
    "                    dict_folder_list_users[folder].append(user_id)\n",
    "                except:\n",
    "                    dict_folder_list_users[folder]=[]\n",
    "                    dict_folder_list_users[folder].append(user_id)\n",
    "\n",
    "                try:    \n",
    "                    dict_folder_list_domains[folder].append(email)\n",
    "                except:            \n",
    "                    dict_folder_list_domains[folder]=[]\n",
    "                    dict_folder_list_domains[folder].append(email)\n",
    "\n",
    "\n",
    "\n",
    "                dict_user_id_domain[user_id]=email   \n",
    "\n",
    "                try:\n",
    "                    dict_user_id_edit[user_id] +=edits   # ojo!! the records are by folder and by user, so i need to accumulate!\n",
    "                    dict_user_id_del[user_id] +=deletes\n",
    "                    dict_user_id_add[user_id] +=adds \n",
    "\n",
    "                    dict_user_id_folder_lifespan[user_id].append(folder_lifespan) \n",
    "\n",
    "                except :\n",
    "                    dict_user_id_edit[user_id] =edits\n",
    "                    dict_user_id_del[user_id] =deletes\n",
    "                    dict_user_id_add[user_id] =adds \n",
    "\n",
    "                    dict_user_id_folder_lifespan[user_id]=[]\n",
    "                    dict_user_id_folder_lifespan[user_id].append(folder_lifespan) \n",
    "\n",
    "\n",
    "\n",
    "    #     cont +=1\n",
    "    #     if cont % 100000 ==0:\n",
    "    #         print cont\n",
    "\n",
    "    print \"done with the dict., size:\",len(dict_folder_list_users)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for user in  dict_user_id_folder_lifespan:\n",
    "        dict_user_id_folder_lifespan[user]=np.median(dict_user_id_folder_lifespan[user])\n",
    "\n",
    "\n",
    "\n",
    "    for folder in dict_folder_list_users:\n",
    "        dict_folder_list_users[folder]=list(set(dict_folder_list_users[folder]))  # remove possible duplicates\n",
    "\n",
    "        dict_folder_list_domains[folder]=list(set(dict_folder_list_domains[folder]))\n",
    "\n",
    "\n",
    "        lista=dict_folder_list_users[folder]\n",
    "\n",
    "        if len(lista)>1:\n",
    "\n",
    "            lista_pares=itertools.combinations(lista, 2)        \n",
    "\n",
    "            for item in lista_pares:\n",
    "                e1=item[0]\n",
    "                e2=item[1]\n",
    "                G.add_edge(e1,e2)\n",
    "               # print \"added edge:\",e1, e2\n",
    "    #     else:   # FOR NOW, I DO NOT ADD THE NODES WITH COLLABORATORS OUTSIDE THE UNIVERSITY DOMAINS\n",
    "    #         user_id=lista[0]\n",
    "\n",
    "    #         G.add_node(user_id)\n",
    "\n",
    "\n",
    "\n",
    "    print \"  N:\", len(G.nodes()),\"  L:\", len(G.edges())    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    GC_string=\"\"\n",
    "    if flag_GC ==\"yes\":   # i will plot only the GC\n",
    "        print \"selecting only the GC for plotting\"\n",
    "        G = max(nx.connected_component_subgraphs(G), key=len)\n",
    "        print \"  N:\", len(G.nodes()),\"  L:\", len(G.edges())    \n",
    "        GC_string=\"_GC\"\n",
    "\n",
    "    elif flag_GC ==\"m\":  # i will plot multiple large connected components\n",
    "\n",
    "        print \"selecting GC and some other large connected components for plotting\"\n",
    "\n",
    "        new_G = max(nx.connected_component_subgraphs(G), key=len)\n",
    "        print \"  N:\",len(new_G.nodes()),\"  L:\",len(new_G.edges())\n",
    "        lista_comp= reversed(sorted(nx.connected_component_subgraphs(G), key=len))\n",
    "\n",
    "\n",
    "        cont_comp=0\n",
    "        for comp in lista_comp:\n",
    "    #         cont_comp +=1\n",
    "    #         new_G.add_nodes_from(comp.nodes())\n",
    "    #         new_G.add_edges_from(comp.edges())\n",
    "    #         print cont_comp,\"  N:\",len(new_G.nodes()),\"  L:\",len(new_G.edges())\n",
    "    #         if cont_comp >=Num_con_comp:\n",
    "    #             break\n",
    "\n",
    "\n",
    "            if len(comp.nodes())>=10:\n",
    "                new_G.add_nodes_from(comp.nodes())\n",
    "                new_G.add_edges_from(comp.edges())\n",
    "                print \"  N:\",len(new_G.nodes()),\"  L:\",len(new_G.edges())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        G= new_G.copy()\n",
    "        GC_string=\"_multiple_comp\"\n",
    "\n",
    "\n",
    "    elif flag_GC ==\"no\":  # i will plot the entire structure\n",
    "        print \"selecting entire network for plotting\"\n",
    "       # print focus_university, \"done.  N:\", len(G.nodes()),\"  L:\", len(G.edges())\n",
    "        GC = max(nx.connected_component_subgraphs(G), key=len)\n",
    "        print \"\\n  GC:     N:\", len(GC.nodes()), \"  L:\", len(GC.edges())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### the master dict is larger than G.nodes(), and the set_node_attribute does not work in that case, so i get a selection of the dict only with the common nodes:\n",
    "    #######################\n",
    "    print len(G.nodes()), len(dict_user_id_domain)\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_domain[k] for k in set(G.nodes()) & set(dict_user_id_domain.keys())}\n",
    "    print len(G.nodes()), len(new_dict_user_id)\n",
    "    # i add the email as node attributes    \n",
    "    nx.set_node_attributes(G, 'email', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_edit[k] for k in set(G.nodes()) & set(dict_user_id_edit.keys())}\n",
    "    # i add the number of edits as node attributes    \n",
    "    nx.set_node_attributes(G, 'edits', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_del[k] for k in set(G.nodes()) & set(dict_user_id_del.keys())}\n",
    "    # i add the number of deletes as node attributes    \n",
    "    nx.set_node_attributes(G, 'deletes', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_add[k] for k in set(G.nodes()) & set(dict_user_id_add.keys())}\n",
    "    # i add the number of additions as node attributes    \n",
    "    nx.set_node_attributes(G, 'adds', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "    new_dict_user_id = {k: dict_user_id_folder_lifespan[k] for k in set(G.nodes()) & set(dict_user_id_folder_lifespan.keys())}\n",
    "    # i add the median folder_lifespan as node attributes \n",
    "    nx.set_node_attributes(G, 'median_folder_lifespan', new_dict_user_id)\n",
    "    ############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/\"\n",
    "    filename=\"first_network_\"+str(start_date).replace(\"00:00:00\",\"\").strip()+\"_\"+str(end_date).replace(\"00:00:00\",\"\").strip()+\".pickle\"\n",
    "    with open(path+filename,'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    print \"written:\",path+filename\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domains: set([])    shapes set([])\n",
      "1135617it [05:28, 3461.26it/s]"
     ]
    }
   ],
   "source": [
    "###### I get a different node shape for each domain (and i group all subdomains together)\n",
    "dict_domains_cont={}\n",
    "cont=0\n",
    "for node in G.nodes():    \n",
    "    \n",
    "    domain=str(G.node[node]['email'])\n",
    "    for focus_university in list_focus_univ:   \n",
    "        if focus_university in domain:\n",
    "            domain=focus_university\n",
    "            break\n",
    "    \n",
    "    if domain in dict_domains_cont:\n",
    "        G.node[node]['shape']=dict_domains_cont[domain]\n",
    "    else:\n",
    "        cont +=1\n",
    "        dict_domains_cont[domain]=cont\n",
    "        G.node[node]['shape']=dict_domains_cont[domain]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "print \"domains:\",set(dict_domains_cont.keys()),\"   shapes\",set(dict_domains_cont.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes relabeled\n",
      "done getting the postion dict for 0 nodes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########### i relabel the nodes so the plotly works later (otherwise, it doesnt work!)\n",
    "mapping={}\n",
    "cont=0\n",
    "for n in G.nodes():\n",
    "    mapping[n]=cont\n",
    "    cont +=1\n",
    "\n",
    "G=nx.relabel_nodes(G,mapping)\n",
    "print \"nodes relabeled\"\n",
    "##############################\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "##### i get a layout for the plotting of the network\n",
    "layt={}\n",
    "\n",
    "layt=nx.fruchterman_reingold_layout(G,dim=3)     \n",
    "#dict_pos=nx.fruchterman_reingold_layout(G,dim=2)\n",
    "#dict_pos=nx.spectral_layout(G,dim=2)\n",
    "#dict_pos=nx.spring_layout(G, dim=2)\n",
    "\n",
    "\n",
    "    ##### layout options for   graphviz_layout:\n",
    "    # dot - \"hierarchical\" or layered drawings of directed graphs. This is the default tool to use if edges have directionality.\n",
    "    # neato - \"spring model'' layouts.  This is the default tool to use if the graph is not too large (about 100 nodes) and you don't know anything else about it. Neato attempts to minimize a global energy function, which is equivalent to statistical multi-dimensional scaling.\n",
    "    # fdp - \"spring model'' layouts similar to those of neato, but does this by reducing forces rather than working with energy.\n",
    "    # sfdp - multiscale version of fdp for the layout of stanfordlarge graphs.\n",
    "    # twopi - radial layouts, after Graham Wills 97. Nodes are placed on concentric circles depending their distance from a given root node.\n",
    "#     circo - circular layout, after Six and Tollis 99, Kauffman and Wiese 02. This is suitable for certain diagrams of multiple cyclic structures, such as certain telecommunications networks.\n",
    "\n",
    "# layt=graphviz_layout(G, prog='fdp')\n",
    "\n",
    "#### i save the resulting  layout as attributes of the nodes themselves\n",
    "nx.set_node_attributes(G, 'pos', layt)\n",
    "\n",
    "print \"done getting the postion dict for\",len(layt),\"nodes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors_as=\"folder_lifespan\"  ## or \"edits\"  or folder_lifespan or k\n",
    "\n",
    "##### i create the list for the info that will show up when hovering over a node, as well as for giving each node a color-coded, shape and size\n",
    "list_values_colors=[]\n",
    "list_labels=[]\n",
    "list_sizes=[]\n",
    "list_symols=[]\n",
    "for node in G.nodes():\n",
    "    if colors_as ==\"k\":\n",
    "        list_values_colors.append(G.degree(node))\n",
    "        title_bar=\"degree\"\n",
    "    elif colors_as == \"edits\" :\n",
    "        list_values_colors.append(G.node[node]['edits'])\n",
    "        title_bar=\"number edits\"\n",
    "    elif colors_as == \"folder_lifespan\" :\n",
    "        list_values_colors.append(G.node[node]['median_folder_lifespan'])\n",
    "        title_bar=\"median lifespan of user's folders\"\n",
    "        \n",
    "         \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #list_sizes.append(random.choice([1,2,3,4,5,6,7,8,9,10]))\n",
    "    list_sizes.append(int(math.log(G.node[node]['edits']+0.001)+1))\n",
    "\n",
    "    list_symols.append(G.node[node]['shape'])\n",
    "                                  \n",
    "    label=G.node[node]['email']+\"  degree: \"+str(G.degree(node))+\"<br>ed: \"+ str(G.node[node]['edits'])+\"  adds: \"+ str(G.node[node]['adds'])+\"  del: \"+ str(G.node[node]['deletes'])+\"<br>median lifespan: \"+str(G.node[node]['median_folder_lifespan'])\n",
    "    list_labels.append(label)\n",
    "\n",
    "    \n",
    "    ## for the label, if i want a new line, code it as:   <br>  not as  \\n\n",
    "    \n",
    "    # see complete list of symbols for nodes at:         https://plot.ly/matlab/reference/#scatter-marker  and    https://plot.ly/~neda/1032/hover-over-the-marker-points-to-see-their-names/\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####### Set data for the Plotly plot of the graph:\n",
    "if len(list_focus_univ)==1:\n",
    "    plot_title=str(list_focus_univ).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"-\").replace('\"','').title()\n",
    "else:\n",
    "    plot_title=\"multiple universities\"\n",
    "\n",
    "\n",
    "N=len(G.nodes())\n",
    "L=len(G.edges())\n",
    "\n",
    "Xn=[layt[k][0] for k in range(N)]# x-coordinates of nodes\n",
    "Yn=[layt[k][1] for k in range(N)]# y-coordinates\n",
    "Zn=[layt[k][2] for k in range(N)]# z-coordinates\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "Ze=[]\n",
    "for e in G.edges():\n",
    "    Xe+=[layt[e[0]][0],layt[e[1]][0], None]# x-coordinates of edge ends\n",
    "    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n",
    "    Ze+=[layt[e[0]][2],layt[e[1]][2], None]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "trace1=Scatter3d(x=Xe,\n",
    "               y=Ye,\n",
    "               z=Ze,\n",
    "               mode='lines',\n",
    "               line=Line(color='rgb(125,125,125)', width=1),\n",
    "               hoverinfo='none'\n",
    "               )\n",
    "trace2=Scatter3d(x=Xn,\n",
    "               y=Yn,\n",
    "               z=Zn,\n",
    "               mode='markers',\n",
    "               name='actors',\n",
    "               marker=Marker(symbol='dot',\n",
    "                             size=list_sizes, #6,\n",
    "                             color=list_values_colors,\n",
    "                             colorscale='Viridis',\n",
    "                             line=Line(color='rgb(50,50,50)', width=0.5),                                                                                       \n",
    "                             colorbar=dict(\n",
    "                                thickness=15,\n",
    "                                title=title_bar,#title='degree',\n",
    "                                xanchor='left',\n",
    "                                titleside='right'),                                \n",
    "                             ),\n",
    "               text=list_labels,\n",
    "               hoverinfo='text'\n",
    "               )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layout = Layout(\n",
    "         title=plot_title,\n",
    "         width=1000,\n",
    "         height=1000,\n",
    "         showlegend=False,\n",
    "         scene=Scene(\n",
    "         xaxis=XAxis(axis),\n",
    "         yaxis=YAxis(axis),\n",
    "         zaxis=ZAxis(axis),\n",
    "        ),\n",
    "     margin=Margin(\n",
    "        t=100\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    annotations=Annotations([\n",
    "           Annotation(\n",
    "           showarrow=False,\n",
    "            text=\"Data source: Dropbox\",\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            x=0,\n",
    "            y=0.1,\n",
    "            xanchor='left',\n",
    "            yanchor='bottom',\n",
    "            font=Font(\n",
    "            size=14\n",
    "            )\n",
    "            )\n",
    "        ]),    )\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"N:\", len(G.nodes()), \"L:\", len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=Data([trace1, trace2])\n",
    "fig=Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the image as png and as html (interactive)\n",
    "\n",
    "filename=str(list_focus_univ).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"-\").replace('\"','')+GC_string\n",
    "#py.image.save_as(fig, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/'+filename+'_color_'+colors_as+GC_string+'_3D_.png',scale=5)  #scale controls the resolution of the image\n",
    "\n",
    "offline.plot(fig, filename='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/'+filename+'_color_'+colors_as+GC_string+'_3D_.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# help(py.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open(path+\"first_network_\"+focus_university+\".pickle\",'wb') as f:\n",
    "#     %time    pickle.dump(G, f)\n",
    "# print \"written:\",path+\"first_network_\"+focus_university+\".pickle\\n\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open(path+\"dict_position_first_network_\"+focus_university+\".pickle\",'wb') as f:\n",
    "#     %time    pickle.dump(dict_pos, f)\n",
    "# print \"written:\",path+\"dict_position_first_network_\"+focus_university+\".pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "d3353c4f04d8459692d21a6ad9739f13": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "fc13f25bbf794ca1b73f9c140650d6a7": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
