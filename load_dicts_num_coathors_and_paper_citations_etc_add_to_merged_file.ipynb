{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "    \n",
    " \n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.45 s, sys: 812 ms, total: 6.26 s\n",
      "Wall time: 8.99 s\n",
      "# authors involved 79948\n"
     ]
    }
   ],
   "source": [
    "path_merge_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "path_merge_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filename=\"Merged_linkedin-WoS_GS_extra70univ.pickle\"\n",
    "%time df_merged = pd.read_pickle(path_merge_linux+filename)\n",
    "\n",
    "\n",
    "aux=df_merged['author_disambig_id_wos'].dropna().tolist()\n",
    "\n",
    "#len(lista_authors_merge)   #   79948\n",
    "#print aux[0]\n",
    "\n",
    "\n",
    "lista_authors_merge = [int(x) for x in aux] \n",
    "\n",
    "#print lista_authors_merge[0],type(lista_authors_merge[0])   INT\n",
    "\n",
    "print \"# authors involved\",len(lista_authors_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 s, sys: 108 ms, total: 4.31 s\n",
      "Wall time: 4.8 s\n",
      "# involved papers: 2674932 2674932\n"
     ]
    }
   ],
   "source": [
    "#file_pickle = open(path_merge_linux+\"list_relevant_papers_partial.pickle\",'rb') \n",
    "file_pickle = open(path_merge_linux+\"list_involved_papers_all_lines.pickle\",'rb')        ### num papers:  2674932\n",
    "%time list_involved_papers  = pickle.load(file_pickle)\n",
    "set_list_involved_papers=set(list_involved_papers)\n",
    "\n",
    "print \"# involved papers:\", len(list_involved_papers), len(set_list_involved_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in df_merged.columns:\n",
    "    print column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string_lines= \"_all_lines\"\n",
    "\n",
    "# written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/master_dict_author_id_att_all_lines.pickle\n",
    "# written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/dict_paper_list_authors_all_lines.pickle\n",
    "# written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/dict_paper_dict_author_seq_all_lines.pickle\n",
    "# written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/dict_author_dict_paper_seq_all_lines.pickle\n",
    "\n",
    "#/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/dict_paper_id_list_papers_that_cite_it_all_lines.pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#file_pickle = open(path_merge_linux+\"dict_paper_dict_author_seq_all_lines.pickle\",'rb')\n",
    "file_pickle = open(path_merge_linux+\"dict_paper_dict_author_seq\"+string_lines+\".pickle\",'rb')\n",
    "%time dict_paper_dict_author_seq  = pickle.load(file_pickle)\n",
    "\n",
    "\n",
    "file_pickle = open(path_merge_linux+\"master_dict_author_id_att_all_lines_to_be_filled.pickle\",'rb')\n",
    "#file_pickle = open(path_merge_linux+\"master_dict_author_id_att\"+string_lines+\".pickle\",'rb')\n",
    "%time master_dict_author_id_att = pickle.load(file_pickle)\n",
    "\n",
    "\n",
    "#file_pickle = open(path_merge_linux+\"dict_paper_id_list_papers_that_cite_it\"+string_lines+\".pickle\",'rb')\n",
    "#file_pickle = open(path_merge_linux+\"dict_paper_id_list_papers_that_cite_it_all_lines.pickle\",'rb')\n",
    "file_pickle = open(path_merge_linux+\"dict_paper_id_list_papers_that_cite_it_all_lines.pickle\",'rb')\n",
    "%time dict_paper_id_list_papers_that_cite_it = pickle.load(file_pickle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### for later\n",
    "# file_pickle = open(path_merge_linux+\"dict_author_dict_paper_seq_all_lines.pickle\",'rb')\n",
    "# %time dict_author_dict_paper_seq  = pickle.load(file_pickle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### for later\n",
    "file_pickle = open(path_merge_linux+\"dict_paper_list_authors_all_lines.pickle\",'rb')        ### num papers:  \n",
    "%time dict_paper_list_authors  = pickle.load(file_pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####  THIS CELL IS TEMPORARY!!\n",
    "\n",
    "\n",
    "print \"adding coauthors.....\"   \n",
    "for paper_id in dict_paper_list_authors:\n",
    "    list_coathors_current_paper=dict_paper_list_authors[paper_id]\n",
    "\n",
    "    for author_id in list_coathors_current_paper:\n",
    "        for coauthor in list_coathors_current_paper:                \n",
    "            if author_id != coauthor:\n",
    "                if coauthor not in master_dict_author_id_att[author_id]['coauthors']:\n",
    "                    master_dict_author_id_att[author_id]['coauthors'].append(coauthor)\n",
    "\n",
    "print \"     done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \"removing redundancy in list of coauthors......\"\n",
    "# i remove redundancy in list of coauthors     \n",
    "for author_id in master_dict_author_id_att:             \n",
    "   # HOW TO REMOVE ELEMENTS FROM A LIST BY VALUE (WHEN THERE MAY BE REPETITIONS):\n",
    "    #     a = [1, 2, 3, 4, 2, 3, 4, 2, 7, 2]\n",
    "    # >>> a = [x for x in a if x != 2]\n",
    "\n",
    "    # I REMOVE THE AUTHOR HERSELF FROM THE LIST OF COAUTHORS\n",
    "        master_dict_author_id_att[author_id]['coauthors']=[ x for x in list(set(master_dict_author_id_att[author_id]['coauthors'])) if x != author_id ]  \n",
    "\n",
    "print \"     done\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filename_pickle=path_merge_cluster+\"master_dict_author_id_att\"+string_lines+\".pickle\"    \n",
    "pickle.dump(master_dict_author_id_att, open(filename_pickle, 'wb'))\n",
    "print \"written:\",filename_pickle  \n",
    "print len(master_dict_author_id_att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 592 ms, sys: 12 ms, total: 604 ms\n",
      "Wall time: 602 ms\n"
     ]
    }
   ],
   "source": [
    "# for paper in dict_paper_dict_author_seq:\n",
    "#     print paper, \"aunthors and seq:\",dict_paper_dict_author_seq[paper], \"list_authors:\",dict_paper_list_authors[paper]\n",
    "   \n",
    "#     #raw_input()\n",
    "\n",
    "\n",
    "\n",
    "#file_pickle = open(path_merge_linux+\"master_dict_author_id_att_all_lines.pickle\",'rb')\n",
    "file_pickle = open(path_merge_linux+\"master_dict_author_id_att\"+string_lines+\".pickle\",'rb')\n",
    "%time master_dict_author_id_att = pickle.load(file_pickle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for author in master_dict_author_id_att:\n",
    "\n",
    "#     try:\n",
    "#         list_papers=master_dict_author_id_att[author]['publications_seq'].keys()\n",
    "#     except : \n",
    "        \n",
    "#         print author, len(master_dict_author_id_att[author]), master_dict_author_id_att[author]\n",
    "#         raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for author in dict_author_dict_paper_seq:\n",
    "#     try:\n",
    "#         dict_author_dict_paper_seq[author].keys()\n",
    "#     except TypeError: \n",
    "#         print author, dict_author_dict_paper_seq[author]\n",
    "#         raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " for author in master_dict_author_id_att:\n",
    "        #print author,dict_author_dict_paper_seq[author]\n",
    "        \n",
    "#         master_dict_author_id_att[author]['publications']=[]\n",
    "#         master_dict_author_id_att[author]['publications_seq']=[]\n",
    "        #print author, master_dict_author_id_att[author]\n",
    "        \n",
    "        try:            \n",
    "            master_dict_author_id_att[author]['publications']=dict_author_dict_paper_seq[author].keys()                                                                  \n",
    "        except:\n",
    "            master_dict_author_id_att[author]['publications']=[]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            master_dict_author_id_att[author]['publications_seq']=dict_author_dict_paper_seq[author]\n",
    "        except:\n",
    "            master_dict_author_id_att[author]['publications_seq']={}\n",
    "            \n",
    "        #print author, master_dict_author_id_att[author]\n",
    "        #raw_input()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in dict_paper_dict_author_seq:\n",
    "    #if len(dict_paper_dict_author_seq[paper])>1:\n",
    "    for author in dict_paper_dict_author_seq[paper]:\n",
    "        num_author_in_paper=max(dict_paper_dict_author_seq[paper].values())\n",
    "        if dict_paper_dict_author_seq[paper][author]==num_author_in_paper:\n",
    "            master_dict_author_id_att[author]['papers_last'] +=1\n",
    "            \n",
    "        if dict_paper_dict_author_seq[paper][author]==0:\n",
    "            master_dict_author_id_att[author]['papers_1st'] +=1    \n",
    "            \n",
    "            #print dict_paper_dict_author_seq[paper]\n",
    "            \n",
    "            if len(dict_paper_dict_author_seq[paper]) ==1:\n",
    "                master_dict_author_id_att[author]['papers_unique_author'] +=1\n",
    "            \n",
    "#         print paper, dict_paper_dict_author_seq[paper]\n",
    "#         raw_input()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    " #example: {'coauthors': [1000417696, 20508800, 1000295970, 1000304934, 1000430248, 452427, 84318355, 19892792], 'publications_seq': {'000326311600057': 0, '000365789100016': 5, \n",
    "#            '000300231400005': 0, '000323103900037': 0, '000332386100011': 9, '000331417700003': 0}, 'publications': ['000326311600057', '000365789100016', '000300231400005', '000323103900037', \n",
    "#          '000332386100011', '000331417700003'], 'papers_last': 1.0, 'num_papers': 6.0, 'papers_unique_author': 0.0, 'papers_1st': 8.0}76924930: {'coauthors': [3840074, 67750750, 12225567], \n",
    "#     'num_papers': 331.0,   'papers_1st': 1.0,   'papers_last': 0.0,   'papers_unique_author': 0.0}\n",
    "\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for author in master_dict_author_id_att:\n",
    "#         #print author,dict_author_dict_paper_seq[author]\n",
    "#     print master_dict_author_id_att[author]        \n",
    "#     raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for author in master_dict_author_id_att:\n",
    "#     print author, master_dict_author_id_att[author]\n",
    "#     raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ojo num_citations 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7049674315c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\" ojo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_dict_author_id_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         )\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juliaponcela/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# example:    master_dict_author_id_att\n",
    "# {'coauthors': [1000417696, 20508800, 1000295970, 1000304934, 1000430248, 452427, 84318355, 19892792], 'publications_seq': {'000326311600057': 0, '000365789100016': 5, \n",
    "#            '000300231400005': 0, '000323103900037': 0, '000332386100011': 9, '000331417700003': 0}, 'publications': ['000326311600057', '000365789100016', '000300231400005', '000323103900037', \n",
    "#          '000332386100011', '000331417700003'], 'papers_last': 1.0, 'num_papers': 6.0, 'papers_unique_author': 0.0, 'papers_1st': 8.0}76924930: {'coauthors': [3840074, 67750750, 12225567], \n",
    "#     'num_papers': 331.0,   'papers_1st': 1.0,   'papers_last': 0.0,   'papers_unique_author': 0.0}\n",
    "\n",
    "\n",
    "#example dict_paper_id_list_papers_that_cite_it[paper]\n",
    "#    A1989AA21500007: ['A1990CT24400001', 'A1991FL05900006', 'A1991GC63600010', 'A1991HP82600004', 'A1991GZ80200002', 'A1991GP27400006', 'A1991HW84200003', 'A1992JY38000006', 'A1992LV58000003', \n",
    "#                  'A1992JW20800001', 'A1993MH78500007', 'A1993LD26000007', 'A1994NG95100002', 'A1995TV47800002', 'A1995RX94200002', 'A1995TP54500003', 'A1996UY03500001', 'A1997XG69900001', \n",
    "#                  'A1997WZ41400003', 'A1997YH60700005', '000073049500001', '000077809000001', '000165125600002', '000089610200001', '000171970500006', '000174029200001', '000179151900010', \n",
    "#                  '000183232400007', '000186331700002', '000221581100007', '000226016800004', '000220851000003', '000220164600012', '000237583600002', '000231005100003', '000264401000001', \n",
    "#                  '000288690000003', '000291174200005', '000288836000002', '000290920900014', '000288888200004', '000340886700003', '000328802300009', '000321228600002', '000358272700004']\n",
    "\n",
    "\n",
    "#### i collect the number of citations for the authors\n",
    "list_not_cited=[]\n",
    "for author in master_dict_author_id_att:\n",
    "\n",
    "    \n",
    "    list_papers=master_dict_author_id_att[author]['publications_seq'].keys()\n",
    "    \n",
    "#     try:\n",
    "#         list_papers=master_dict_author_id_att[author]['publications_seq'].keys()\n",
    "#     except TypeError: \n",
    "#         print \" ojo\",author, master_dict_author_id_att[author]\n",
    "#         raw_input()\n",
    "        \n",
    "        \n",
    "    num_cit=0\n",
    "    for paper in list_papers:\n",
    "        try:\n",
    "            if paper in dict_paper_id_list_papers_that_cite_it[paper]:  # if self-citation of the paper, i remove all possible occurrences of it\n",
    "                #print len(dict_paper_id_list_papers_that_cite_it[paper]),\n",
    "                aux_list = list(filter(lambda x: x!= paper, dict_paper_id_list_papers_that_cite_it[paper]))\n",
    "                dict_paper_id_list_papers_that_cite_it[paper]=aux_list\n",
    "            \n",
    "            num_cit += len(dict_paper_id_list_papers_that_cite_it[paper])\n",
    "            \n",
    "        except:\n",
    "            list_not_cited.append(paper)\n",
    "            #print paper, \"not cited\"\n",
    "\n",
    "    master_dict_author_id_att['num_citations']=num_cit\n",
    "\n",
    "print \"done.    # papers without citations\",len(list_not_cited), \"  out of:\", len(list_involved_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_num_papers_to_doublecheck(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    num_papers=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        num_papers= dicc[wos_id]['num_papers']\n",
    "        return num_papers\n",
    "                    \n",
    "    except:  pass\n",
    "        \n",
    "        \n",
    "        \n",
    "###############################\n",
    "\n",
    "def add_num_coathors(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    num_coathors=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        num_coathors= len(dicc[wos_id]['coauthors'] )\n",
    "        return num_coathors                    \n",
    "    except:  pass\n",
    "        \n",
    "        \n",
    "        \n",
    "###############################\n",
    "def add_papers_1st(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    num_papers_1st=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        num_papers_1st= dicc[wos_id]['papers_1st']\n",
    "        return num_papers_1st                    \n",
    "    except:  pass\n",
    "        \n",
    "        \n",
    "        \n",
    "###############################\n",
    "def add_papers_last(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    num_papers_last=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        num_papers_last= dicc[wos_id]['papers_last']\n",
    "        return num_papers_last                    \n",
    "    except:  pass\n",
    "        \n",
    "        \n",
    "        \n",
    "###############################       \n",
    "             \n",
    "###############################\n",
    "def add_papers_unique(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    num_papers_unique=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        num_papers_unique= dicc[wos_id]['papers_unique_author']\n",
    "        return num_papers_unique                    \n",
    "    except:  pass\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "###############################       \n",
    "def add_list_papers(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    papers=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        papers= \"|\".join(dicc[wos_id]['publications_seq'].keys())\n",
    "        return papers                    \n",
    "    except:  pass\n",
    "        \n",
    "              \n",
    "       \n",
    "        \n",
    "###############################       \n",
    "def add_num_citations(wos_id,dicc):    \n",
    "    \n",
    "   # print \"wos id:\",wos_id   \n",
    "    citations=np.nan             \n",
    "    try:          \n",
    "        wos_id=int(wos_id)\n",
    "        citations=dicc[wos_id]['num_citations']\n",
    "        return citations                    \n",
    "    except:  pass\n",
    "        \n",
    "              \n",
    "###############################\n",
    "#example: 76924930: {'coauthors': [3840074, 67750750, 12225567],   'num_papers': 331.0,   'papers_1st': 1.0,   'papers_last': 0.0,   'papers_unique_author': 0.0}\n",
    "   #master_dict_author_id_att[author]['coauthors'] \n",
    "    \n",
    "    \n",
    "######## i create the new field (and i will run it again after refining the dict)\n",
    "df_merged['num_coauthors'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_num_coathors,args=[master_dict_author_id_att])\n",
    "\n",
    "df_merged['num_papers_double_check'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_num_papers_to_doublecheck,args=[master_dict_author_id_att])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "df_merged['num_papers_1st'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_papers_1st,args=[master_dict_author_id_att])\n",
    "     \n",
    "df_merged['num_papers_last'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_papers_last,args=[master_dict_author_id_att])\n",
    "    \n",
    "df_merged['num_papers_solo'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_papers_unique,args=[master_dict_author_id_att])\n",
    "\n",
    "\n",
    "df_merged['list_pub'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_list_papers,args=[master_dict_author_id_att])\n",
    "\n",
    "\n",
    "\n",
    "df_merged['num_citations'] = df_merged['author_disambig_id_wos'].fillna('').apply(add_num_citations,args=[master_dict_author_id_att])\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged[['full_name_linkedin','Department_linkedin','University_linkedin','num_papers_double_check','total_pubs','num_papers_1st','num_papers_last','num_papers_solo','num_coauthors','list_pub']].dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_merged=\"Merged_linkedin-WoS_GS_extra70univ.pickle\"\n",
    "\n",
    "%time df_merged.to_pickle(path_merge_linux+filename_merged.split(\".pickle\")[0] +\"_added_num_coauth\"+string_lines+\".pickle\" )\n",
    "print \"pickle done:\", path_merge_linux+filename_merged.split(\".pickle\")[0] +\"_added_num_coauth\"+string_lines+\".pickle\"        \n",
    "\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(path_merge_linux+filename_merged.split(\".pickle\")[0] +\"_added_num_coauth\"+string_lines+\".xlsx\", engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "%time df_merged.to_excel(writer, sheet_name='Sheet1')\n",
    "## OJO! hay url muy largas que hacen que el sistema se cuelgue (solucion: no permitirle que las considere url, sino simplemente str)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "print \"xlsx done\",path_merge_linux+filename_merged.split(\".pickle\")[0] +\"_added_num_coauth\"+string_lines+\".xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 loops, best of 3: 595 ns per loop\n",
      "The slowest run took 5.56 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 343 ns per loop\n"
     ]
    }
   ],
   "source": [
    "# %timeit lista+lista2 # 595 ns per loop\n",
    "\n",
    "\n",
    "# %timeit lista.extend(lista2) #343 ns per loop"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
