{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403349, 38)\n",
      "440353\n",
      "(440353, 14)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file = 'Dropbox_datafile_complete_new_ranking.csv'\n",
    "#input_file = 'Dropbox_datafile_may22_2017_modified_added_univ_country_geolocation_RUCC_population_density_when_available_career_stage_GINI_folder_act_categories.csv'\n",
    "df = pd.read_csv(path+input_file, sep=';',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "print df.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######## load dictionary aggregated info by user  \n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_user_id_user_attr = pickle.load(handle)\n",
    "print len(dict_user_id_user_attr.keys())\n",
    "\n",
    "df_users = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "#df_selection_users=df_folders[df_folders['user_univ_ranking']<=50]\n",
    "print df_users.shape   # 440353, 11\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27029.3620573 28.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'folder_id', u'num_folder_members', u'folder_creation_date',\n",
       "       u'date_last_change', u'user_id', u'email_domain', u'num_adds',\n",
       "       u'num_edits', u'num_deletes', u'major_content_type',\n",
       "       u'major_content_ext', u'group_total_publ', u'group_num_papers_last',\n",
       "       u'group_num_citations', u'folder_lifespan', u'simplified_domain',\n",
       "       u'University_Name', u'Cleaned_university_name', u'Country',\n",
       "       u'Geolocation', u'lat', u'long', u'zip', u'Rural_Urban_Continuum_Code',\n",
       "       u'State_Name', u'Description', u'Population_2010', u'Land-Sq-Mi',\n",
       "       u'Density_Per_Sq_Mile', u'career_stage', u'median_num_publ',\n",
       "       u'median_num_last_auth', u'folder_activity_GINI',\n",
       "       u'category_total_publ', u'category_total_last_auth',\n",
       "       u'category_total_cit', u'world_ranking', u'national_ranking'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for item in df.email_domain.unique():\n",
    "#     print item,\"   \"\n",
    "\n",
    "\n",
    "# dict_user_id_user_attr    \n",
    "# 378535942: {'CC': 1.0,\n",
    "#   'career_stage': nan,\n",
    "#   'category_total_cit': nan,\n",
    "#   'category_total_last_auth': nan,\n",
    "#   'category_total_publ': nan,\n",
    "#   'k': 11,\n",
    "#   'kshell': 11,\n",
    "#   'mean_folder_lifespan': 1.0,\n",
    "#   'number_folders': 1,\n",
    "#   'user_tot_act': 0.0,\n",
    "#   'user_tot_num_adds': 0.0,\n",
    "#   'user_tot_num_deletes': 0.0,\n",
    "#   'user_tot_num_edits': 0.0,\n",
    "#   'user_univ_ranking': 281.0}\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #### time window for temporal networks\n",
    "# string_start_date='2014-05-01'\n",
    "# start_date=pd.Timestamp(string_start_date)\n",
    "\n",
    "# #string_end_date='2014-11-01'\n",
    "# end_date=start_date + pd.Timedelta('180 days')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list_tupla_dates=[]\n",
    "# for i in range(6):\n",
    "#     print start_date, end_date    \n",
    "#     tupla_dates=[start_date,end_date]\n",
    "#     list_tupla_dates.append(tupla_dates)\n",
    "\n",
    "    \n",
    "#     start_date += pd.Timedelta('180 days')\n",
    "#     end_date += pd.Timedelta('180 days')\n",
    "\n",
    "# # 2014-05-01_2014-10-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### for plotting time series directly from data\n",
    "#df.plot(x='folder_creation_date',y='folder_lifespan',ls='',marker='.') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done with the dicts., size: 521274 521274\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "                     \n",
    "    pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_list_users.pickle'\n",
    "    with open(pickle_name, 'rb') as handle:\n",
    "        dict_folder_list_users = pickle.load(handle)\n",
    "\n",
    "\n",
    "    pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_folder_dict_user_act_in_folder.pickle'\n",
    "    with open(pickle_name, 'rb') as handle:\n",
    "        dict_folder_dict_user_act_in_folder = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "except IOError:  #dictinonaries not found\n",
    "    \n",
    "        dict_folder_list_users={}\n",
    "        dict_folder_dict_user_act_in_folder={}\n",
    "\n",
    "\n",
    "        for row in tqdm_notebook(df.iterrows()):  # one row per user and per folder\n",
    "\n",
    "                folder=row[1][\"folder_id\"]\n",
    "                user_id=row[1][\"user_id\"]                           \n",
    "\n",
    "\n",
    "                user_act= row[1][\"num_adds\"]+row[1][\"num_edits\"]+row[1][\"num_deletes\"]   # only in this folder\n",
    "\n",
    "                try: \n",
    "                    dict_folder_list_users[folder].append(user_id)\n",
    "                except:\n",
    "                    dict_folder_list_users[folder]=[]\n",
    "                    dict_folder_list_users[folder].append(user_id)\n",
    "\n",
    "\n",
    "                try: \n",
    "                    dict_folder_dict_user_act_in_folder[folder]\n",
    "                except KeyError:\n",
    "                    dict_folder_dict_user_act_in_folder[folder]={}            \n",
    "\n",
    "                dict_folder_dict_user_act_in_folder[folder][user_id]=user_act\n",
    "\n",
    "\n",
    "        print \"done with the dicts., size:\",len(dict_folder_list_users),len(dict_folder_dict_user_act_in_folder)\n",
    "\n",
    "\n",
    "        path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/\"\n",
    "        filename=\"dict_folder_list_users.pickle\"\n",
    "        with open(path+filename,'wb') as f:\n",
    "            pickle.dump(dict_folder_list_users, f)\n",
    "        print \"written:\",path+filename\n",
    "\n",
    "\n",
    "\n",
    "        path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/\"\n",
    "        filename=\"dict_folder_dict_user_act_in_folder.pickle\"\n",
    "        with open(path+filename,'wb') as f:\n",
    "            pickle.dump(dict_folder_dict_user_act_in_folder, f)\n",
    "        print \"written:\",path+filename\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  N: 440353   L: 3659098\n",
      "\n",
      "  GC:     N: 410414   L: 3615306\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/first_network_all_new.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "######## unweighted network:\n",
    "\n",
    "G=nx.Graph()\n",
    "for folder in tqdm_notebook(dict_folder_list_users):\n",
    "        dict_folder_list_users[folder]=list(set(dict_folder_list_users[folder]))  # remove possible duplicates       (there shouldnt be any)\n",
    "\n",
    "        lista=dict_folder_list_users[folder]\n",
    "\n",
    "        if len(lista)>1:\n",
    "\n",
    "            lista_pares=itertools.combinations(lista, 2)        \n",
    "\n",
    "            for item in lista_pares:\n",
    "                e1=item[0]\n",
    "                e2=item[1]\n",
    "                G.add_edge(e1,e2)\n",
    "                \n",
    "                try: \n",
    "                    G.edge[e1][e2][\"num_common_projects\"] +=1\n",
    "                except KeyError:\n",
    "                    G.edge[e1][e2][\"num_common_projects\"] =1\n",
    "                    \n",
    "#                 print e1, e2, G.edge[e1][e2][\"num_common_folders\"]    \n",
    "#                 raw_input()\n",
    "               # print \"added edge:\",e1, e2\n",
    "    \n",
    "        else:\n",
    "            n=lista[0]\n",
    "            G.add_node(n)\n",
    "            G.node[n][\"tot_act\"]=dict_user_id_user_attr[n]['user_tot_act']\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "print \"  N:\", len(G.nodes()),\"  L:\", len(G.edges())       \n",
    "GC = max(nx.connected_component_subgraphs(G), key=len)\n",
    "print \"\\n  GC:     N:\", len(GC.nodes()), \"  L:\", len(GC.edges())\n",
    "\n",
    "\n",
    "\n",
    "path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/\"\n",
    "filename=\"network_all_new.pickle\"\n",
    "with open(path+filename,'wb') as f:\n",
    "    pickle.dump(G, f)\n",
    "print \"written:\",path+filename\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27029.3620573 28.0\n",
      "thershold for activity 1\n",
      "\n",
      "  N: 440353   L: 450589\n",
      "\n",
      "  GC:     N: 100437   L: 351762\n",
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/network_all_weighted_by_act_thresh1.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_users.columns\n",
    "print df_users.user_tot_act.mean(), df_users.user_tot_act.quantile(q=0.6)\n",
    "act_threshold=1 #  28 is the 60% ,  56 is the 65%  ,   168 is the 70% percentile (50% percentile is 0 and 55% is also 0)\n",
    "\n",
    "print \"thershold for activity\",act_threshold\n",
    "\n",
    "\n",
    "####### weighted network:\n",
    "\n",
    "G_weighted=nx.Graph()\n",
    "for folder in tqdm_notebook(dict_folder_dict_user_act_in_folder):\n",
    "        #dict_folder_list_users[folder]=list(set(dict_folder_list_users[folder]))  # remove possible duplicates      \n",
    "\n",
    "       # print folder\n",
    "        \n",
    "        lista_users=dict_folder_dict_user_act_in_folder[folder].keys()\n",
    "        #print dict_folder_dict_user_act_in_folder[folder], lista_users\n",
    "        weighted_list_users=[]\n",
    "        for user in dict_folder_dict_user_act_in_folder[folder]:\n",
    "            user_act_in_folder=dict_folder_dict_user_act_in_folder[folder][user]\n",
    "            if user_act_in_folder >= act_threshold:\n",
    "                weighted_list_users.append(user)\n",
    "                \n",
    "      #  print weighted_list_users\n",
    "       \n",
    "        \n",
    "        if len(weighted_list_users)>1:  # ignore nodes that havent done any work in a particular folder (they will only count as isolated)\n",
    "\n",
    "            lista_pares=itertools.combinations(weighted_list_users, 2)        \n",
    "\n",
    "            for item in lista_pares:\n",
    "                e1=item[0]\n",
    "                e2=item[1]\n",
    "                G_weighted.add_edge(e1,e2)\n",
    "               # print \"added link\", e1, e2\n",
    "                \n",
    "                try: \n",
    "                    G_weighted.edge[e1][e2][\"num_common_projects\"] +=1\n",
    "                except KeyError:\n",
    "                    G_weighted.edge[e1][e2][\"num_common_projects\"] =1\n",
    "                    \n",
    "#                 print e1, e2, G.edge[e1][e2][\"num_common_folders\"]    \n",
    "#                 raw_input()\n",
    "               # print \"added edge:\",e1, e2\n",
    "    \n",
    "        \n",
    "        for n in lista_users:\n",
    "            G_weighted.add_node(n)\n",
    "            G_weighted.node[n][\"tot_act\"]=dict_user_id_user_attr[n]['user_tot_act']\n",
    "           # print \"added node\", n\n",
    "\n",
    "            \n",
    "           \n",
    "        #raw_input()    \n",
    "\n",
    "print \"  N:\", len(G_weighted.nodes()),\"  L:\", len(G_weighted.edges())       \n",
    "GC = max(nx.connected_component_subgraphs(G_weighted), key=len)\n",
    "print \"\\n  GC:     N:\", len(GC.nodes()), \"  L:\", len(GC.edges())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/\"\n",
    "filename=\"network_all_weighted_by_act_thresh\"+str(act_threshold)+\".pickle\"\n",
    "with open(path+filename,'wb') as f:\n",
    "    pickle.dump(G_weighted, f)\n",
    "print \"written:\",path+filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### the master dict is larger than G.nodes(), and the set_node_attribute does not work in that case, so i get a selection of the dict only with the common nodes:\n",
    "#######################\n",
    "\n",
    "# new_dict_user_id = {k: dict_user_id_domain[k] for k in set(G.nodes()) & set(dict_user_id_domain.keys())}\n",
    "# print len(G.nodes()), len(new_dict_user_id)\n",
    "# # i add the email as node attributes    \n",
    "# nx.set_node_attributes(G, 'email', new_dict_user_id)\n",
    "# ############\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "06a006e441194d768bce52caf1257754": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "cefad3bf36a741ddb2fb8941bca8d246": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "dbf287eb975c4e9aa5a04f9a618a1581": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
