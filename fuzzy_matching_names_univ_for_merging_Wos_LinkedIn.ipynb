{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import time\n",
    " \n",
    "# # Wait for x seconds\n",
    "# for i in range(7):\n",
    "#     time.sleep(3600)  # time in seconds\n",
    "#     localtime = time.localtime(time.time())\n",
    "#     print \"Local current time :\", localtime\n",
    "    \n",
    "    \n",
    "# print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import difflib\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "    \n",
    "    \n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# title=u\"Klüft skräms inför på fédéral électoral große\"\n",
    "# try:\n",
    "#     new=unicodedata.normalize('NFKD', title).encode('ascii','ignore')\n",
    "# except TypeError:\n",
    "#     new=title\n",
    "# print title\n",
    "# print new \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert_unicode_to_string(old_cadena):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        new_cadena=unicodedata.normalize('NFKD', old_cadena).encode('ascii','ignore')\n",
    "#         print old_cadena,type(old_cadena)\n",
    "#         print new_cadena,type(new_cadena)\n",
    "#         raw_input()\n",
    "        return new_cadena\n",
    "    except TypeError:  # if it is a string already\n",
    "#         print type(old_cadena)\n",
    "#         print old_cadena\n",
    "#         raw_input()\n",
    "        return old_cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done reading wos file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# big Csv file for 201-2015 run by Jared @ KDC using my code \"clean_unpacking...\"\n",
    "#see code: processlinkedin_index_wos_disambig_dump_into_pickle.ipynb  for cleaning and reformating of the wos disambiguated data\n",
    "#path_wos_win='C:\\\\Users\\\\julietta\\\\Work\\\\Dropbox_studies\\\\Data\\\\WoS_data\\\\Disambiguated_authors\\\\'\n",
    "\n",
    "number_rows=1000000#\"All\" # or 1000000\n",
    "\n",
    "\n",
    "#path_cluster='/home/julia/Dropbox_collaborations/Data/WoS_data/Disambiguated_authors/'\n",
    "path_redbox='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/WoS_data/Disambiguated_authors/'\n",
    "\n",
    "string_num_rows=\"\"\n",
    "if  number_rows==\"All\":\n",
    "\n",
    "    df_disamb_wos_test=pd.read_csv(path_redbox+'wos_author_disambiguated_2000-2015_USA_processed.tsv', sep=\"\\t\")\n",
    "\n",
    "else:\n",
    "    string_num_rows=\"_\"+str(number_rows)\n",
    "    df_disamb_wos_test=pd.read_csv(path_redbox+'wos_author_disambiguated_2000-2015_USA_processed.tsv', sep=\"\\t\",nrows= number_rows)\n",
    "\n",
    "\n",
    "print \"done reading wos file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author_id</th>\n",
       "      <th>year</th>\n",
       "      <th>author_names</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>total_pubs</th>\n",
       "      <th>Department</th>\n",
       "      <th>firstname</th>\n",
       "      <th>firstname_initial</th>\n",
       "      <th>middle</th>\n",
       "      <th>lastname</th>\n",
       "      <th>list_author_names</th>\n",
       "      <th>University</th>\n",
       "      <th>list_years</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14972627</td>\n",
       "      <td>1973|1980|1983|1992|1993|1994|1995|1996|2000|2...</td>\n",
       "      <td>Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|...</td>\n",
       "      <td>Univ Milan, I-20122 Milan, Italy|OSPED CAMPOSA...</td>\n",
       "      <td>116</td>\n",
       "      <td>[Department Internal Med, Peninsula Med School...</td>\n",
       "      <td>adriano</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>rossi</td>\n",
       "      <td>[rossi, a g, rossi, ag, rossi, a, rossi, adria...</td>\n",
       "      <td>[University Fed Rio De Janeiro, University Mil...</td>\n",
       "      <td>[1973, 1980, 1983, 1992, 1993, 1994, 1995, 199...</td>\n",
       "      <td>adriano g rossi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8198127</td>\n",
       "      <td>1971|1973|1987|1989|1990|1991|1993|1994|1995|1...</td>\n",
       "      <td>Johnson, TM|JOHNSON, TM|Johnson, T|JOHNSON, T|...</td>\n",
       "      <td>UTAH STATE UNIV,DEPT BIOL,LOGAN,UT 84322|UNIV ...</td>\n",
       "      <td>24</td>\n",
       "      <td>[Department Human Genet, Department Dev Biol, ...</td>\n",
       "      <td>tanya</td>\n",
       "      <td>t</td>\n",
       "      <td>m</td>\n",
       "      <td>johnson</td>\n",
       "      <td>[johnson, t, johnson, tanya m , johnson, tm]</td>\n",
       "      <td>[University London, St Louis University, Lehig...</td>\n",
       "      <td>[1971, 1973, 1987, 1989, 1990, 1991, 1993, 199...</td>\n",
       "      <td>tanya m johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>879592</td>\n",
       "      <td>2014|2015</td>\n",
       "      <td>Barker, J. G.|Barker, John G.</td>\n",
       "      <td>NIST, NIST Ctr Neutron Res, Gaithersburg, MD 2...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Nist Center Neutron Res]</td>\n",
       "      <td>john</td>\n",
       "      <td>j</td>\n",
       "      <td>g</td>\n",
       "      <td>barker</td>\n",
       "      <td>[barker, john g , barker, j g]</td>\n",
       "      <td>[Nist]</td>\n",
       "      <td>[2014, 2015]</td>\n",
       "      <td>john g barker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  author_id                                               year  \\\n",
       "0           0   14972627  1973|1980|1983|1992|1993|1994|1995|1996|2000|2...   \n",
       "1           1    8198127  1971|1973|1987|1989|1990|1991|1993|1994|1995|1...   \n",
       "2           2     879592                                          2014|2015   \n",
       "\n",
       "                                        author_names  \\\n",
       "0  Rossi, Adriano G.|Rossi, Adriano|Rossi, A. G.|...   \n",
       "1  Johnson, TM|JOHNSON, TM|Johnson, T|JOHNSON, T|...   \n",
       "2                      Barker, J. G.|Barker, John G.   \n",
       "\n",
       "                                        affiliations  total_pubs  \\\n",
       "0  Univ Milan, I-20122 Milan, Italy|OSPED CAMPOSA...         116   \n",
       "1  UTAH STATE UNIV,DEPT BIOL,LOGAN,UT 84322|UNIV ...          24   \n",
       "2  NIST, NIST Ctr Neutron Res, Gaithersburg, MD 2...           2   \n",
       "\n",
       "                                          Department firstname  \\\n",
       "0  [Department Internal Med, Peninsula Med School...   adriano   \n",
       "1  [Department Human Genet, Department Dev Biol, ...     tanya   \n",
       "2                          [Nist Center Neutron Res]      john   \n",
       "\n",
       "  firstname_initial middle lastname  \\\n",
       "0                 a      g    rossi   \n",
       "1                 t      m  johnson   \n",
       "2                 j      g   barker   \n",
       "\n",
       "                                   list_author_names  \\\n",
       "0  [rossi, a g, rossi, ag, rossi, a, rossi, adria...   \n",
       "1       [johnson, t, johnson, tanya m , johnson, tm]   \n",
       "2                     [barker, john g , barker, j g]   \n",
       "\n",
       "                                          University  \\\n",
       "0  [University Fed Rio De Janeiro, University Mil...   \n",
       "1  [University London, St Louis University, Lehig...   \n",
       "2                                             [Nist]   \n",
       "\n",
       "                                          list_years        full_name  \n",
       "0  [1973, 1980, 1983, 1992, 1993, 1994, 1995, 199...  adriano g rossi  \n",
       "1  [1971, 1973, 1987, 1989, 1990, 1991, 1993, 199...  tanya m johnson  \n",
       "2                                       [2014, 2015]    john g barker  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disamb_wos_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# type(df_disamb_wos_test.University.iloc[0])\n",
    "\n",
    "\n",
    "# type(df_linkedin_test.University.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_disamb_wos_test['full_name'] = df_disamb_wos_test.full_name.apply(convert_unicode_to_string)\n",
    "df_disamb_wos_test['firstname'] = df_disamb_wos_test.firstname.apply(convert_unicode_to_string)\n",
    "df_disamb_wos_test['middle'] = df_disamb_wos_test.middle.apply(convert_unicode_to_string)\n",
    "df_disamb_wos_test['lastname'] = df_disamb_wos_test.lastname.apply(convert_unicode_to_string)\n",
    "df_disamb_wos_test['University'] = df_disamb_wos_test.University.apply(convert_unicode_to_string)\n",
    "\n",
    "\n",
    "df_disamb_wos_test['University'] = df_disamb_wos_test.apply(lambda row: row.University.replace(\", \",\",\").replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"), axis=1)\n",
    "\n",
    "# example:  [University Michigan, University Michigan Hlth Syst]\n",
    "\n",
    "\n",
    "#total_rows['ColumnID'] = total_rows['ColumnID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_disamb_wos_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_disamb_wos_test = df_disamb_wos_test.drop('Unnamed: 0', 1)\n",
    "# df_disamb_wos_test = df_disamb_wos_test.drop('list_years', 1)\n",
    "# df_disamb_wos_test = df_disamb_wos_test.drop('list_years', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "#path_linkedin_win='C:\\\\Users\\\\julietta\\\\Work\\\\Dropbox_studies\\\\Data\\\\Vinu_University_Sheets\\\\Improved_3Feb\\\\All_linkedIn_new_indeces.pickle'   \n",
    "path_linkedin_linux=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Vinu_University_Sheets/Improved_3Feb_and_more_emails_27Feb/All_linkedIn.pickle\"\n",
    "\n",
    "df_linkedin_test=pd.read_pickle(path_linkedin_linux)\n",
    "\n",
    "\n",
    "\n",
    "df_linkedin_test = df_linkedin_test.rename(columns={'Department(s)': 'Department', 'School/college': 'School_college'})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lista=df_linkedin_test.columns\n",
    "# #type(df_linkedin_test.University.iloc[0])\n",
    "# for item in lista:\n",
    "#     print item\n",
    "\n",
    "\n",
    "# print df_linkedin_test.shape\n",
    "\n",
    "# df_linkedin_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df_disamb_wos_test['Department'] = df_disamb_wooutput_fuzzy_match_0.985s_test.affiliations.apply(get_department_names)\n",
    "\n",
    "df_linkedin_test['full_name'] = df_linkedin_test.full_name.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['firstname'] = df_linkedin_test.firstname.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['middle'] = df_linkedin_test.middle.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['lastname'] = df_linkedin_test.lastname.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['dirty_firstname'] = df_linkedin_test.dirty_firstname.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['dirty_lastname'] = df_linkedin_test.dirty_lastname.apply(convert_unicode_to_string)\n",
    "\n",
    "df_linkedin_test['University'] = df_linkedin_test.University.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['Department'] = df_linkedin_test.Department.apply(convert_unicode_to_string)\n",
    "df_linkedin_test['School_college'] = df_linkedin_test.School_college.apply(convert_unicode_to_string)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_linkedin_test['Name_and_Univ'] = df_linkedin_test.apply(lambda row: row.full_name + \" \"+ row.University, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_linkedin_test.head(3)\n",
    "# type(df_linkedin_test.iloc[671].University)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_linkedin_test.columns\n",
    "\n",
    "df_linkedin_test.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WoS:  (1000000, 14)\n",
      "LinkedIn:  (83072, 145)\n"
     ]
    }
   ],
   "source": [
    "print \"WoS: \",df_disamb_wos_test.shape\n",
    "print \"LinkedIn: \",df_linkedin_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_disamb_wos_test.iloc[434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_closest_match(cadena_name_and_univ, list_univ_wos, cadena_full_name_wos):    \n",
    "    \n",
    "    \n",
    "     #difflib.get_close_matches(a,b,3)   # this one gets you as many close matches as you want, in descending order of matching\n",
    "        \n",
    "#     print cadena_name_and_univ, list_univ_wos, cadena_full_name_wos    \n",
    "#     print type(cadena_name_and_univ), type(list_univ_wos), type(cadena_full_name_wos)\n",
    "#     raw_input()\n",
    "     ###   difflib.get_close_print \"wos univ:\", df_disamb_wos_test.University.unique()matches?   #### to read the manual of sth\n",
    "    \n",
    "    \n",
    "    score=0.\n",
    "    match=None\n",
    "    \n",
    "    a=cadena_name_and_univ.replace(\"  \",\" \").lower()\n",
    "    lista=list_univ_wos\n",
    "    dict_index_score={}\n",
    "    for i in range(len(lista)):\n",
    "    \n",
    "        b=(cadena_full_name_wos + \" \" + lista[i]).replace(\"  \",\" \").lower()\n",
    "        score = difflib.SequenceMatcher(None,a, b).ratio()  \n",
    "        dict_index_score[i]=score\n",
    "\n",
    "  \n",
    "    sorted_dict = sorted(dict_index_score.items(), key=lambda x: x[1],reverse=True) # SORT DICT BY VALUE, IN DESCENDING ORDER     print \"sorted dictsorted_dict\",sorted_dict ## [(3, 0.9285714285714286), (6, 0.7586206896551724), (0, 0.6896551724137931), (5, 0.37037037037037035), (2, 0.35714285714285715), (4, 0.35714285714285715), (1, 0.23076923076923078)]\n",
    "\n",
    "    match=(cadena_full_name_wos + \" \" + lista[sorted_dict[0][0]]).lower()\n",
    "    index=sorted_dict[0][0]\n",
    "    score=sorted_dict[0][1]\n",
    "\n",
    "   \n",
    "    return match, score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering a loop of 83072 iters (linkedin rows)......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold  = 0.985  # to accept a matching of two strings\n",
    "    \n",
    "    \n",
    "# given two dataframes, i go over all names in one (linkedin)   and find  matches from the other\n",
    "\n",
    "master_dict_linkedin_index_wos_index={}\n",
    "cont=0\n",
    "print \"entering a loop of\",len(df_linkedin_test), \"iters (linkedin rows)......\\n\"\n",
    "\n",
    "\n",
    "cont_ambig=0\n",
    "# for row in tqdm_nofull_nametebook(df_linkedin_test.head(5000).iterrows()):       \n",
    "#for row in df_linkedin_test.head(1000).iterrows():       \n",
    "lista_linkedin_idx=[]\n",
    "#for row in tqdm_notebook(df_linkedin_test.head(5000).iterrows()):       \n",
    "for row in tqdm_notebook(df_linkedin_test.head(5000).iterrows()):       \n",
    "    cont +=1\n",
    "\n",
    "    linkedin_index=row[0]\n",
    "       #print (cont, linkedin_index)\n",
    "\n",
    "    lista_linkedin_idx.append(linkedin_index)\n",
    "\n",
    "    master_dict_linkedin_index_wos_index[linkedin_index]=[]\n",
    "    matching_dict_univ_linkedin_univ_wos={}     \n",
    "\n",
    "\n",
    "    univ_linkedin=row[1].University    \n",
    "    lastname_linkedin=row[1].lastname    \n",
    "    full_name_linkedin=row[1].full_name\n",
    "\n",
    "    name_and_univ_linkedin=row[1].Name_and_Univ\n",
    "    \n",
    "    lista_posibles_wos_index=[] \n",
    "\n",
    "\n",
    "    try:   # if the whole row is not just NANs    \n",
    "\n",
    "        #LINKEDIN:   dirty_firstname\tdirty_lastname\tfull_name\tfirstname\tmiddle\tlastname\n",
    "        #WOS:      firstname\tfirstname_initial\tmiddle\tlastname\tlist_author_names\tUniversity\tlist_years\tfull_name\n",
    "        \n",
    "      \n",
    "        select_df_wos_one_lastname=df_disamb_wos_test[df_disamb_wos_test.lastname == lastname_linkedin]                        \n",
    "\n",
    "#         print name_and_univ_linkedin, \"        # potential matches by lastname:\",len(select_df_wos_one_lastname)\n",
    "        for fila in  select_df_wos_one_lastname.iterrows():  # one row per author\n",
    "\n",
    "                list_univ_wos=fila[1].University\n",
    "                full_name_wos=fila[1].full_name\n",
    "            \n",
    "                wos_index=fila[0]                       \n",
    "            \n",
    "                match, score= find_closest_match(name_and_univ_linkedin, list_univ_wos, full_name_wos)\n",
    "\n",
    "\n",
    "                if score > threshold:  #if the result of the matching is worth considering\n",
    "                \n",
    "                    master_dict_linkedin_index_wos_index[linkedin_index].append(wos_index)                                   \n",
    "                    lista_posibles_wos_index.append(wos_index)   \n",
    "#                     print \"\\nbest matching for:    \", name_and_univ_linkedin,\"           is:\", match, \"       score:\"    , score\n",
    "#                     raw_input()\n",
    "\n",
    "\n",
    "\n",
    "    #      print (lista_posibles_wos_index)\n",
    "        if len(lista_posibles_wos_index)>1:\n",
    "                cont_ambig +=1\n",
    "    except TypeError:   # for the few empty rows (all Nan)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "print \"done\"\n",
    " \n",
    "#     print type(cadena_name_and_univ), type(list_univ_wos), type(cadena_full_name_wos)\n",
    "\n",
    "print \"# of linkedin names with wos ambiguity:\", cont_ambig\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a=\"robert bates harvard university\"\n",
    "# b=\"robert bates harvard university\"\n",
    "\n",
    "# score = difflib.SequenceMatcher(None,a, b).ratio()  \n",
    "# print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# #path_merge_win='C:\\\\Users\\\\julietta\\\\Work\\\\Dropbox_studies\\\\Data\\\\Merged_LinkedIn_WoS\\\\'\n",
    "# path_merge_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "path_merge_redbox='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "filename_pickle=path_merge_redbox+\"master_dict_linkedin_index_wos_index_fuzzy_matching_name_and_univ\"+string_num_rows+\".pickle\"    \n",
    "pickle.dump(master_dict_linkedin_index_wos_index, open(filename_pickle, 'wb'))\n",
    "print \"written:\",filename_pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linkedin  wos\n",
      "# linkedin names:  5000\n",
      "  # linkedin authors found:  2493\n",
      "      # linkedin authors found but with ambiguity:  1580\n",
      "  # link.firstname_or_initialedin authors NOT found:  2507\n",
      "\n",
      "\n",
      "size list linkedin idx 5000   unique: 5000\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "print \"linkedin  wos\"\n",
    "cont_found=0\n",
    "cont_ambiguedad=0\n",
    "cont_no_match=0\n",
    "for llave in master_dict_linkedin_index_wos_index:\n",
    "    if len(master_dict_linkedin_index_wos_index[llave]) >0:\n",
    "        #print (llave, master_dict_linkedin_index_wos_index[llave])\n",
    "        cont_found +=1\n",
    "        if len(master_dict_linkedin_index_wos_index[llave]) >1:\n",
    "            cont_ambiguedad +=1\n",
    "    else:\n",
    "        cont_no_match +=1\n",
    "        \n",
    "print \"# linkedin names: \",len(master_dict_linkedin_index_wos_index)\n",
    "print \"  # linkedin authors found: \", cont_found\n",
    "print \"      # linkedin authors found but with ambiguity: \", cont_ambiguedad\n",
    "print \"  # link.firstname_or_initialedin authors NOT found: \", cont_no_match\n",
    "print \"\\n\"\n",
    "    \n",
    "print \"size list linkedin idx\",len(lista_linkedin_idx), \"  unique:\", len(set(lista_linkedin_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path_merge_linux='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "# filename_pickle=path_merge_linux+\"8feb_master_dict_linkedin_index_wos_index.pickle\"\n",
    "\n",
    "# pickled_master_dict_linkedin_index_wos_index=pd.read_pickle(filename_pickle)\n",
    "\n",
    "# print df_linkedin_test.iloc[4821]\n",
    "# print df_disamb_wos_test.iloc[27883]\n",
    "# #perfect_selection.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "linkedin_idx  wos_idx\n",
      "3 [914060]\n",
      "18 [519471]\n",
      "20 [559062]\n",
      "32 [743657]\n",
      "37 [89692, 272844, 660344]\n",
      "48 [513475]\n",
      "62 [21556]\n",
      "68 [782901]\n",
      "71 [502140, 922102]\n",
      "73 [21324, 349069, 487923]\n",
      "83 [913763]\n",
      "138 [274132]\n",
      "164 [210794]\n",
      "169 [953960]\n",
      "187 [336693]\n",
      "189 [962360]\n",
      "194 [544037]\n",
      "195 [467512]\n",
      "203 [706701]\n",
      "207 [206469]\n",
      "222 [821019]\n",
      "241 [310393]\n",
      "250 [582856]\n",
      "253 [837611]\n",
      "258 [675716]\n",
      "267 [555625, 813528]\n",
      "292 [413129]\n",
      "302 [705889]\n",
      "331 [842668]\n",
      "334 [573032]\n",
      "344 [792760]\n",
      "355 [833213, 990177]\n",
      "358 [86778]\n",
      "366 [622208]\n",
      "377 [407048]\n",
      "384 [685730]\n",
      "386 [625788]\n",
      "407 [350424, 549779]\n",
      "429 [232384]\n",
      "432 [438434]\n",
      "441 [712213]\n",
      "452 [552261, 735749]\n",
      "465 [951713]\n",
      "483 [58469]\n",
      "486 [627876]\n",
      "487 [65734, 809239]\n",
      "489 [13256, 185046, 681015]\n",
      "492 [420945, 674002]\n",
      "503 [459109]\n",
      "505 [630004]\n",
      "507 [99657]\n",
      "527 [30394, 213924]\n",
      "529 [758962]\n",
      "532 [9855]\n",
      "538 [912977]\n",
      "585 [484869]\n",
      "603 [108021, 851076]\n",
      "605 [997841]\n",
      "619 [428241]\n",
      "652 [583657]\n",
      "655 [34783]\n",
      "659 [124958]\n",
      "662 [370129]\n",
      "673 [930303]\n",
      "680 [559340]\n",
      "692 [744654]\n",
      "693 [57928]\n",
      "707 [778766]\n",
      "711 [250971]\n",
      "722 [836019, 898876]\n",
      "723 [85977]\n",
      "745 [37282]\n",
      "748 [942654]\n",
      "762 [105761]\n",
      "776 [672944]\n",
      "778 [575636]\n",
      "808 [321284]\n",
      "817 [149931]\n",
      "818 [165960, 202484, 229696, 533108, 675183, 747811, 795884, 806281, 928039]\n",
      "825 [275828]\n",
      "827 [757948]\n",
      "830 [407439]\n",
      "831 [309365]\n",
      "846 [21225]\n",
      "856 [505884]\n",
      "857 [353084]\n",
      "860 [721196]\n",
      "866 [878533]\n",
      "871 [245238]\n",
      "875 [955846]\n",
      "877 [225343, 265146]\n",
      "886 [477994]\n",
      "889 [795717]\n",
      "899 [749808]\n",
      "900 [507909, 868299]\n",
      "905 [232831]\n",
      "907 [545057]\n",
      "926 [188571]\n",
      "930 [272805, 289966]\n",
      "932 [428423]\n",
      "947 [375772]\n",
      "953 [672870]\n",
      "1014 [775420]\n",
      "1015 [253675]\n",
      "1039 [932314]\n",
      "1048 [785717]\n",
      "1055 [503965]\n",
      "1065 [590044]\n",
      "1069 [903498]\n",
      "1084 [106188]\n",
      "1090 [102894]\n",
      "1105 [39088]\n",
      "1151 [546864]\n",
      "1155 [84045, 728447]\n",
      "1162 [6768, 932601]\n",
      "1170 [424776]\n",
      "1195 [754130]\n",
      "1200 [622960]\n",
      "1222 [158552]\n",
      "1225 [538609]\n",
      "1228 [105745, 497340]\n",
      "1248 [252129]\n",
      "1250 [204897]\n",
      "1266 [526073]\n",
      "1284 [344973]\n",
      "1295 [338969, 993264]\n",
      "1306 [813181]\n",
      "1331 [488747, 691910]\n",
      "1335 [316925, 949695]\n",
      "1336 [910202]\n",
      "1342 [680086, 866096, 939989]\n",
      "1344 [151912, 910769, 916948]\n",
      "1349 [160669]\n",
      "1353 [139567, 227317]\n",
      "1354 [568453]\n",
      "1356 [498469]\n",
      "1358 [505404]\n",
      "1361 [191880]\n",
      "1365 [491986]\n",
      "1366 [264459]\n",
      "1376 [389952]\n",
      "1377 [172078, 544639, 763379]\n",
      "1381 [670105, 985475]\n",
      "1387 [917995]\n",
      "1389 [820124]\n",
      "1391 [506315]\n",
      "1392 [290870]\n",
      "1394 [549791, 935054]\n",
      "1404 [399386, 505280, 644066, 886985]\n",
      "1405 [181008]\n",
      "1412 [463116]\n",
      "1426 [181828]\n",
      "1434 [561581]\n",
      "1436 [771975]\n",
      "1437 [258872, 763523, 800839]\n",
      "1441 [552552]\n",
      "1444 [974754]\n",
      "1446 [326258]\n",
      "1448 [5341, 394722, 438061]\n",
      "1454 [505404]\n",
      "1456 [290870]\n",
      "1457 [418039]\n",
      "1459 [491986]\n",
      "1469 [740273]\n",
      "1478 [84931]\n",
      "1479 [510678, 826148]\n",
      "1482 [433943]\n",
      "1485 [652251]\n",
      "1486 [561581]\n",
      "1488 [625493, 651243]\n",
      "1489 [162303]\n",
      "1494 [886546]\n",
      "1495 [883056]\n",
      "1499 [928494]\n",
      "1501 [505404]\n",
      "1532 [737102]\n",
      "1536 [712634]\n",
      "1547 [388605]\n",
      "1560 [662686]\n",
      "1565 [211153]\n",
      "1567 [672268]\n",
      "1579 [652813]\n",
      "1580 [321928]\n",
      "1581 [346720]\n",
      "1588 [750468]\n",
      "1589 [371281]\n",
      "1595 [326258]\n",
      "1596 [647261]\n",
      "1602 [55670, 919482]\n",
      "1604 [249334]\n",
      "1616 [27435]\n",
      "1618 [258872, 763523, 800839]\n",
      "1619 [552552]\n",
      "1621 [147663, 602308]\n",
      "1622 [996466]\n",
      "1624 [505404]\n",
      "1627 [418039]\n",
      "1628 [687827]\n",
      "1629 [170584, 281724]\n",
      "1632 [716404]\n",
      "1633 [191036]\n",
      "1634 [841990]\n",
      "1636 [128743]\n",
      "1648 [237853, 333976, 581649, 963899]\n",
      "1655 [387252, 944037]\n",
      "1656 [742570]\n",
      "1657 [819340, 868351]\n",
      "1670 [89692, 272844, 660344]\n",
      "1671 [375022]\n",
      "1673 [767424]\n",
      "1688 [799248]\n",
      "1697 [722422]\n",
      "1700 [293109]\n",
      "1703 [764321]\n",
      "1709 [671115]\n",
      "1716 [165184]\n",
      "1720 [746680]\n",
      "1727 [871455]\n",
      "1733 [927544]\n",
      "1734 [491242]\n",
      "1738 [539838]\n",
      "1753 [244831]\n",
      "1758 [183611]\n",
      "1760 [607847]\n",
      "1777 [644393]\n",
      "1783 [849035]\n",
      "1788 [163447]\n",
      "1793 [749279]\n",
      "1803 [199063]\n",
      "1805 [658969, 686004]\n",
      "1823 [824240]\n",
      "1839 [334436]\n",
      "1877 [563554]\n",
      "1927 [179582]\n",
      "2043 [967982]\n",
      "2082 [377932, 551972]\n",
      "2102 [591015, 639119]\n",
      "2125 [496256]\n",
      "2135 [357963]\n",
      "4189 [866910]\n",
      "4190 [58515]\n",
      "4191 [529766]\n",
      "4199 [994128]\n",
      "4218 [405812]\n",
      "4232 [251314]\n",
      "4265 [990956]\n",
      "4275 [638240]\n",
      "4276 [660918]\n",
      "4283 [76890]\n",
      "4284 [87086]\n",
      "4295 [311644]\n",
      "4302 [95313]\n",
      "4303 [629835]\n",
      "4323 [180302]\n",
      "4341 [123049]\n",
      "4344 [980408]\n",
      "4345 [857328]\n",
      "4347 [626135]\n",
      "4349 [767654]\n",
      "4358 [270311]\n",
      "4367 [844422]\n",
      "4377 [173272]\n",
      "4382 [197874, 434149, 477510, 571756, 595291, 707380, 885767, 932768]\n",
      "4384 [707547]\n",
      "4386 [210015]\n",
      "4392 [912788]\n",
      "4421 [941870]\n",
      "4426 [613849]\n",
      "4427 [368649]\n",
      "4434 [473449, 549973]\n",
      "4445 [102683]\n",
      "4446 [102683]\n",
      "4449 [365220, 419460, 707371, 802888]\n",
      "4450 [849368]\n",
      "4469 [651612]\n",
      "4479 [572477]\n",
      "4480 [806425]\n",
      "4489 [223697, 506079]\n",
      "4491 [609335]\n",
      "4494 [18979]\n",
      "4497 [932427]\n",
      "4500 [451911]\n",
      "4505 [831260]\n",
      "4529 [400992]\n",
      "4537 [892942]\n",
      "4541 [853193]\n",
      "4542 [972738]\n",
      "4544 [140590]\n",
      "4545 [770999]\n",
      "4550 [215124, 745668]\n",
      "4562 [649018]\n",
      "4571 [809559]\n",
      "4573 [716388]\n",
      "4576 [129280]\n",
      "4602 [161657]\n",
      "4618 [950376]\n",
      "4619 [69767]\n",
      "4620 [424423]\n",
      "4627 [685713]\n",
      "4628 [394218]\n",
      "4635 [968510]\n",
      "4636 [96941]\n",
      "4637 [27602]\n",
      "4645 [881943]\n",
      "4646 [324401]\n",
      "4647 [750093]\n",
      "4648 [200107]\n",
      "4652 [432356]\n",
      "4657 [233645]\n",
      "4658 [500029]\n",
      "4665 [218720, 439825]\n",
      "4671 [379642]\n",
      "4678 [238480]\n",
      "4681 [178926]\n",
      "4684 [664848]\n",
      "4704 [247621]\n",
      "4706 [690503, 708148]\n",
      "4710 [349715]\n",
      "4715 [333163, 358293, 546247, 883356]\n",
      "4716 [271273, 408572, 620075, 678000, 812182]\n",
      "4737 [52363, 628966]\n",
      "4744 [476449]\n",
      "4750 [173297]\n",
      "4751 [190815, 602268, 828171, 981687]\n",
      "4769 [620732]\n",
      "4774 [609514]\n",
      "4784 [265014]\n",
      "4788 [797396]\n",
      "4808 [720487]\n",
      "4812 [261016]\n",
      "4817 [298697]\n",
      "4818 [776118]\n",
      "4821 [23433]\n",
      "4825 [493298]\n",
      "4828 [179887]\n",
      "4832 [402094]\n",
      "4922 [792926]\n",
      "4937 [475740]\n",
      "4955 [318791]\n",
      "4964 [69800]\n",
      "4977 [426377]\n",
      "4979 [23508]\n",
      "4983 [92267]\n",
      "4991 [157591]\n",
      "4992 [496189]\n",
      "numb linkedin names:  5000\n",
      "  numb. linkedin authors found:  345\n",
      "      numb. linkedin authors found but with ambiguity:  56\n",
      "  numb. linkedin authors NOT found:  4655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print len(master_dict_linkedin_index_wos_index)\n",
    "\n",
    "print \"linkedin_idx  wos_idx\"\n",
    "cont_found=0\n",
    "cont_ambiguedad=0\n",
    "cont_no_match=0\n",
    "for llave in master_dict_linkedin_index_wos_index:\n",
    "    if len(master_dict_linkedin_index_wos_index[llave]) >0:\n",
    "        print llave, master_dict_linkedin_index_wos_index[llave]\n",
    "        cont_found +=1\n",
    "        if len(master_dict_linkedin_index_wos_index[llave]) >1:\n",
    "            cont_ambiguedad +=1 \n",
    "    else:\n",
    "        cont_no_match +=1\n",
    "        \n",
    "print \"numb linkedin names: \",len(master_dict_linkedin_index_wos_index)\n",
    "print \"  numb. linkedin authors found: \", cont_found\n",
    "print \"      numb. linkedin authors found but with ambiguity: \", cont_ambiguedad\n",
    "print \"  numb. linkedin authors NOT found: \", cont_no_match\n",
    "print \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written: /home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/checking_fuzzy_matcht_LinkedIn_WoS_ONE_name__1000000THR0.95.dat\n"
     ]
    }
   ],
   "source": [
    "filename_output='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/checking_fuzzy_matcht_LinkedIn_WoS_multiple_names_'+string_num_rows+'THR0.95.dat'\n",
    "output=open(filename_output,'wt')\n",
    "\n",
    "for linkedin_idx in master_dict_linkedin_index_wos_index:\n",
    "\n",
    "   \n",
    "    if len(master_dict_linkedin_index_wos_index[linkedin_idx])==1:      \n",
    "        \n",
    "        try:\n",
    "            print >> output, \"\\n\\nLINKEDIN idx:\",linkedin_idx, \"  \",df_linkedin_test.iloc[linkedin_idx].full_name.title() ,\" || \", df_linkedin_test.iloc[linkedin_idx].Current_Title,\" || \", df_linkedin_test.iloc[linkedin_idx].University,\" || \", df_linkedin_test.iloc[linkedin_idx].Department\n",
    "            print >> output ,\"\"\n",
    "\n",
    "\n",
    "            for wos_indx in master_dict_linkedin_index_wos_index[linkedin_idx]:\n",
    "\n",
    "                print >> output , \"  ---wos_idx:\", wos_indx\n",
    "                print >> output ,\"  \", df_disamb_wos_test.iloc[wos_indx].full_name\n",
    "                print >> output ,\"  \",df_disamb_wos_test.iloc[wos_indx].University\n",
    "                print >> output ,\"  \", df_disamb_wos_test.iloc[wos_indx].Department\n",
    "                print >> output ,\"  \",df_disamb_wos_test.iloc[wos_indx].total_pubs , \"publ\"\n",
    "                print >> output ,\"  \",df_disamb_wos_test.iloc[wos_indx].year\n",
    "                \n",
    "        except UnicodeEncodeError:\n",
    "            pass# print df_linkedin_test.iloc[linkedin_idx]\n",
    "            \n",
    "output.close()\n",
    "print \"written:\",filename_output       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_disamb_wos_test.iloc[6358]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_not_found_linkedin_lastnames=[]\n",
    "list_found_linkedin_lastnames=[]\n",
    "for linkedin_idx in master_dict_linkedin_index_wos_index:\n",
    "    #print linkedin_idx, pickled_master_dict_linkedin_index_wos_index[linkedin_idx]\n",
    "    if len(master_dict_linkedin_index_wos_index[linkedin_idx]) == 0:\n",
    "            list_not_found_linkedin_lastnames.append(df_linkedin_test.iloc[linkedin_idx].lastname)\n",
    "    else:\n",
    "        list_found_linkedin_lastnames.append(df_linkedin_test.iloc[linkedin_idx].lastname)\n",
    "           \n",
    "            \n",
    "print \"tot # names on linkedin\", len(master_dict_linkedin_index_wos_index)   # 81444\n",
    "print \"# linkedin lastnmes NOT found on wos:\",len(list_not_found_linkedin_lastnames), \"  unique:\",len(set(list_not_found_linkedin_lastnames))  #    48840   unique: 29070  \n",
    "print \"# linkedin lastnames found on wos:\",len(list_found_linkedin_lastnames), \"  unique:\",len(set(list_found_linkedin_lastnames))   #  32604   unique: 18840 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_lastnames_in_wos=list(df_disamb_wos_test.lastname.values)\n",
    "\n",
    "\n",
    "\n",
    "print \"# wos lastnames:\",len(list_lastnames_in_wos), \"  unique:\",len(set(list_lastnames_in_wos))\n",
    "\n",
    "# for lastname in list_not_found_linkedin_lastnames:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print \"overlap between all wos lastnames and linkedin lastnames not found on wos:\", \\\n",
    "len(list( set(list_lastnames_in_wos)  &   set(list_not_found_linkedin_lastnames)   ))   #  20104    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wos_with_new_column=df_disamb_wos_test.copy()\n",
    "linkedin_with_new_column=df_linkedin_test.copy()\n",
    "\n",
    "\n",
    "wos_with_new_column.head()\n",
    "linkedin_with_new_column.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wos_with_new_column=wos_with_new_column.assign(merging_idx=np.nan)\n",
    "\n",
    "linkedin_with_new_column=linkedin_with_new_column.assign(merging_idx=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wos_with_new_column.head()\n",
    "linkedin_with_new_column.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "cont_merging_idx=0\n",
    "for linkedin_idx in master_dict_linkedin_index_wos_index:\n",
    "    \n",
    "    try:\n",
    "        wos_idx=master_dict_linkedin_index_wos_index[linkedin_idx][0] # OJO!!! for now i only consider one of the potentialy multiple wos_idx associated to a given linkedin idx\n",
    "        wos_with_new_column.set_value(wos_idx, 'merging_idx',int(cont_merging_idx) )\n",
    "    # df.set_value('C', 'x', 10)     where:   index=['A','B','C']  and columns=['x','y']\n",
    "        linkedin_with_new_column.set_value(linkedin_idx, 'merging_idx', int(cont_merging_idx) )\n",
    "  \n",
    "        \n",
    "        \n",
    "    except IndexError:\n",
    "        linkedin_with_new_column.set_value(linkedin_idx, 'merging_idx', 999999999 )\n",
    "  \n",
    "        \n",
    "#         print linkedin_idx, pickled_master_dict_linkedin_index_wos_index[linkedin_idx]\n",
    "#         raw_input()\n",
    "     \n",
    "    \n",
    "    cont_merging_idx +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wos_with_new_column.head(10000)\n",
    "#linkedin_with_new_column.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linkedin_with_new_column=linkedin_with_new_column.rename(columns = {'firstname':'firstname_linkedin'})\n",
    "linkedin_with_new_column=linkedin_with_new_column.rename(columns = {'lastname':'lastname_linkedin'})\n",
    "linkedin_with_new_column=linkedin_with_new_column.rename(columns = {'full_namename':'full_name_linkedin'})\n",
    "linkedin_with_new_column=linkedin_with_new_column.rename(columns = {'middle':'middle_linkedin'})\n",
    "\n",
    "linkedin_with_new_column=linkedin_with_new_column.rename(columns = {'University':'University_linkedin'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(linkedin_with_new_column, wos_with_new_column, how='left',on='merging_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_merged='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Merged_LinkedIn_WoS/'\n",
    "\n",
    "merged_file_name=path_merged+\"Merged_linkedin-wos_fuzzy_matching_name_and_univ.tsv\"\n",
    "\n",
    "df_merged.to_csv(merged_file_name, sep='\\t', encoding='utf-8')#, columns = list_headers)\n",
    "print \"tsv done\"\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(path_merged+\"Merged_linkedin-wos_fuzzy_matching_name_and_unvi.xlsx\", engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df_merged.to_excel(writer, sheet_name='Sheet1')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "print \"xlsx done\"\n",
    "\n",
    "df_merged.to_pickle(merged_file_name.split(\".tsv\")[0]+\".pickle\")\n",
    "print \"pickle done\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_merged.merged_idx.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "fe2c724e29b34392aa827da773fdb20a": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
