{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt   \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import scipy\n",
    "import operator\n",
    "import difflib\n",
    "import math\n",
    "from IPython.core.display import display,HTML\n",
    "try:\n",
    "    import cPickle as pickle     #it is faster than pickle!\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import unicodedata\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import seaborn as sns   ### https://seaborn.pydata.org/tutorial/categorical.html\n",
    "    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # to make the notebook use the entire width of the browser\n",
    "\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# i only need my credentials if i want to plot online --- and send plots to server (limits per day apply!)\n",
    "#import plotly.tools as tls\n",
    "#tls.set_credentials_file(username='juliettapc', api_key='deyNIvtOoDZ5PLmrHlhd')  # my plotly account credentials\n",
    "\n",
    "\n",
    "import pygraphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## to be able to plot offline (without sending the plots to the plotly server every time)\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403349, 38)\n",
      "440353\n",
      "(440353, 14)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Data/Dropbox/\"\n",
    "input_file = 'Dropbox_datafile_complete_new_ranking.csv'\n",
    "#input_file = 'Dropbox_datafile_may22_2017_modified_added_univ_country_geolocation_RUCC_population_density_when_available_career_stage_GINI_folder_act_categories.csv'\n",
    "df = pd.read_csv(path+input_file, sep=';',na_values=[\"NAN\",\"-1\",\"null\"],low_memory=False, parse_dates=['folder_creation_date','date_last_change']) # set header=0 if i wanna pass it my own list of header names\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "print df.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######## load dictionary aggregated info by user  \n",
    "pickle_name='/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/dict_user_id_user_attr_more_var.pickle'\n",
    "with open(pickle_name, 'rb') as handle:\n",
    "    dict_user_id_user_attr = pickle.load(handle)\n",
    "print len(dict_user_id_user_attr.keys())\n",
    "\n",
    "df_users = pd.DataFrame.from_dict(dict_user_id_user_attr,orient='index')\n",
    "#df_selection_users=df_folders[df_folders['user_univ_ranking']<=50]\n",
    "print df_users.shape   # 440353, 11\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27029.3620573 28.0\n"
     ]
    }
   ],
   "source": [
    "df_users.columns\n",
    "print df_users.user_tot_act.mean(), df_users.user_tot_act.quantile(q=0.6)\n",
    "act_threshold=60  #  28 is the 60% ,  56 is the 65%  ,   168 is the 70% percentile (50% percentile is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for item in df.email_domain.unique():\n",
    "#     print item,\"   \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #### time window for temporal networks\n",
    "# string_start_date='2014-05-01'\n",
    "# start_date=pd.Timestamp(string_start_date)\n",
    "\n",
    "# #string_end_date='2014-11-01'\n",
    "# end_date=start_date + pd.Timedelta('180 days')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list_tupla_dates=[]\n",
    "# for i in range(6):\n",
    "#     print start_date, end_date    \n",
    "#     tupla_dates=[start_date,end_date]\n",
    "#     list_tupla_dates.append(tupla_dates)\n",
    "\n",
    "    \n",
    "#     start_date += pd.Timedelta('180 days')\n",
    "#     end_date += pd.Timedelta('180 days')\n",
    "\n",
    "# # 2014-05-01_2014-10-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### for plotting time series directly from data\n",
    "#df.plot(x='folder_creation_date',y='folder_lifespan',ls='',marker='.') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "G=nx.Graph()\n",
    "dict_folder_list_users={}\n",
    "dict_folder_dict_user_act_in_folder={}\n",
    "\n",
    "    \n",
    "for row in tqdm_notebook(df.iterrows()):\n",
    "\n",
    "        folder=row[1][\"folder_id\"]\n",
    "        user_id=row[1][\"user_id\"]                           \n",
    "        \n",
    "        try: \n",
    "            dict_folder_list_users[folder].append(user_id)\n",
    "        except:\n",
    "            dict_folder_list_users[folder]=[]\n",
    "            dict_folder_list_users[folder].append(user_id)\n",
    "     \n",
    "print \"done with the dict., size:\",len(dict_folder_list_users)\n",
    "\n",
    "\n",
    "\n",
    "for folder in dict_folder_list_users:\n",
    "        dict_folder_list_users[folder]=list(set(dict_folder_list_users[folder]))  # remove possible duplicates      \n",
    "\n",
    "        lista=dict_folder_list_users[folder]\n",
    "\n",
    "        if len(lista)>1:\n",
    "\n",
    "            lista_pares=itertools.combinations(lista, 2)        \n",
    "\n",
    "            for item in lista_pares:\n",
    "                e1=item[0]\n",
    "                e2=item[1]\n",
    "                G.add_edge(e1,e2)\n",
    "                \n",
    "                try: \n",
    "                    G.edge[e1][e2][\"num_common_projects\"] +=1\n",
    "                except KeyError:\n",
    "                    G.edge[e1][e2][\"num_common_projects\"] =1\n",
    "                    \n",
    "#                 print e1, e2, G.edge[e1][e2][\"num_common_folders\"]    \n",
    "#                 raw_input()\n",
    "               # print \"added edge:\",e1, e2\n",
    "    \n",
    "        else:\n",
    "            n=lista[0]\n",
    "            G.add_node(n)\n",
    "            G.node[n][\"tot_act\"]\n",
    "            \n",
    "\n",
    "print \"  N:\", len(G.nodes()),\"  L:\", len(G.edges())       \n",
    "GC = max(nx.connected_component_subgraphs(G), key=len)\n",
    "print \"\\n  GC:     N:\", len(GC.nodes()), \"  L:\", len(GC.edges())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### the master dict is larger than G.nodes(), and the set_node_attribute does not work in that case, so i get a selection of the dict only with the common nodes:\n",
    "#######################\n",
    "\n",
    "# new_dict_user_id = {k: dict_user_id_domain[k] for k in set(G.nodes()) & set(dict_user_id_domain.keys())}\n",
    "# print len(G.nodes()), len(new_dict_user_id)\n",
    "# # i add the email as node attributes    \n",
    "# nx.set_node_attributes(G, 'email', new_dict_user_id)\n",
    "# ############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path=\"/home/juliaponcela/at_NICO/Dropbox_collaboration_patterns/Results/Networks/\"\n",
    "filename=\"first_network_all_new.pickle\"\n",
    "with open(path+filename,'wb') as f:\n",
    "    pickle.dump(G, f)\n",
    "print \"written:\",path+filename\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
